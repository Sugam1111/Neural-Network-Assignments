{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.seterr('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am building a normal forward propogation for a perceptron layer\n",
    "# and the various function i would use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Declaring Training Data        ############\n",
    "#############################################\n",
    "X_train = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "Y_train = np.array([[1],[0],[0],[0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(pred,Y):\n",
    "    return (Y - pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultiLayerPerceptron import MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model , X , Y):\n",
    "    pred,_ = model.forward(X)\n",
    "    pred =pred > 0.5\n",
    "    acc = np.sum(pred == Y)\n",
    "    acc = float(acc) / Y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function tanh at 0x7fc28f6f6598>\n",
      "(2, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "# Declare a neuron with shape of weights as [shape_of_input,1]\n",
    "model = MultiLayerPerceptron([2,1],['tanh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model outputs\n",
    "pred , _ = model.forward(X_train)\n",
    "# print(np.sum((pred > 0.5)== Y_train) / Y_train.shape[0])\n",
    "# accuracy(model , X_train,Y_train)\n",
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function sigmoid at 0x7fc28f6f6400>\n",
      "(2, 3) (3,)\n",
      "<function sigmoid at 0x7fc28f6f6400>\n",
      "(3, 1) (1,)\n",
      "The training loss at 0th epoch : 0.7722248927824626  Training Accuracy:0.25\n",
      "The training loss at 1th epoch : 0.74356641905686  Training Accuracy:0.25\n",
      "The training loss at 2th epoch : 0.7149791382726095  Training Accuracy:0.25\n",
      "The training loss at 3th epoch : 0.6866967799514747  Training Accuracy:0.5\n",
      "The training loss at 4th epoch : 0.6589600727045021  Training Accuracy:0.5\n",
      "The training loss at 5th epoch : 0.6320062078443989  Training Accuracy:0.5\n",
      "The training loss at 6th epoch : 0.6060575321474214  Training Accuracy:0.5\n",
      "The training loss at 7th epoch : 0.581310724230354  Training Accuracy:0.5\n",
      "The training loss at 8th epoch : 0.5579277441099357  Training Accuracy:0.5\n",
      "The training loss at 9th epoch : 0.5360296074096995  Training Accuracy:0.5\n",
      "The training loss at 10th epoch : 0.5156935757785212  Training Accuracy:0.5\n",
      "The training loss at 11th epoch : 0.4969537966580385  Training Accuracy:0.5\n",
      "The training loss at 12th epoch : 0.4798049155823084  Training Accuracy:0.5\n",
      "The training loss at 13th epoch : 0.46420783812787947  Training Accuracy:0.5\n",
      "The training loss at 14th epoch : 0.4500966853501164  Training Accuracy:0.5\n",
      "The training loss at 15th epoch : 0.437386046448222  Training Accuracy:0.5\n",
      "The training loss at 16th epoch : 0.42597782149681335  Training Accuracy:0.5\n",
      "The training loss at 17th epoch : 0.4157671894932314  Training Accuracy:0.75\n",
      "The training loss at 18th epoch : 0.4066474702714462  Training Accuracy:0.75\n",
      "The training loss at 19th epoch : 0.3985138354887469  Training Accuracy:0.75\n",
      "The training loss at 20th epoch : 0.3912659505739834  Training Accuracy:0.75\n",
      "The training loss at 21th epoch : 0.3848096999441565  Training Accuracy:0.75\n",
      "The training loss at 22th epoch : 0.3790581743081143  Training Accuracy:0.75\n",
      "The training loss at 23th epoch : 0.3739320959482692  Training Accuracy:0.75\n",
      "The training loss at 24th epoch : 0.3693598382494392  Training Accuracy:0.75\n",
      "The training loss at 25th epoch : 0.365277168923545  Training Accuracy:0.75\n",
      "The training loss at 26th epoch : 0.3616268185303386  Training Accuracy:0.75\n",
      "The training loss at 27th epoch : 0.35835795047878344  Training Accuracy:0.75\n",
      "The training loss at 28th epoch : 0.35542558726078866  Training Accuracy:0.75\n",
      "The training loss at 29th epoch : 0.3527900305730116  Training Accuracy:0.75\n",
      "The training loss at 30th epoch : 0.3504162999223915  Training Accuracy:0.75\n",
      "The training loss at 31th epoch : 0.3482736046918995  Training Accuracy:0.75\n",
      "The training loss at 32th epoch : 0.3463348577927923  Training Accuracy:0.75\n",
      "The training loss at 33th epoch : 0.3445762343155177  Training Accuracy:0.75\n",
      "The training loss at 34th epoch : 0.3429767754707455  Training Accuracy:0.75\n",
      "The training loss at 35th epoch : 0.3415180361463202  Training Accuracy:0.75\n",
      "The training loss at 36th epoch : 0.340183773255365  Training Accuracy:0.75\n",
      "The training loss at 37th epoch : 0.3389596714600466  Training Accuracy:0.75\n",
      "The training loss at 38th epoch : 0.3378331026378306  Training Accuracy:0.75\n",
      "The training loss at 39th epoch : 0.33679291547872126  Training Accuracy:0.75\n",
      "The training loss at 40th epoch : 0.3358292517693761  Training Accuracy:0.75\n",
      "The training loss at 41th epoch : 0.3349333861689217  Training Accuracy:0.75\n",
      "The training loss at 42th epoch : 0.33409758656886895  Training Accuracy:0.75\n",
      "The training loss at 43th epoch : 0.33331499242785484  Training Accuracy:0.75\n",
      "The training loss at 44th epoch : 0.33257950876365755  Training Accuracy:0.75\n",
      "The training loss at 45th epoch : 0.33188571375981746  Training Accuracy:0.75\n",
      "The training loss at 46th epoch : 0.3312287781968892  Training Accuracy:0.75\n",
      "The training loss at 47th epoch : 0.3306043951465609  Training Accuracy:0.75\n",
      "The training loss at 48th epoch : 0.33000871857041686  Training Accuracy:0.75\n",
      "The training loss at 49th epoch : 0.3294383096448933  Training Accuracy:0.75\n"
     ]
    }
   ],
   "source": [
    "# Now we can train the model by iteratively on each datapoint.\n",
    "from Loss import Loss\n",
    "layer_list = [2 ,3, 1]\n",
    "activation_list = ['sigmoid','sigmoid']\n",
    "model = MultiLayerPerceptron(layer_list,activation_list)\n",
    "loss_m = Loss()\n",
    "\n",
    "def train(model ,loss_m,X_train , Y_train,epochs,alpha =0.1):\n",
    "    for i in range(epochs):\n",
    "        act , cache = model.forward(X_train)\n",
    "        loss,d_back= loss_m.sq_loss(act,Y_train)\n",
    "        acc = accuracy(model ,X_train,Y_train)\n",
    "        print(\"The training loss at {}th epoch : {}  Training Accuracy:{}\".format(i , loss , acc))\n",
    "        model.update_gradient(cache,d_back,alpha)        \n",
    "\n",
    "train(model , loss_m , X_train,Y_train , 50,alpha = 0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can predict the values for unseen data or trained data also\n",
    "# We can also calculate the accuracy of the model we have trained\n",
    "accuracy(model , X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N Bit XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Lets try working with just a little better data. A n XOR operator. So lets create the dataset for n bit xor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would have atmost 2^n data point in this type of data set.BUt we would limit our dataset to a 1000 data points\n",
    "whichever is smaller.\n",
    "\n",
    "Then we can divide into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 10\n",
    "max_datapoint = 10000\n",
    "datapoints = min(pow(2,n) , max_datapoint)\n",
    "\n",
    "X = np.zeros((datapoints , n) , dtype=np.int32)\n",
    "Y = np.zeros((datapoints , 1), dtype=np.int32)\n",
    "\n",
    "for i in range(datapoints):\n",
    "    tmp = i\n",
    "    y_tmp = 0\n",
    "    for j in range(n-1 , -1 , -1):\n",
    "        X[i,j] = tmp&1\n",
    "        y_tmp = y_tmp^X[i,j]\n",
    "        tmp = tmp>>1\n",
    "    Y[i] = y_tmp\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 1] [1]\n"
     ]
    }
   ],
   "source": [
    "# for sanity check lets print one example\n",
    "ind = 11\n",
    "print(X[ind] , Y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets divide the set in training and testing\n",
    "div = 0.9\n",
    "train_n = int(div * datapoints)\n",
    "X_train = X[:train_n]\n",
    "Y_train = Y[:train_n]\n",
    "\n",
    "X_test = X[train_n:]\n",
    "Y_test = Y[train_n:]\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function sigmoid at 0x7fc28f6f6400>\n",
      "(10, 8) (8,)\n",
      "<function linear at 0x7fc28f6f66a8>\n",
      "(8, 2) (2,)\n",
      "<function tanh at 0x7fc28f6f6598>\n",
      "(2, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "layer_list = [n,8,2,1]\n",
    "activation_list = ['sigmoid','linear','tanh']\n",
    "\n",
    "loss_m = Loss()\n",
    "\n",
    "\n",
    "model = MultiLayerPerceptron(layer_list,activation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 0th epoch : 115.12318449879041  Training Accuracy:0.501628664495114\n",
      "The training loss at 1th epoch : 115.12318236276869  Training Accuracy:0.501628664495114\n",
      "The training loss at 2th epoch : 115.12318028288092  Training Accuracy:0.500542888165038\n",
      "The training loss at 3th epoch : 115.12317825780892  Training Accuracy:0.500542888165038\n",
      "The training loss at 4th epoch : 115.12317628709329  Training Accuracy:0.500542888165038\n",
      "The training loss at 5th epoch : 115.12317443425857  Training Accuracy:0.500542888165038\n",
      "The training loss at 6th epoch : 115.12319718536631  Training Accuracy:0.501628664495114\n",
      "The training loss at 7th epoch : 115.13109089369168  Training Accuracy:0.500542888165038\n",
      "The training loss at 8th epoch : 117.89300815101502  Training Accuracy:0.499457111834962\n",
      "The training loss at 9th epoch : 225.45912602675637  Training Accuracy:0.500542888165038\n",
      "The training loss at 10th epoch : 220.30682906224257  Training Accuracy:0.500542888165038\n",
      "The training loss at 11th epoch : 193.98398462633688  Training Accuracy:0.500542888165038\n",
      "The training loss at 12th epoch : 278.32418001097335  Training Accuracy:0.499457111834962\n",
      "The training loss at 13th epoch : 229.99999964298837  Training Accuracy:0.500542888165038\n",
      "The training loss at 14th epoch : 229.9999996429883  Training Accuracy:0.500542888165038\n",
      "The training loss at 15th epoch : 229.99999964298829  Training Accuracy:0.500542888165038\n",
      "The training loss at 16th epoch : 229.99999964298823  Training Accuracy:0.500542888165038\n",
      "The training loss at 17th epoch : 229.9999996429882  Training Accuracy:0.500542888165038\n",
      "The training loss at 18th epoch : 229.99999964298814  Training Accuracy:0.500542888165038\n",
      "The training loss at 19th epoch : 229.99999964298812  Training Accuracy:0.500542888165038\n",
      "The training loss at 20th epoch : 229.9999996429881  Training Accuracy:0.500542888165038\n",
      "The training loss at 21th epoch : 229.99999964298803  Training Accuracy:0.500542888165038\n",
      "The training loss at 22th epoch : 229.99999964298797  Training Accuracy:0.500542888165038\n",
      "The training loss at 23th epoch : 229.99999964298794  Training Accuracy:0.500542888165038\n",
      "The training loss at 24th epoch : 229.99999964298792  Training Accuracy:0.500542888165038\n",
      "The training loss at 25th epoch : 229.99999964298786  Training Accuracy:0.500542888165038\n",
      "The training loss at 26th epoch : 229.9999996429878  Training Accuracy:0.500542888165038\n",
      "The training loss at 27th epoch : 229.99999964298777  Training Accuracy:0.500542888165038\n",
      "The training loss at 28th epoch : 229.99999964298775  Training Accuracy:0.500542888165038\n",
      "The training loss at 29th epoch : 229.9999996429877  Training Accuracy:0.500542888165038\n",
      "The training loss at 30th epoch : 229.99999964298763  Training Accuracy:0.500542888165038\n",
      "The training loss at 31th epoch : 229.9999996429876  Training Accuracy:0.500542888165038\n",
      "The training loss at 32th epoch : 229.99999964298755  Training Accuracy:0.500542888165038\n",
      "The training loss at 33th epoch : 229.99999964298752  Training Accuracy:0.500542888165038\n",
      "The training loss at 34th epoch : 229.99999964298746  Training Accuracy:0.500542888165038\n",
      "The training loss at 35th epoch : 229.9999996429874  Training Accuracy:0.500542888165038\n",
      "The training loss at 36th epoch : 229.99999964298738  Training Accuracy:0.500542888165038\n",
      "The training loss at 37th epoch : 229.99999964298735  Training Accuracy:0.500542888165038\n",
      "The training loss at 38th epoch : 229.9999996429873  Training Accuracy:0.500542888165038\n",
      "The training loss at 39th epoch : 229.99999964298723  Training Accuracy:0.500542888165038\n",
      "The training loss at 40th epoch : 229.99999964298723  Training Accuracy:0.500542888165038\n",
      "The training loss at 41th epoch : 229.99999964298718  Training Accuracy:0.500542888165038\n",
      "The training loss at 42th epoch : 229.99999964298712  Training Accuracy:0.500542888165038\n",
      "The training loss at 43th epoch : 229.99999964298706  Training Accuracy:0.500542888165038\n",
      "The training loss at 44th epoch : 229.999999642987  Training Accuracy:0.500542888165038\n",
      "The training loss at 45th epoch : 229.999999642987  Training Accuracy:0.500542888165038\n",
      "The training loss at 46th epoch : 229.99999964298692  Training Accuracy:0.500542888165038\n",
      "The training loss at 47th epoch : 229.9999996429869  Training Accuracy:0.500542888165038\n",
      "The training loss at 48th epoch : 229.99999964298686  Training Accuracy:0.500542888165038\n",
      "The training loss at 49th epoch : 229.99999964298684  Training Accuracy:0.500542888165038\n",
      "The training loss at 50th epoch : 229.99999964298678  Training Accuracy:0.500542888165038\n",
      "The training loss at 51th epoch : 229.99999964298672  Training Accuracy:0.500542888165038\n",
      "The training loss at 52th epoch : 229.9999996429867  Training Accuracy:0.500542888165038\n",
      "The training loss at 53th epoch : 229.9999996429866  Training Accuracy:0.500542888165038\n",
      "The training loss at 54th epoch : 229.9999996429866  Training Accuracy:0.500542888165038\n",
      "The training loss at 55th epoch : 229.99999964298655  Training Accuracy:0.500542888165038\n",
      "The training loss at 56th epoch : 229.9999996429865  Training Accuracy:0.500542888165038\n",
      "The training loss at 57th epoch : 229.99999964298647  Training Accuracy:0.500542888165038\n",
      "The training loss at 58th epoch : 229.99999964298644  Training Accuracy:0.500542888165038\n",
      "The training loss at 59th epoch : 229.99999964298638  Training Accuracy:0.500542888165038\n",
      "The training loss at 60th epoch : 229.99999964298632  Training Accuracy:0.500542888165038\n",
      "The training loss at 61th epoch : 229.9999996429863  Training Accuracy:0.500542888165038\n",
      "The training loss at 62th epoch : 229.99999964298624  Training Accuracy:0.500542888165038\n",
      "The training loss at 63th epoch : 229.9999996429862  Training Accuracy:0.500542888165038\n",
      "The training loss at 64th epoch : 229.99999964298615  Training Accuracy:0.500542888165038\n",
      "The training loss at 65th epoch : 229.99999964298613  Training Accuracy:0.500542888165038\n",
      "The training loss at 66th epoch : 229.99999964298607  Training Accuracy:0.500542888165038\n",
      "The training loss at 67th epoch : 229.99999964298604  Training Accuracy:0.500542888165038\n",
      "The training loss at 68th epoch : 229.99999964298598  Training Accuracy:0.500542888165038\n",
      "The training loss at 69th epoch : 229.99999964298598  Training Accuracy:0.500542888165038\n",
      "The training loss at 70th epoch : 229.99999964298593  Training Accuracy:0.500542888165038\n",
      "The training loss at 71th epoch : 229.99999964298587  Training Accuracy:0.500542888165038\n",
      "The training loss at 72th epoch : 229.9999996429858  Training Accuracy:0.500542888165038\n",
      "The training loss at 73th epoch : 229.99999964298578  Training Accuracy:0.500542888165038\n",
      "The training loss at 74th epoch : 229.99999964298573  Training Accuracy:0.500542888165038\n",
      "The training loss at 75th epoch : 229.9999996429857  Training Accuracy:0.500542888165038\n",
      "The training loss at 76th epoch : 229.99999964298564  Training Accuracy:0.500542888165038\n",
      "The training loss at 77th epoch : 229.99999964298559  Training Accuracy:0.500542888165038\n",
      "The training loss at 78th epoch : 229.99999964298556  Training Accuracy:0.500542888165038\n",
      "The training loss at 79th epoch : 229.99999964298553  Training Accuracy:0.500542888165038\n",
      "The training loss at 80th epoch : 229.99999964298547  Training Accuracy:0.500542888165038\n",
      "The training loss at 81th epoch : 229.99999964298541  Training Accuracy:0.500542888165038\n",
      "The training loss at 82th epoch : 229.9999996429854  Training Accuracy:0.500542888165038\n",
      "The training loss at 83th epoch : 229.99999964298533  Training Accuracy:0.500542888165038\n",
      "The training loss at 84th epoch : 229.9999996429853  Training Accuracy:0.500542888165038\n",
      "The training loss at 85th epoch : 229.99999964298524  Training Accuracy:0.500542888165038\n",
      "The training loss at 86th epoch : 229.9999996429852  Training Accuracy:0.500542888165038\n",
      "The training loss at 87th epoch : 229.99999964298516  Training Accuracy:0.500542888165038\n",
      "The training loss at 88th epoch : 229.99999964298513  Training Accuracy:0.500542888165038\n",
      "The training loss at 89th epoch : 229.99999964298507  Training Accuracy:0.500542888165038\n",
      "The training loss at 90th epoch : 229.99999964298505  Training Accuracy:0.500542888165038\n",
      "The training loss at 91th epoch : 229.999999642985  Training Accuracy:0.500542888165038\n",
      "The training loss at 92th epoch : 229.99999964298496  Training Accuracy:0.500542888165038\n",
      "The training loss at 93th epoch : 229.9999996429849  Training Accuracy:0.500542888165038\n",
      "The training loss at 94th epoch : 229.99999964298485  Training Accuracy:0.500542888165038\n",
      "The training loss at 95th epoch : 229.99999964298482  Training Accuracy:0.500542888165038\n",
      "The training loss at 96th epoch : 229.9999996429848  Training Accuracy:0.500542888165038\n",
      "The training loss at 97th epoch : 229.99999964298473  Training Accuracy:0.500542888165038\n",
      "The training loss at 98th epoch : 229.9999996429847  Training Accuracy:0.500542888165038\n",
      "The training loss at 99th epoch : 229.99999964298465  Training Accuracy:0.500542888165038\n",
      "The training loss at 100th epoch : 229.99999964298462  Training Accuracy:0.500542888165038\n",
      "The training loss at 101th epoch : 229.99999964298456  Training Accuracy:0.500542888165038\n",
      "The training loss at 102th epoch : 229.9999996429845  Training Accuracy:0.500542888165038\n",
      "The training loss at 103th epoch : 229.99999964298448  Training Accuracy:0.500542888165038\n",
      "The training loss at 104th epoch : 229.99999964298445  Training Accuracy:0.500542888165038\n",
      "The training loss at 105th epoch : 229.9999996429844  Training Accuracy:0.500542888165038\n",
      "The training loss at 106th epoch : 229.99999964298433  Training Accuracy:0.500542888165038\n",
      "The training loss at 107th epoch : 229.99999964298428  Training Accuracy:0.500542888165038\n",
      "The training loss at 108th epoch : 229.99999964298428  Training Accuracy:0.500542888165038\n",
      "The training loss at 109th epoch : 229.99999964298422  Training Accuracy:0.500542888165038\n",
      "The training loss at 110th epoch : 229.99999964298416  Training Accuracy:0.500542888165038\n",
      "The training loss at 111th epoch : 229.9999996429841  Training Accuracy:0.500542888165038\n",
      "The training loss at 112th epoch : 229.9999996429841  Training Accuracy:0.500542888165038\n",
      "The training loss at 113th epoch : 229.99999964298405  Training Accuracy:0.500542888165038\n",
      "The training loss at 114th epoch : 229.999999642984  Training Accuracy:0.500542888165038\n",
      "The training loss at 115th epoch : 229.99999964298397  Training Accuracy:0.500542888165038\n",
      "The training loss at 116th epoch : 229.99999964298394  Training Accuracy:0.500542888165038\n",
      "The training loss at 117th epoch : 229.99999964298388  Training Accuracy:0.500542888165038\n",
      "The training loss at 118th epoch : 229.99999964298382  Training Accuracy:0.500542888165038\n",
      "The training loss at 119th epoch : 229.9999996429838  Training Accuracy:0.500542888165038\n",
      "The training loss at 120th epoch : 229.99999964298374  Training Accuracy:0.500542888165038\n",
      "The training loss at 121th epoch : 229.9999996429837  Training Accuracy:0.500542888165038\n",
      "The training loss at 122th epoch : 229.99999964298365  Training Accuracy:0.500542888165038\n",
      "The training loss at 123th epoch : 229.9999996429836  Training Accuracy:0.500542888165038\n",
      "The training loss at 124th epoch : 229.99999964298357  Training Accuracy:0.500542888165038\n",
      "The training loss at 125th epoch : 229.99999964298354  Training Accuracy:0.500542888165038\n",
      "The training loss at 126th epoch : 229.99999964298348  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 127th epoch : 229.99999964298343  Training Accuracy:0.500542888165038\n",
      "The training loss at 128th epoch : 229.9999996429834  Training Accuracy:0.500542888165038\n",
      "The training loss at 129th epoch : 229.99999964298337  Training Accuracy:0.500542888165038\n",
      "The training loss at 130th epoch : 229.9999996429833  Training Accuracy:0.500542888165038\n",
      "The training loss at 131th epoch : 229.99999964298325  Training Accuracy:0.500542888165038\n",
      "The training loss at 132th epoch : 229.99999964298323  Training Accuracy:0.500542888165038\n",
      "The training loss at 133th epoch : 229.9999996429832  Training Accuracy:0.500542888165038\n",
      "The training loss at 134th epoch : 229.99999964298314  Training Accuracy:0.500542888165038\n",
      "The training loss at 135th epoch : 229.99999964298308  Training Accuracy:0.500542888165038\n",
      "The training loss at 136th epoch : 229.99999964298303  Training Accuracy:0.500542888165038\n",
      "The training loss at 137th epoch : 229.999999642983  Training Accuracy:0.500542888165038\n",
      "The training loss at 138th epoch : 229.99999964298297  Training Accuracy:0.500542888165038\n",
      "The training loss at 139th epoch : 229.9999996429829  Training Accuracy:0.500542888165038\n",
      "The training loss at 140th epoch : 229.99999964298286  Training Accuracy:0.500542888165038\n",
      "The training loss at 141th epoch : 229.99999964298283  Training Accuracy:0.500542888165038\n",
      "The training loss at 142th epoch : 229.9999996429828  Training Accuracy:0.500542888165038\n",
      "The training loss at 143th epoch : 229.99999964298274  Training Accuracy:0.500542888165038\n",
      "The training loss at 144th epoch : 229.99999964298271  Training Accuracy:0.500542888165038\n",
      "The training loss at 145th epoch : 229.99999964298266  Training Accuracy:0.500542888165038\n",
      "The training loss at 146th epoch : 229.99999964298263  Training Accuracy:0.500542888165038\n",
      "The training loss at 147th epoch : 229.99999964298257  Training Accuracy:0.500542888165038\n",
      "The training loss at 148th epoch : 229.99999964298252  Training Accuracy:0.500542888165038\n",
      "The training loss at 149th epoch : 229.9999996429825  Training Accuracy:0.500542888165038\n",
      "The training loss at 150th epoch : 229.99999964298243  Training Accuracy:0.500542888165038\n",
      "The training loss at 151th epoch : 229.9999996429824  Training Accuracy:0.500542888165038\n",
      "The training loss at 152th epoch : 229.99999964298235  Training Accuracy:0.500542888165038\n",
      "The training loss at 153th epoch : 229.99999964298232  Training Accuracy:0.500542888165038\n",
      "The training loss at 154th epoch : 229.9999996429823  Training Accuracy:0.500542888165038\n",
      "The training loss at 155th epoch : 229.99999964298223  Training Accuracy:0.500542888165038\n",
      "The training loss at 156th epoch : 229.99999964298217  Training Accuracy:0.500542888165038\n",
      "The training loss at 157th epoch : 229.99999964298212  Training Accuracy:0.500542888165038\n",
      "The training loss at 158th epoch : 229.99999964298212  Training Accuracy:0.500542888165038\n",
      "The training loss at 159th epoch : 229.99999964298206  Training Accuracy:0.500542888165038\n",
      "The training loss at 160th epoch : 229.999999642982  Training Accuracy:0.500542888165038\n",
      "The training loss at 161th epoch : 229.99999964298195  Training Accuracy:0.500542888165038\n",
      "The training loss at 162th epoch : 229.99999964298195  Training Accuracy:0.500542888165038\n",
      "The training loss at 163th epoch : 229.9999996429819  Training Accuracy:0.500542888165038\n",
      "The training loss at 164th epoch : 229.99999964298183  Training Accuracy:0.500542888165038\n",
      "The training loss at 165th epoch : 229.9999996429818  Training Accuracy:0.500542888165038\n",
      "The training loss at 166th epoch : 229.99999964298178  Training Accuracy:0.500542888165038\n",
      "The training loss at 167th epoch : 229.99999964298172  Training Accuracy:0.500542888165038\n",
      "The training loss at 168th epoch : 229.99999964298166  Training Accuracy:0.500542888165038\n",
      "The training loss at 169th epoch : 229.9999996429816  Training Accuracy:0.500542888165038\n",
      "The training loss at 170th epoch : 229.99999964298158  Training Accuracy:0.500542888165038\n",
      "The training loss at 171th epoch : 229.99999964298152  Training Accuracy:0.500542888165038\n",
      "The training loss at 172th epoch : 229.9999996429815  Training Accuracy:0.500542888165038\n",
      "The training loss at 173th epoch : 229.99999964298144  Training Accuracy:0.500542888165038\n",
      "The training loss at 174th epoch : 229.99999964298138  Training Accuracy:0.500542888165038\n",
      "The training loss at 175th epoch : 229.99999964298135  Training Accuracy:0.500542888165038\n",
      "The training loss at 176th epoch : 229.99999964298132  Training Accuracy:0.500542888165038\n",
      "The training loss at 177th epoch : 229.99999964298127  Training Accuracy:0.500542888165038\n",
      "The training loss at 178th epoch : 229.9999996429812  Training Accuracy:0.500542888165038\n",
      "The training loss at 179th epoch : 229.99999964298118  Training Accuracy:0.500542888165038\n",
      "The training loss at 180th epoch : 229.99999964298112  Training Accuracy:0.500542888165038\n",
      "The training loss at 181th epoch : 229.9999996429811  Training Accuracy:0.500542888165038\n",
      "The training loss at 182th epoch : 229.99999964298107  Training Accuracy:0.500542888165038\n",
      "The training loss at 183th epoch : 229.99999964298104  Training Accuracy:0.500542888165038\n",
      "The training loss at 184th epoch : 229.99999964298098  Training Accuracy:0.500542888165038\n",
      "The training loss at 185th epoch : 229.99999964298092  Training Accuracy:0.500542888165038\n",
      "The training loss at 186th epoch : 229.9999996429809  Training Accuracy:0.500542888165038\n",
      "The training loss at 187th epoch : 229.99999964298084  Training Accuracy:0.500542888165038\n",
      "The training loss at 188th epoch : 229.9999996429808  Training Accuracy:0.500542888165038\n",
      "The training loss at 189th epoch : 229.99999964298075  Training Accuracy:0.500542888165038\n",
      "The training loss at 190th epoch : 229.99999964298073  Training Accuracy:0.500542888165038\n",
      "The training loss at 191th epoch : 229.99999964298067  Training Accuracy:0.500542888165038\n",
      "The training loss at 192th epoch : 229.99999964298064  Training Accuracy:0.500542888165038\n",
      "The training loss at 193th epoch : 229.99999964298058  Training Accuracy:0.500542888165038\n",
      "The training loss at 194th epoch : 229.99999964298053  Training Accuracy:0.500542888165038\n",
      "The training loss at 195th epoch : 229.99999964298053  Training Accuracy:0.500542888165038\n",
      "The training loss at 196th epoch : 229.99999964298047  Training Accuracy:0.500542888165038\n",
      "The training loss at 197th epoch : 229.9999996429804  Training Accuracy:0.500542888165038\n",
      "The training loss at 198th epoch : 229.99999964298036  Training Accuracy:0.500542888165038\n",
      "The training loss at 199th epoch : 229.99999964298036  Training Accuracy:0.500542888165038\n",
      "The training loss at 200th epoch : 229.9999996429803  Training Accuracy:0.500542888165038\n",
      "The training loss at 201th epoch : 229.9999996429802  Training Accuracy:0.500542888165038\n",
      "The training loss at 202th epoch : 229.99999964298019  Training Accuracy:0.500542888165038\n",
      "The training loss at 203th epoch : 229.99999964298013  Training Accuracy:0.500542888165038\n",
      "The training loss at 204th epoch : 229.99999964298013  Training Accuracy:0.500542888165038\n",
      "The training loss at 205th epoch : 229.99999964298007  Training Accuracy:0.500542888165038\n",
      "The training loss at 206th epoch : 229.99999964298004  Training Accuracy:0.500542888165038\n",
      "The training loss at 207th epoch : 229.99999964297996  Training Accuracy:0.500542888165038\n",
      "The training loss at 208th epoch : 229.99999964297996  Training Accuracy:0.500542888165038\n",
      "The training loss at 209th epoch : 229.9999996429799  Training Accuracy:0.500542888165038\n",
      "The training loss at 210th epoch : 229.99999964297984  Training Accuracy:0.500542888165038\n",
      "The training loss at 211th epoch : 229.9999996429798  Training Accuracy:0.500542888165038\n",
      "The training loss at 212th epoch : 229.99999964297976  Training Accuracy:0.500542888165038\n",
      "The training loss at 213th epoch : 229.99999964297973  Training Accuracy:0.500542888165038\n",
      "The training loss at 214th epoch : 229.99999964297967  Training Accuracy:0.500542888165038\n",
      "The training loss at 215th epoch : 229.99999964297962  Training Accuracy:0.500542888165038\n",
      "The training loss at 216th epoch : 229.99999964297956  Training Accuracy:0.500542888165038\n",
      "The training loss at 217th epoch : 229.99999964297953  Training Accuracy:0.500542888165038\n",
      "The training loss at 218th epoch : 229.9999996429795  Training Accuracy:0.500542888165038\n",
      "The training loss at 219th epoch : 229.99999964297945  Training Accuracy:0.500542888165038\n",
      "The training loss at 220th epoch : 229.99999964297942  Training Accuracy:0.500542888165038\n",
      "The training loss at 221th epoch : 229.99999964297936  Training Accuracy:0.500542888165038\n",
      "The training loss at 222th epoch : 229.99999964297933  Training Accuracy:0.500542888165038\n",
      "The training loss at 223th epoch : 229.99999964297928  Training Accuracy:0.500542888165038\n",
      "The training loss at 224th epoch : 229.99999964297922  Training Accuracy:0.500542888165038\n",
      "The training loss at 225th epoch : 229.99999964297922  Training Accuracy:0.500542888165038\n",
      "The training loss at 226th epoch : 229.99999964297916  Training Accuracy:0.500542888165038\n",
      "The training loss at 227th epoch : 229.9999996429791  Training Accuracy:0.500542888165038\n",
      "The training loss at 228th epoch : 229.99999964297905  Training Accuracy:0.500542888165038\n",
      "The training loss at 229th epoch : 229.99999964297905  Training Accuracy:0.500542888165038\n",
      "The training loss at 230th epoch : 229.99999964297896  Training Accuracy:0.500542888165038\n",
      "The training loss at 231th epoch : 229.99999964297893  Training Accuracy:0.500542888165038\n",
      "The training loss at 232th epoch : 229.9999996429789  Training Accuracy:0.500542888165038\n",
      "The training loss at 233th epoch : 229.99999964297885  Training Accuracy:0.500542888165038\n",
      "The training loss at 234th epoch : 229.99999964297882  Training Accuracy:0.500542888165038\n",
      "The training loss at 235th epoch : 229.99999964297876  Training Accuracy:0.500542888165038\n",
      "The training loss at 236th epoch : 229.99999964297874  Training Accuracy:0.500542888165038\n",
      "The training loss at 237th epoch : 229.99999964297868  Training Accuracy:0.500542888165038\n",
      "The training loss at 238th epoch : 229.99999964297862  Training Accuracy:0.500542888165038\n",
      "The training loss at 239th epoch : 229.9999996429786  Training Accuracy:0.500542888165038\n",
      "The training loss at 240th epoch : 229.99999964297854  Training Accuracy:0.500542888165038\n",
      "The training loss at 241th epoch : 229.99999964297848  Training Accuracy:0.500542888165038\n",
      "The training loss at 242th epoch : 229.99999964297845  Training Accuracy:0.500542888165038\n",
      "The training loss at 243th epoch : 229.99999964297842  Training Accuracy:0.500542888165038\n",
      "The training loss at 244th epoch : 229.99999964297837  Training Accuracy:0.500542888165038\n",
      "The training loss at 245th epoch : 229.9999996429783  Training Accuracy:0.500542888165038\n",
      "The training loss at 246th epoch : 229.9999996429783  Training Accuracy:0.500542888165038\n",
      "The training loss at 247th epoch : 229.99999964297825  Training Accuracy:0.500542888165038\n",
      "The training loss at 248th epoch : 229.9999996429782  Training Accuracy:0.500542888165038\n",
      "The training loss at 249th epoch : 229.99999964297817  Training Accuracy:0.500542888165038\n",
      "The training loss at 250th epoch : 229.99999964297808  Training Accuracy:0.500542888165038\n",
      "The training loss at 251th epoch : 229.99999964297808  Training Accuracy:0.500542888165038\n",
      "The training loss at 252th epoch : 229.99999964297803  Training Accuracy:0.500542888165038\n",
      "The training loss at 253th epoch : 229.99999964297797  Training Accuracy:0.500542888165038\n",
      "The training loss at 254th epoch : 229.99999964297794  Training Accuracy:0.500542888165038\n",
      "The training loss at 255th epoch : 229.9999996429779  Training Accuracy:0.500542888165038\n",
      "The training loss at 256th epoch : 229.99999964297785  Training Accuracy:0.500542888165038\n",
      "The training loss at 257th epoch : 229.9999996429778  Training Accuracy:0.500542888165038\n",
      "The training loss at 258th epoch : 229.99999964297777  Training Accuracy:0.500542888165038\n",
      "The training loss at 259th epoch : 229.99999964297774  Training Accuracy:0.500542888165038\n",
      "The training loss at 260th epoch : 229.99999964297768  Training Accuracy:0.500542888165038\n",
      "The training loss at 261th epoch : 229.99999964297763  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 262th epoch : 229.9999996429776  Training Accuracy:0.500542888165038\n",
      "The training loss at 263th epoch : 229.99999964297754  Training Accuracy:0.500542888165038\n",
      "The training loss at 264th epoch : 229.9999996429775  Training Accuracy:0.500542888165038\n",
      "The training loss at 265th epoch : 229.99999964297746  Training Accuracy:0.500542888165038\n",
      "The training loss at 266th epoch : 229.99999964297743  Training Accuracy:0.500542888165038\n",
      "The training loss at 267th epoch : 229.99999964297737  Training Accuracy:0.500542888165038\n",
      "The training loss at 268th epoch : 229.99999964297734  Training Accuracy:0.500542888165038\n",
      "The training loss at 269th epoch : 229.9999996429773  Training Accuracy:0.500542888165038\n",
      "The training loss at 270th epoch : 229.99999964297723  Training Accuracy:0.500542888165038\n",
      "The training loss at 271th epoch : 229.99999964297723  Training Accuracy:0.500542888165038\n",
      "The training loss at 272th epoch : 229.99999964297717  Training Accuracy:0.500542888165038\n",
      "The training loss at 273th epoch : 229.99999964297714  Training Accuracy:0.500542888165038\n",
      "The training loss at 274th epoch : 229.99999964297706  Training Accuracy:0.500542888165038\n",
      "The training loss at 275th epoch : 229.99999964297703  Training Accuracy:0.500542888165038\n",
      "The training loss at 276th epoch : 229.999999642977  Training Accuracy:0.500542888165038\n",
      "The training loss at 277th epoch : 229.99999964297695  Training Accuracy:0.500542888165038\n",
      "The training loss at 278th epoch : 229.99999964297692  Training Accuracy:0.500542888165038\n",
      "The training loss at 279th epoch : 229.99999964297686  Training Accuracy:0.500542888165038\n",
      "The training loss at 280th epoch : 229.9999996429768  Training Accuracy:0.500542888165038\n",
      "The training loss at 281th epoch : 229.99999964297677  Training Accuracy:0.500542888165038\n",
      "The training loss at 282th epoch : 229.99999964297672  Training Accuracy:0.500542888165038\n",
      "The training loss at 283th epoch : 229.9999996429767  Training Accuracy:0.500542888165038\n",
      "The training loss at 284th epoch : 229.99999964297663  Training Accuracy:0.500542888165038\n",
      "The training loss at 285th epoch : 229.9999996429766  Training Accuracy:0.500542888165038\n",
      "The training loss at 286th epoch : 229.99999964297655  Training Accuracy:0.500542888165038\n",
      "The training loss at 287th epoch : 229.99999964297652  Training Accuracy:0.500542888165038\n",
      "The training loss at 288th epoch : 229.9999996429765  Training Accuracy:0.500542888165038\n",
      "The training loss at 289th epoch : 229.99999964297643  Training Accuracy:0.500542888165038\n",
      "The training loss at 290th epoch : 229.99999964297638  Training Accuracy:0.500542888165038\n",
      "The training loss at 291th epoch : 229.99999964297632  Training Accuracy:0.500542888165038\n",
      "The training loss at 292th epoch : 229.99999964297632  Training Accuracy:0.500542888165038\n",
      "The training loss at 293th epoch : 229.99999964297623  Training Accuracy:0.500542888165038\n",
      "The training loss at 294th epoch : 229.9999996429762  Training Accuracy:0.500542888165038\n",
      "The training loss at 295th epoch : 229.99999964297615  Training Accuracy:0.500542888165038\n",
      "The training loss at 296th epoch : 229.99999964297615  Training Accuracy:0.500542888165038\n",
      "The training loss at 297th epoch : 229.9999996429761  Training Accuracy:0.500542888165038\n",
      "The training loss at 298th epoch : 229.99999964297604  Training Accuracy:0.500542888165038\n",
      "The training loss at 299th epoch : 229.99999964297598  Training Accuracy:0.500542888165038\n",
      "The training loss at 300th epoch : 229.99999964297595  Training Accuracy:0.500542888165038\n",
      "The training loss at 301th epoch : 229.99999964297592  Training Accuracy:0.500542888165038\n",
      "The training loss at 302th epoch : 229.99999964297587  Training Accuracy:0.500542888165038\n",
      "The training loss at 303th epoch : 229.9999996429758  Training Accuracy:0.500542888165038\n",
      "The training loss at 304th epoch : 229.99999964297578  Training Accuracy:0.500542888165038\n",
      "The training loss at 305th epoch : 229.99999964297572  Training Accuracy:0.500542888165038\n",
      "The training loss at 306th epoch : 229.9999996429757  Training Accuracy:0.500542888165038\n",
      "The training loss at 307th epoch : 229.99999964297564  Training Accuracy:0.500542888165038\n",
      "The training loss at 308th epoch : 229.9999996429756  Training Accuracy:0.500542888165038\n",
      "The training loss at 309th epoch : 229.99999964297555  Training Accuracy:0.500542888165038\n",
      "The training loss at 310th epoch : 229.9999996429755  Training Accuracy:0.500542888165038\n",
      "The training loss at 311th epoch : 229.99999964297547  Training Accuracy:0.500542888165038\n",
      "The training loss at 312th epoch : 229.99999964297544  Training Accuracy:0.500542888165038\n",
      "The training loss at 313th epoch : 229.9999996429754  Training Accuracy:0.500542888165038\n",
      "The training loss at 314th epoch : 229.99999964297535  Training Accuracy:0.500542888165038\n",
      "The training loss at 315th epoch : 229.9999996429753  Training Accuracy:0.500542888165038\n",
      "The training loss at 316th epoch : 229.99999964297524  Training Accuracy:0.500542888165038\n",
      "The training loss at 317th epoch : 229.9999996429752  Training Accuracy:0.500542888165038\n",
      "The training loss at 318th epoch : 229.99999964297515  Training Accuracy:0.500542888165038\n",
      "The training loss at 319th epoch : 229.99999964297513  Training Accuracy:0.500542888165038\n",
      "The training loss at 320th epoch : 229.9999996429751  Training Accuracy:0.500542888165038\n",
      "The training loss at 321th epoch : 229.99999964297507  Training Accuracy:0.500542888165038\n",
      "The training loss at 322th epoch : 229.999999642975  Training Accuracy:0.500542888165038\n",
      "The training loss at 323th epoch : 229.99999964297496  Training Accuracy:0.500542888165038\n",
      "The training loss at 324th epoch : 229.99999964297493  Training Accuracy:0.500542888165038\n",
      "The training loss at 325th epoch : 229.99999964297487  Training Accuracy:0.500542888165038\n",
      "The training loss at 326th epoch : 229.99999964297484  Training Accuracy:0.500542888165038\n",
      "The training loss at 327th epoch : 229.99999964297479  Training Accuracy:0.500542888165038\n",
      "The training loss at 328th epoch : 229.99999964297473  Training Accuracy:0.500542888165038\n",
      "The training loss at 329th epoch : 229.9999996429747  Training Accuracy:0.500542888165038\n",
      "The training loss at 330th epoch : 229.99999964297464  Training Accuracy:0.500542888165038\n",
      "The training loss at 331th epoch : 229.99999964297461  Training Accuracy:0.500542888165038\n",
      "The training loss at 332th epoch : 229.99999964297456  Training Accuracy:0.500542888165038\n",
      "The training loss at 333th epoch : 229.99999964297453  Training Accuracy:0.500542888165038\n",
      "The training loss at 334th epoch : 229.99999964297447  Training Accuracy:0.500542888165038\n",
      "The training loss at 335th epoch : 229.99999964297442  Training Accuracy:0.500542888165038\n",
      "The training loss at 336th epoch : 229.9999996429744  Training Accuracy:0.500542888165038\n",
      "The training loss at 337th epoch : 229.99999964297433  Training Accuracy:0.500542888165038\n",
      "The training loss at 338th epoch : 229.9999996429743  Training Accuracy:0.500542888165038\n",
      "The training loss at 339th epoch : 229.99999964297427  Training Accuracy:0.500542888165038\n",
      "The training loss at 340th epoch : 229.99999964297422  Training Accuracy:0.500542888165038\n",
      "The training loss at 341th epoch : 229.99999964297416  Training Accuracy:0.500542888165038\n",
      "The training loss at 342th epoch : 229.99999964297413  Training Accuracy:0.500542888165038\n",
      "The training loss at 343th epoch : 229.9999996429741  Training Accuracy:0.500542888165038\n",
      "The training loss at 344th epoch : 229.99999964297405  Training Accuracy:0.500542888165038\n",
      "The training loss at 345th epoch : 229.99999964297402  Training Accuracy:0.500542888165038\n",
      "The training loss at 346th epoch : 229.99999964297396  Training Accuracy:0.500542888165038\n",
      "The training loss at 347th epoch : 229.99999964297393  Training Accuracy:0.500542888165038\n",
      "The training loss at 348th epoch : 229.99999964297388  Training Accuracy:0.500542888165038\n",
      "The training loss at 349th epoch : 229.99999964297382  Training Accuracy:0.500542888165038\n",
      "The training loss at 350th epoch : 229.9999996429738  Training Accuracy:0.500542888165038\n",
      "The training loss at 351th epoch : 229.99999964297373  Training Accuracy:0.500542888165038\n",
      "The training loss at 352th epoch : 229.9999996429737  Training Accuracy:0.500542888165038\n",
      "The training loss at 353th epoch : 229.99999964297365  Training Accuracy:0.500542888165038\n",
      "The training loss at 354th epoch : 229.9999996429736  Training Accuracy:0.500542888165038\n",
      "The training loss at 355th epoch : 229.99999964297356  Training Accuracy:0.500542888165038\n",
      "The training loss at 356th epoch : 229.99999964297353  Training Accuracy:0.500542888165038\n",
      "The training loss at 357th epoch : 229.99999964297348  Training Accuracy:0.500542888165038\n",
      "The training loss at 358th epoch : 229.99999964297342  Training Accuracy:0.500542888165038\n",
      "The training loss at 359th epoch : 229.9999996429734  Training Accuracy:0.500542888165038\n",
      "The training loss at 360th epoch : 229.99999964297336  Training Accuracy:0.500542888165038\n",
      "The training loss at 361th epoch : 229.9999996429733  Training Accuracy:0.500542888165038\n",
      "The training loss at 362th epoch : 229.99999964297328  Training Accuracy:0.500542888165038\n",
      "The training loss at 363th epoch : 229.9999996429732  Training Accuracy:0.500542888165038\n",
      "The training loss at 364th epoch : 229.99999964297317  Training Accuracy:0.500542888165038\n",
      "The training loss at 365th epoch : 229.99999964297314  Training Accuracy:0.500542888165038\n",
      "The training loss at 366th epoch : 229.9999996429731  Training Accuracy:0.500542888165038\n",
      "The training loss at 367th epoch : 229.99999964297305  Training Accuracy:0.500542888165038\n",
      "The training loss at 368th epoch : 229.99999964297302  Training Accuracy:0.500542888165038\n",
      "The training loss at 369th epoch : 229.99999964297297  Training Accuracy:0.500542888165038\n",
      "The training loss at 370th epoch : 229.9999996429729  Training Accuracy:0.500542888165038\n",
      "The training loss at 371th epoch : 229.99999964297288  Training Accuracy:0.500542888165038\n",
      "The training loss at 372th epoch : 229.99999964297285  Training Accuracy:0.500542888165038\n",
      "The training loss at 373th epoch : 229.9999996429728  Training Accuracy:0.500542888165038\n",
      "The training loss at 374th epoch : 229.99999964297274  Training Accuracy:0.500542888165038\n",
      "The training loss at 375th epoch : 229.9999996429727  Training Accuracy:0.500542888165038\n",
      "The training loss at 376th epoch : 229.99999964297265  Training Accuracy:0.500542888165038\n",
      "The training loss at 377th epoch : 229.99999964297263  Training Accuracy:0.500542888165038\n",
      "The training loss at 378th epoch : 229.99999964297257  Training Accuracy:0.500542888165038\n",
      "The training loss at 379th epoch : 229.9999996429725  Training Accuracy:0.500542888165038\n",
      "The training loss at 380th epoch : 229.9999996429725  Training Accuracy:0.500542888165038\n",
      "The training loss at 381th epoch : 229.99999964297243  Training Accuracy:0.500542888165038\n",
      "The training loss at 382th epoch : 229.9999996429724  Training Accuracy:0.500542888165038\n",
      "The training loss at 383th epoch : 229.99999964297237  Training Accuracy:0.500542888165038\n",
      "The training loss at 384th epoch : 229.99999964297234  Training Accuracy:0.500542888165038\n",
      "The training loss at 385th epoch : 229.99999964297228  Training Accuracy:0.500542888165038\n",
      "The training loss at 386th epoch : 229.99999964297223  Training Accuracy:0.500542888165038\n",
      "The training loss at 387th epoch : 229.9999996429722  Training Accuracy:0.500542888165038\n",
      "The training loss at 388th epoch : 229.99999964297214  Training Accuracy:0.500542888165038\n",
      "The training loss at 389th epoch : 229.9999996429721  Training Accuracy:0.500542888165038\n",
      "The training loss at 390th epoch : 229.99999964297206  Training Accuracy:0.500542888165038\n",
      "The training loss at 391th epoch : 229.999999642972  Training Accuracy:0.500542888165038\n",
      "The training loss at 392th epoch : 229.99999964297197  Training Accuracy:0.500542888165038\n",
      "The training loss at 393th epoch : 229.99999964297194  Training Accuracy:0.500542888165038\n",
      "The training loss at 394th epoch : 229.9999996429719  Training Accuracy:0.500542888165038\n",
      "The training loss at 395th epoch : 229.99999964297183  Training Accuracy:0.500542888165038\n",
      "The training loss at 396th epoch : 229.9999996429718  Training Accuracy:0.500542888165038\n",
      "The training loss at 397th epoch : 229.99999964297174  Training Accuracy:0.500542888165038\n",
      "The training loss at 398th epoch : 229.99999964297172  Training Accuracy:0.500542888165038\n",
      "The training loss at 399th epoch : 229.99999964297166  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 400th epoch : 229.99999964297163  Training Accuracy:0.500542888165038\n",
      "The training loss at 401th epoch : 229.99999964297157  Training Accuracy:0.500542888165038\n",
      "The training loss at 402th epoch : 229.99999964297155  Training Accuracy:0.500542888165038\n",
      "The training loss at 403th epoch : 229.99999964297152  Training Accuracy:0.500542888165038\n",
      "The training loss at 404th epoch : 229.99999964297143  Training Accuracy:0.500542888165038\n",
      "The training loss at 405th epoch : 229.9999996429714  Training Accuracy:0.500542888165038\n",
      "The training loss at 406th epoch : 229.99999964297135  Training Accuracy:0.500542888165038\n",
      "The training loss at 407th epoch : 229.99999964297132  Training Accuracy:0.500542888165038\n",
      "The training loss at 408th epoch : 229.9999996429713  Training Accuracy:0.500542888165038\n",
      "The training loss at 409th epoch : 229.99999964297123  Training Accuracy:0.500542888165038\n",
      "The training loss at 410th epoch : 229.9999996429712  Training Accuracy:0.500542888165038\n",
      "The training loss at 411th epoch : 229.99999964297115  Training Accuracy:0.500542888165038\n",
      "The training loss at 412th epoch : 229.9999996429711  Training Accuracy:0.500542888165038\n",
      "The training loss at 413th epoch : 229.99999964297103  Training Accuracy:0.500542888165038\n",
      "The training loss at 414th epoch : 229.99999964297103  Training Accuracy:0.500542888165038\n",
      "The training loss at 415th epoch : 229.99999964297098  Training Accuracy:0.500542888165038\n",
      "The training loss at 416th epoch : 229.99999964297092  Training Accuracy:0.500542888165038\n",
      "The training loss at 417th epoch : 229.9999996429709  Training Accuracy:0.500542888165038\n",
      "The training loss at 418th epoch : 229.99999964297083  Training Accuracy:0.500542888165038\n",
      "The training loss at 419th epoch : 229.9999996429708  Training Accuracy:0.500542888165038\n",
      "The training loss at 420th epoch : 229.99999964297075  Training Accuracy:0.500542888165038\n",
      "The training loss at 421th epoch : 229.9999996429707  Training Accuracy:0.500542888165038\n",
      "The training loss at 422th epoch : 229.99999964297066  Training Accuracy:0.500542888165038\n",
      "The training loss at 423th epoch : 229.9999996429706  Training Accuracy:0.500542888165038\n",
      "The training loss at 424th epoch : 229.99999964297058  Training Accuracy:0.500542888165038\n",
      "The training loss at 425th epoch : 229.99999964297052  Training Accuracy:0.500542888165038\n",
      "The training loss at 426th epoch : 229.99999964297052  Training Accuracy:0.500542888165038\n",
      "The training loss at 427th epoch : 229.99999964297047  Training Accuracy:0.500542888165038\n",
      "The training loss at 428th epoch : 229.9999996429704  Training Accuracy:0.500542888165038\n",
      "The training loss at 429th epoch : 229.99999964297035  Training Accuracy:0.500542888165038\n",
      "The training loss at 430th epoch : 229.99999964297032  Training Accuracy:0.500542888165038\n",
      "The training loss at 431th epoch : 229.9999996429703  Training Accuracy:0.500542888165038\n",
      "The training loss at 432th epoch : 229.99999964297024  Training Accuracy:0.500542888165038\n",
      "The training loss at 433th epoch : 229.99999964297018  Training Accuracy:0.500542888165038\n",
      "The training loss at 434th epoch : 229.99999964297015  Training Accuracy:0.500542888165038\n",
      "The training loss at 435th epoch : 229.99999964297012  Training Accuracy:0.500542888165038\n",
      "The training loss at 436th epoch : 229.99999964297007  Training Accuracy:0.500542888165038\n",
      "The training loss at 437th epoch : 229.99999964297  Training Accuracy:0.500542888165038\n",
      "The training loss at 438th epoch : 229.99999964296998  Training Accuracy:0.500542888165038\n",
      "The training loss at 439th epoch : 229.99999964296995  Training Accuracy:0.500542888165038\n",
      "The training loss at 440th epoch : 229.9999996429699  Training Accuracy:0.500542888165038\n",
      "The training loss at 441th epoch : 229.99999964296984  Training Accuracy:0.500542888165038\n",
      "The training loss at 442th epoch : 229.99999964296978  Training Accuracy:0.500542888165038\n",
      "The training loss at 443th epoch : 229.99999964296975  Training Accuracy:0.500542888165038\n",
      "The training loss at 444th epoch : 229.99999964296973  Training Accuracy:0.500542888165038\n",
      "The training loss at 445th epoch : 229.99999964296967  Training Accuracy:0.500542888165038\n",
      "The training loss at 446th epoch : 229.9999996429696  Training Accuracy:0.500542888165038\n",
      "The training loss at 447th epoch : 229.9999996429696  Training Accuracy:0.500542888165038\n",
      "The training loss at 448th epoch : 229.99999964296956  Training Accuracy:0.500542888165038\n",
      "The training loss at 449th epoch : 229.9999996429695  Training Accuracy:0.500542888165038\n",
      "The training loss at 450th epoch : 229.99999964296944  Training Accuracy:0.500542888165038\n",
      "The training loss at 451th epoch : 229.9999996429694  Training Accuracy:0.500542888165038\n",
      "The training loss at 452th epoch : 229.99999964296939  Training Accuracy:0.500542888165038\n",
      "The training loss at 453th epoch : 229.99999964296933  Training Accuracy:0.500542888165038\n",
      "The training loss at 454th epoch : 229.99999964296927  Training Accuracy:0.500542888165038\n",
      "The training loss at 455th epoch : 229.99999964296924  Training Accuracy:0.500542888165038\n",
      "The training loss at 456th epoch : 229.99999964296921  Training Accuracy:0.500542888165038\n",
      "The training loss at 457th epoch : 229.99999964296916  Training Accuracy:0.500542888165038\n",
      "The training loss at 458th epoch : 229.9999996429691  Training Accuracy:0.500542888165038\n",
      "The training loss at 459th epoch : 229.99999964296907  Training Accuracy:0.500542888165038\n",
      "The training loss at 460th epoch : 229.99999964296902  Training Accuracy:0.500542888165038\n",
      "The training loss at 461th epoch : 229.999999642969  Training Accuracy:0.500542888165038\n",
      "The training loss at 462th epoch : 229.99999964296893  Training Accuracy:0.500542888165038\n",
      "The training loss at 463th epoch : 229.9999996429689  Training Accuracy:0.500542888165038\n",
      "The training loss at 464th epoch : 229.99999964296887  Training Accuracy:0.500542888165038\n",
      "The training loss at 465th epoch : 229.99999964296882  Training Accuracy:0.500542888165038\n",
      "The training loss at 466th epoch : 229.99999964296876  Training Accuracy:0.500542888165038\n",
      "The training loss at 467th epoch : 229.99999964296873  Training Accuracy:0.500542888165038\n",
      "The training loss at 468th epoch : 229.99999964296867  Training Accuracy:0.500542888165038\n",
      "The training loss at 469th epoch : 229.99999964296865  Training Accuracy:0.500542888165038\n",
      "The training loss at 470th epoch : 229.9999996429686  Training Accuracy:0.500542888165038\n",
      "The training loss at 471th epoch : 229.99999964296853  Training Accuracy:0.500542888165038\n",
      "The training loss at 472th epoch : 229.99999964296853  Training Accuracy:0.500542888165038\n",
      "The training loss at 473th epoch : 229.99999964296845  Training Accuracy:0.500542888165038\n",
      "The training loss at 474th epoch : 229.99999964296842  Training Accuracy:0.500542888165038\n",
      "The training loss at 475th epoch : 229.99999964296836  Training Accuracy:0.500542888165038\n",
      "The training loss at 476th epoch : 229.99999964296836  Training Accuracy:0.500542888165038\n",
      "The training loss at 477th epoch : 229.9999996429683  Training Accuracy:0.500542888165038\n",
      "The training loss at 478th epoch : 229.99999964296825  Training Accuracy:0.500542888165038\n",
      "The training loss at 479th epoch : 229.9999996429682  Training Accuracy:0.500542888165038\n",
      "The training loss at 480th epoch : 229.99999964296816  Training Accuracy:0.500542888165038\n",
      "The training loss at 481th epoch : 229.99999964296813  Training Accuracy:0.500542888165038\n",
      "The training loss at 482th epoch : 229.99999964296808  Training Accuracy:0.500542888165038\n",
      "The training loss at 483th epoch : 229.99999964296802  Training Accuracy:0.500542888165038\n",
      "The training loss at 484th epoch : 229.999999642968  Training Accuracy:0.500542888165038\n",
      "The training loss at 485th epoch : 229.99999964296794  Training Accuracy:0.500542888165038\n",
      "The training loss at 486th epoch : 229.9999996429679  Training Accuracy:0.500542888165038\n",
      "The training loss at 487th epoch : 229.99999964296785  Training Accuracy:0.500542888165038\n",
      "The training loss at 488th epoch : 229.9999996429678  Training Accuracy:0.500542888165038\n",
      "The training loss at 489th epoch : 229.99999964296777  Training Accuracy:0.500542888165038\n",
      "The training loss at 490th epoch : 229.99999964296774  Training Accuracy:0.500542888165038\n",
      "The training loss at 491th epoch : 229.99999964296768  Training Accuracy:0.500542888165038\n",
      "The training loss at 492th epoch : 229.99999964296762  Training Accuracy:0.500542888165038\n",
      "The training loss at 493th epoch : 229.99999964296762  Training Accuracy:0.500542888165038\n",
      "The training loss at 494th epoch : 229.99999964296757  Training Accuracy:0.500542888165038\n",
      "The training loss at 495th epoch : 229.9999996429675  Training Accuracy:0.500542888165038\n",
      "The training loss at 496th epoch : 229.99999964296745  Training Accuracy:0.500542888165038\n",
      "The training loss at 497th epoch : 229.99999964296745  Training Accuracy:0.500542888165038\n",
      "The training loss at 498th epoch : 229.9999996429674  Training Accuracy:0.500542888165038\n",
      "The training loss at 499th epoch : 229.99999964296734  Training Accuracy:0.500542888165038\n",
      "The training loss at 500th epoch : 229.9999996429673  Training Accuracy:0.500542888165038\n",
      "The training loss at 501th epoch : 229.99999964296728  Training Accuracy:0.500542888165038\n",
      "The training loss at 502th epoch : 229.99999964296723  Training Accuracy:0.500542888165038\n",
      "The training loss at 503th epoch : 229.99999964296717  Training Accuracy:0.500542888165038\n",
      "The training loss at 504th epoch : 229.9999996429671  Training Accuracy:0.500542888165038\n",
      "The training loss at 505th epoch : 229.99999964296708  Training Accuracy:0.500542888165038\n",
      "The training loss at 506th epoch : 229.99999964296705  Training Accuracy:0.500542888165038\n",
      "The training loss at 507th epoch : 229.999999642967  Training Accuracy:0.500542888165038\n",
      "The training loss at 508th epoch : 229.99999964296694  Training Accuracy:0.500542888165038\n",
      "The training loss at 509th epoch : 229.9999996429669  Training Accuracy:0.500542888165038\n",
      "The training loss at 510th epoch : 229.99999964296686  Training Accuracy:0.500542888165038\n",
      "The training loss at 511th epoch : 229.99999964296683  Training Accuracy:0.500542888165038\n",
      "The training loss at 512th epoch : 229.99999964296677  Training Accuracy:0.500542888165038\n",
      "The training loss at 513th epoch : 229.9999996429667  Training Accuracy:0.500542888165038\n",
      "The training loss at 514th epoch : 229.99999964296666  Training Accuracy:0.500542888165038\n",
      "The training loss at 515th epoch : 229.99999964296666  Training Accuracy:0.500542888165038\n",
      "The training loss at 516th epoch : 229.9999996429666  Training Accuracy:0.500542888165038\n",
      "The training loss at 517th epoch : 229.99999964296654  Training Accuracy:0.500542888165038\n",
      "The training loss at 518th epoch : 229.99999964296651  Training Accuracy:0.500542888165038\n",
      "The training loss at 519th epoch : 229.9999996429665  Training Accuracy:0.500542888165038\n",
      "The training loss at 520th epoch : 229.99999964296643  Training Accuracy:0.500542888165038\n",
      "The training loss at 521th epoch : 229.9999996429664  Training Accuracy:0.500542888165038\n",
      "The training loss at 522th epoch : 229.99999964296634  Training Accuracy:0.500542888165038\n",
      "The training loss at 523th epoch : 229.99999964296632  Training Accuracy:0.500542888165038\n",
      "The training loss at 524th epoch : 229.99999964296626  Training Accuracy:0.500542888165038\n",
      "The training loss at 525th epoch : 229.9999996429662  Training Accuracy:0.500542888165038\n",
      "The training loss at 526th epoch : 229.99999964296617  Training Accuracy:0.500542888165038\n",
      "The training loss at 527th epoch : 229.99999964296612  Training Accuracy:0.500542888165038\n",
      "The training loss at 528th epoch : 229.9999996429661  Training Accuracy:0.500542888165038\n",
      "The training loss at 529th epoch : 229.99999964296603  Training Accuracy:0.500542888165038\n",
      "The training loss at 530th epoch : 229.999999642966  Training Accuracy:0.500542888165038\n",
      "The training loss at 531th epoch : 229.99999964296597  Training Accuracy:0.500542888165038\n",
      "The training loss at 532th epoch : 229.99999964296592  Training Accuracy:0.500542888165038\n",
      "The training loss at 533th epoch : 229.99999964296586  Training Accuracy:0.500542888165038\n",
      "The training loss at 534th epoch : 229.9999996429658  Training Accuracy:0.500542888165038\n",
      "The training loss at 535th epoch : 229.99999964296578  Training Accuracy:0.500542888165038\n",
      "The training loss at 536th epoch : 229.99999964296575  Training Accuracy:0.500542888165038\n",
      "The training loss at 537th epoch : 229.9999996429657  Training Accuracy:0.500542888165038\n",
      "The training loss at 538th epoch : 229.99999964296563  Training Accuracy:0.500542888165038\n",
      "The training loss at 539th epoch : 229.9999996429656  Training Accuracy:0.500542888165038\n",
      "The training loss at 540th epoch : 229.99999964296558  Training Accuracy:0.500542888165038\n",
      "The training loss at 541th epoch : 229.99999964296552  Training Accuracy:0.500542888165038\n",
      "The training loss at 542th epoch : 229.99999964296546  Training Accuracy:0.500542888165038\n",
      "The training loss at 543th epoch : 229.9999996429654  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 544th epoch : 229.9999996429654  Training Accuracy:0.500542888165038\n",
      "The training loss at 545th epoch : 229.99999964296535  Training Accuracy:0.500542888165038\n",
      "The training loss at 546th epoch : 229.99999964296532  Training Accuracy:0.500542888165038\n",
      "The training loss at 547th epoch : 229.99999964296524  Training Accuracy:0.500542888165038\n",
      "The training loss at 548th epoch : 229.99999964296524  Training Accuracy:0.500542888165038\n",
      "The training loss at 549th epoch : 229.99999964296518  Training Accuracy:0.500542888165038\n",
      "The training loss at 550th epoch : 229.99999964296512  Training Accuracy:0.500542888165038\n",
      "The training loss at 551th epoch : 229.9999996429651  Training Accuracy:0.500542888165038\n",
      "The training loss at 552th epoch : 229.99999964296507  Training Accuracy:0.500542888165038\n",
      "The training loss at 553th epoch : 229.999999642965  Training Accuracy:0.500542888165038\n",
      "The training loss at 554th epoch : 229.99999964296495  Training Accuracy:0.500542888165038\n",
      "The training loss at 555th epoch : 229.9999996429649  Training Accuracy:0.500542888165038\n",
      "The training loss at 556th epoch : 229.99999964296487  Training Accuracy:0.500542888165038\n",
      "The training loss at 557th epoch : 229.9999996429648  Training Accuracy:0.500542888165038\n",
      "The training loss at 558th epoch : 229.99999964296478  Training Accuracy:0.500542888165038\n",
      "The training loss at 559th epoch : 229.99999964296472  Training Accuracy:0.500542888165038\n",
      "The training loss at 560th epoch : 229.9999996429647  Training Accuracy:0.500542888165038\n",
      "The training loss at 561th epoch : 229.99999964296467  Training Accuracy:0.500542888165038\n",
      "The training loss at 562th epoch : 229.9999996429646  Training Accuracy:0.500542888165038\n",
      "The training loss at 563th epoch : 229.99999964296455  Training Accuracy:0.500542888165038\n",
      "The training loss at 564th epoch : 229.99999964296453  Training Accuracy:0.500542888165038\n",
      "The training loss at 565th epoch : 229.9999996429645  Training Accuracy:0.500542888165038\n",
      "The training loss at 566th epoch : 229.99999964296444  Training Accuracy:0.500542888165038\n",
      "The training loss at 567th epoch : 229.9999996429644  Training Accuracy:0.500542888165038\n",
      "The training loss at 568th epoch : 229.99999964296433  Training Accuracy:0.500542888165038\n",
      "The training loss at 569th epoch : 229.99999964296433  Training Accuracy:0.500542888165038\n",
      "The training loss at 570th epoch : 229.99999964296427  Training Accuracy:0.500542888165038\n",
      "The training loss at 571th epoch : 229.9999996429642  Training Accuracy:0.500542888165038\n",
      "The training loss at 572th epoch : 229.99999964296418  Training Accuracy:0.500542888165038\n",
      "The training loss at 573th epoch : 229.99999964296413  Training Accuracy:0.500542888165038\n",
      "The training loss at 574th epoch : 229.9999996429641  Training Accuracy:0.500542888165038\n",
      "The training loss at 575th epoch : 229.99999964296404  Training Accuracy:0.500542888165038\n",
      "The training loss at 576th epoch : 229.999999642964  Training Accuracy:0.500542888165038\n",
      "The training loss at 577th epoch : 229.99999964296396  Training Accuracy:0.500542888165038\n",
      "The training loss at 578th epoch : 229.99999964296393  Training Accuracy:0.500542888165038\n",
      "The training loss at 579th epoch : 229.99999964296387  Training Accuracy:0.500542888165038\n",
      "The training loss at 580th epoch : 229.99999964296381  Training Accuracy:0.500542888165038\n",
      "The training loss at 581th epoch : 229.9999996429638  Training Accuracy:0.500542888165038\n",
      "The training loss at 582th epoch : 229.99999964296376  Training Accuracy:0.500542888165038\n",
      "The training loss at 583th epoch : 229.9999996429637  Training Accuracy:0.500542888165038\n",
      "The training loss at 584th epoch : 229.99999964296364  Training Accuracy:0.500542888165038\n",
      "The training loss at 585th epoch : 229.99999964296364  Training Accuracy:0.500542888165038\n",
      "The training loss at 586th epoch : 229.9999996429636  Training Accuracy:0.500542888165038\n",
      "The training loss at 587th epoch : 229.9999996429635  Training Accuracy:0.500542888165038\n",
      "The training loss at 588th epoch : 229.9999996429635  Training Accuracy:0.500542888165038\n",
      "The training loss at 589th epoch : 229.99999964296345  Training Accuracy:0.500542888165038\n",
      "The training loss at 590th epoch : 229.99999964296342  Training Accuracy:0.500542888165038\n",
      "The training loss at 591th epoch : 229.99999964296336  Training Accuracy:0.500542888165038\n",
      "The training loss at 592th epoch : 229.9999996429633  Training Accuracy:0.500542888165038\n",
      "The training loss at 593th epoch : 229.99999964296327  Training Accuracy:0.500542888165038\n",
      "The training loss at 594th epoch : 229.99999964296325  Training Accuracy:0.500542888165038\n",
      "The training loss at 595th epoch : 229.9999996429632  Training Accuracy:0.500542888165038\n",
      "The training loss at 596th epoch : 229.99999964296313  Training Accuracy:0.500542888165038\n",
      "The training loss at 597th epoch : 229.99999964296308  Training Accuracy:0.500542888165038\n",
      "The training loss at 598th epoch : 229.99999964296305  Training Accuracy:0.500542888165038\n",
      "The training loss at 599th epoch : 229.99999964296302  Training Accuracy:0.500542888165038\n",
      "The training loss at 600th epoch : 229.99999964296296  Training Accuracy:0.500542888165038\n",
      "The training loss at 601th epoch : 229.9999996429629  Training Accuracy:0.500542888165038\n",
      "The training loss at 602th epoch : 229.99999964296288  Training Accuracy:0.500542888165038\n",
      "The training loss at 603th epoch : 229.99999964296285  Training Accuracy:0.500542888165038\n",
      "The training loss at 604th epoch : 229.9999996429628  Training Accuracy:0.500542888165038\n",
      "The training loss at 605th epoch : 229.99999964296273  Training Accuracy:0.500542888165038\n",
      "The training loss at 606th epoch : 229.99999964296273  Training Accuracy:0.500542888165038\n",
      "The training loss at 607th epoch : 229.99999964296268  Training Accuracy:0.500542888165038\n",
      "The training loss at 608th epoch : 229.99999964296262  Training Accuracy:0.500542888165038\n",
      "The training loss at 609th epoch : 229.99999964296256  Training Accuracy:0.500542888165038\n",
      "The training loss at 610th epoch : 229.99999964296254  Training Accuracy:0.500542888165038\n",
      "The training loss at 611th epoch : 229.9999996429625  Training Accuracy:0.500542888165038\n",
      "The training loss at 612th epoch : 229.99999964296245  Training Accuracy:0.500542888165038\n",
      "The training loss at 613th epoch : 229.9999996429624  Training Accuracy:0.500542888165038\n",
      "The training loss at 614th epoch : 229.99999964296236  Training Accuracy:0.500542888165038\n",
      "The training loss at 615th epoch : 229.99999964296234  Training Accuracy:0.500542888165038\n",
      "The training loss at 616th epoch : 229.99999964296228  Training Accuracy:0.500542888165038\n",
      "The training loss at 617th epoch : 229.99999964296222  Training Accuracy:0.500542888165038\n",
      "The training loss at 618th epoch : 229.9999996429622  Training Accuracy:0.500542888165038\n",
      "The training loss at 619th epoch : 229.99999964296214  Training Accuracy:0.500542888165038\n",
      "The training loss at 620th epoch : 229.9999996429621  Training Accuracy:0.500542888165038\n",
      "The training loss at 621th epoch : 229.99999964296205  Training Accuracy:0.500542888165038\n",
      "The training loss at 622th epoch : 229.99999964296202  Training Accuracy:0.500542888165038\n",
      "The training loss at 623th epoch : 229.99999964296197  Training Accuracy:0.500542888165038\n",
      "The training loss at 624th epoch : 229.99999964296194  Training Accuracy:0.500542888165038\n",
      "The training loss at 625th epoch : 229.99999964296188  Training Accuracy:0.500542888165038\n",
      "The training loss at 626th epoch : 229.99999964296182  Training Accuracy:0.500542888165038\n",
      "The training loss at 627th epoch : 229.9999996429618  Training Accuracy:0.500542888165038\n",
      "The training loss at 628th epoch : 229.99999964296177  Training Accuracy:0.500542888165038\n",
      "The training loss at 629th epoch : 229.9999996429617  Training Accuracy:0.500542888165038\n",
      "The training loss at 630th epoch : 229.99999964296165  Training Accuracy:0.500542888165038\n",
      "The training loss at 631th epoch : 229.9999996429616  Training Accuracy:0.500542888165038\n",
      "The training loss at 632th epoch : 229.9999996429616  Training Accuracy:0.500542888165038\n",
      "The training loss at 633th epoch : 229.99999964296154  Training Accuracy:0.500542888165038\n",
      "The training loss at 634th epoch : 229.99999964296148  Training Accuracy:0.500542888165038\n",
      "The training loss at 635th epoch : 229.99999964296143  Training Accuracy:0.500542888165038\n",
      "The training loss at 636th epoch : 229.99999964296143  Training Accuracy:0.500542888165038\n",
      "The training loss at 637th epoch : 229.99999964296137  Training Accuracy:0.500542888165038\n",
      "The training loss at 638th epoch : 229.9999996429613  Training Accuracy:0.500542888165038\n",
      "The training loss at 639th epoch : 229.99999964296128  Training Accuracy:0.500542888165038\n",
      "The training loss at 640th epoch : 229.99999964296126  Training Accuracy:0.500542888165038\n",
      "The training loss at 641th epoch : 229.9999996429612  Training Accuracy:0.500542888165038\n",
      "The training loss at 642th epoch : 229.99999964296114  Training Accuracy:0.500542888165038\n",
      "The training loss at 643th epoch : 229.9999996429611  Training Accuracy:0.500542888165038\n",
      "The training loss at 644th epoch : 229.9999996429611  Training Accuracy:0.500542888165038\n",
      "The training loss at 645th epoch : 229.99999964296103  Training Accuracy:0.500542888165038\n",
      "The training loss at 646th epoch : 229.99999964296097  Training Accuracy:0.500542888165038\n",
      "The training loss at 647th epoch : 229.99999964296094  Training Accuracy:0.500542888165038\n",
      "The training loss at 648th epoch : 229.99999964296092  Training Accuracy:0.500542888165038\n",
      "The training loss at 649th epoch : 229.99999964296083  Training Accuracy:0.500542888165038\n",
      "The training loss at 650th epoch : 229.9999996429608  Training Accuracy:0.500542888165038\n",
      "The training loss at 651th epoch : 229.99999964296074  Training Accuracy:0.500542888165038\n",
      "The training loss at 652th epoch : 229.99999964296074  Training Accuracy:0.500542888165038\n",
      "The training loss at 653th epoch : 229.9999996429607  Training Accuracy:0.500542888165038\n",
      "The training loss at 654th epoch : 229.99999964296063  Training Accuracy:0.500542888165038\n",
      "The training loss at 655th epoch : 229.99999964296057  Training Accuracy:0.500542888165038\n",
      "The training loss at 656th epoch : 229.99999964296057  Training Accuracy:0.500542888165038\n",
      "The training loss at 657th epoch : 229.9999996429605  Training Accuracy:0.500542888165038\n",
      "The training loss at 658th epoch : 229.99999964296046  Training Accuracy:0.500542888165038\n",
      "The training loss at 659th epoch : 229.9999996429604  Training Accuracy:0.500542888165038\n",
      "The training loss at 660th epoch : 229.99999964296038  Training Accuracy:0.500542888165038\n",
      "The training loss at 661th epoch : 229.99999964296032  Training Accuracy:0.500542888165038\n",
      "The training loss at 662th epoch : 229.9999996429603  Training Accuracy:0.500542888165038\n",
      "The training loss at 663th epoch : 229.99999964296023  Training Accuracy:0.500542888165038\n",
      "The training loss at 664th epoch : 229.9999996429602  Training Accuracy:0.500542888165038\n",
      "The training loss at 665th epoch : 229.99999964296015  Training Accuracy:0.500542888165038\n",
      "The training loss at 666th epoch : 229.99999964296012  Training Accuracy:0.500542888165038\n",
      "The training loss at 667th epoch : 229.99999964296006  Training Accuracy:0.500542888165038\n",
      "The training loss at 668th epoch : 229.99999964296003  Training Accuracy:0.500542888165038\n",
      "The training loss at 669th epoch : 229.99999964295998  Training Accuracy:0.500542888165038\n",
      "The training loss at 670th epoch : 229.99999964295995  Training Accuracy:0.500542888165038\n",
      "The training loss at 671th epoch : 229.9999996429599  Training Accuracy:0.500542888165038\n",
      "The training loss at 672th epoch : 229.99999964295984  Training Accuracy:0.500542888165038\n",
      "The training loss at 673th epoch : 229.9999996429598  Training Accuracy:0.500542888165038\n",
      "The training loss at 674th epoch : 229.99999964295975  Training Accuracy:0.500542888165038\n",
      "The training loss at 675th epoch : 229.99999964295972  Training Accuracy:0.500542888165038\n",
      "The training loss at 676th epoch : 229.99999964295966  Training Accuracy:0.500542888165038\n",
      "The training loss at 677th epoch : 229.99999964295964  Training Accuracy:0.500542888165038\n",
      "The training loss at 678th epoch : 229.9999996429596  Training Accuracy:0.500542888165038\n",
      "The training loss at 679th epoch : 229.99999964295955  Training Accuracy:0.500542888165038\n",
      "The training loss at 680th epoch : 229.99999964295952  Training Accuracy:0.500542888165038\n",
      "The training loss at 681th epoch : 229.99999964295947  Training Accuracy:0.500542888165038\n",
      "The training loss at 682th epoch : 229.99999964295944  Training Accuracy:0.500542888165038\n",
      "The training loss at 683th epoch : 229.99999964295938  Training Accuracy:0.500542888165038\n",
      "The training loss at 684th epoch : 229.99999964295932  Training Accuracy:0.500542888165038\n",
      "The training loss at 685th epoch : 229.9999996429593  Training Accuracy:0.500542888165038\n",
      "The training loss at 686th epoch : 229.99999964295924  Training Accuracy:0.500542888165038\n",
      "The training loss at 687th epoch : 229.9999996429592  Training Accuracy:0.500542888165038\n",
      "The training loss at 688th epoch : 229.99999964295915  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 689th epoch : 229.9999996429591  Training Accuracy:0.500542888165038\n",
      "The training loss at 690th epoch : 229.99999964295904  Training Accuracy:0.500542888165038\n",
      "The training loss at 691th epoch : 229.99999964295904  Training Accuracy:0.500542888165038\n",
      "The training loss at 692th epoch : 229.99999964295898  Training Accuracy:0.500542888165038\n",
      "The training loss at 693th epoch : 229.99999964295893  Training Accuracy:0.500542888165038\n",
      "The training loss at 694th epoch : 229.9999996429589  Training Accuracy:0.500542888165038\n",
      "The training loss at 695th epoch : 229.99999964295887  Training Accuracy:0.500542888165038\n",
      "The training loss at 696th epoch : 229.9999996429588  Training Accuracy:0.500542888165038\n",
      "The training loss at 697th epoch : 229.99999964295878  Training Accuracy:0.500542888165038\n",
      "The training loss at 698th epoch : 229.99999964295873  Training Accuracy:0.500542888165038\n",
      "The training loss at 699th epoch : 229.9999996429587  Training Accuracy:0.500542888165038\n",
      "The training loss at 700th epoch : 229.99999964295864  Training Accuracy:0.500542888165038\n",
      "The training loss at 701th epoch : 229.99999964295858  Training Accuracy:0.500542888165038\n",
      "The training loss at 702th epoch : 229.99999964295856  Training Accuracy:0.500542888165038\n",
      "The training loss at 703th epoch : 229.99999964295853  Training Accuracy:0.500542888165038\n",
      "The training loss at 704th epoch : 229.99999964295847  Training Accuracy:0.500542888165038\n",
      "The training loss at 705th epoch : 229.99999964295841  Training Accuracy:0.500542888165038\n",
      "The training loss at 706th epoch : 229.9999996429584  Training Accuracy:0.500542888165038\n",
      "The training loss at 707th epoch : 229.99999964295833  Training Accuracy:0.500542888165038\n",
      "The training loss at 708th epoch : 229.9999996429583  Training Accuracy:0.500542888165038\n",
      "The training loss at 709th epoch : 229.99999964295824  Training Accuracy:0.500542888165038\n",
      "The training loss at 710th epoch : 229.99999964295822  Training Accuracy:0.500542888165038\n",
      "The training loss at 711th epoch : 229.99999964295816  Training Accuracy:0.500542888165038\n",
      "The training loss at 712th epoch : 229.99999964295813  Training Accuracy:0.500542888165038\n",
      "The training loss at 713th epoch : 229.99999964295807  Training Accuracy:0.500542888165038\n",
      "The training loss at 714th epoch : 229.99999964295804  Training Accuracy:0.500542888165038\n",
      "The training loss at 715th epoch : 229.999999642958  Training Accuracy:0.500542888165038\n",
      "The training loss at 716th epoch : 229.99999964295793  Training Accuracy:0.500542888165038\n",
      "The training loss at 717th epoch : 229.9999996429579  Training Accuracy:0.500542888165038\n",
      "The training loss at 718th epoch : 229.99999964295785  Training Accuracy:0.500542888165038\n",
      "The training loss at 719th epoch : 229.99999964295782  Training Accuracy:0.500542888165038\n",
      "The training loss at 720th epoch : 229.9999996429578  Training Accuracy:0.500542888165038\n",
      "The training loss at 721th epoch : 229.99999964295773  Training Accuracy:0.500542888165038\n",
      "The training loss at 722th epoch : 229.99999964295768  Training Accuracy:0.500542888165038\n",
      "The training loss at 723th epoch : 229.99999964295765  Training Accuracy:0.500542888165038\n",
      "The training loss at 724th epoch : 229.99999964295762  Training Accuracy:0.500542888165038\n",
      "The training loss at 725th epoch : 229.99999964295756  Training Accuracy:0.500542888165038\n",
      "The training loss at 726th epoch : 229.99999964295753  Training Accuracy:0.500542888165038\n",
      "The training loss at 727th epoch : 229.99999964295745  Training Accuracy:0.500542888165038\n",
      "The training loss at 728th epoch : 229.99999964295745  Training Accuracy:0.500542888165038\n",
      "The training loss at 729th epoch : 229.9999996429574  Training Accuracy:0.500542888165038\n",
      "The training loss at 730th epoch : 229.99999964295733  Training Accuracy:0.500542888165038\n",
      "The training loss at 731th epoch : 229.9999996429573  Training Accuracy:0.500542888165038\n",
      "The training loss at 732th epoch : 229.99999964295725  Training Accuracy:0.500542888165038\n",
      "The training loss at 733th epoch : 229.99999964295722  Training Accuracy:0.500542888165038\n",
      "The training loss at 734th epoch : 229.99999964295716  Training Accuracy:0.500542888165038\n",
      "The training loss at 735th epoch : 229.99999964295714  Training Accuracy:0.500542888165038\n",
      "The training loss at 736th epoch : 229.99999964295708  Training Accuracy:0.500542888165038\n",
      "The training loss at 737th epoch : 229.99999964295702  Training Accuracy:0.500542888165038\n",
      "The training loss at 738th epoch : 229.999999642957  Training Accuracy:0.500542888165038\n",
      "The training loss at 739th epoch : 229.99999964295694  Training Accuracy:0.500542888165038\n",
      "The training loss at 740th epoch : 229.9999996429569  Training Accuracy:0.500542888165038\n",
      "The training loss at 741th epoch : 229.99999964295688  Training Accuracy:0.500542888165038\n",
      "The training loss at 742th epoch : 229.99999964295682  Training Accuracy:0.500542888165038\n",
      "The training loss at 743th epoch : 229.99999964295677  Training Accuracy:0.500542888165038\n",
      "The training loss at 744th epoch : 229.99999964295674  Training Accuracy:0.500542888165038\n",
      "The training loss at 745th epoch : 229.9999996429567  Training Accuracy:0.500542888165038\n",
      "The training loss at 746th epoch : 229.99999964295665  Training Accuracy:0.500542888165038\n",
      "The training loss at 747th epoch : 229.9999996429566  Training Accuracy:0.500542888165038\n",
      "The training loss at 748th epoch : 229.99999964295657  Training Accuracy:0.500542888165038\n",
      "The training loss at 749th epoch : 229.99999964295654  Training Accuracy:0.500542888165038\n",
      "The training loss at 750th epoch : 229.99999964295648  Training Accuracy:0.500542888165038\n",
      "The training loss at 751th epoch : 229.99999964295645  Training Accuracy:0.500542888165038\n",
      "The training loss at 752th epoch : 229.9999996429564  Training Accuracy:0.500542888165038\n",
      "The training loss at 753th epoch : 229.99999964295637  Training Accuracy:0.500542888165038\n",
      "The training loss at 754th epoch : 229.9999996429563  Training Accuracy:0.500542888165038\n",
      "The training loss at 755th epoch : 229.99999964295625  Training Accuracy:0.500542888165038\n",
      "The training loss at 756th epoch : 229.9999996429562  Training Accuracy:0.500542888165038\n",
      "The training loss at 757th epoch : 229.99999964295617  Training Accuracy:0.500542888165038\n",
      "The training loss at 758th epoch : 229.99999964295614  Training Accuracy:0.500542888165038\n",
      "The training loss at 759th epoch : 229.99999964295608  Training Accuracy:0.500542888165038\n",
      "The training loss at 760th epoch : 229.99999964295603  Training Accuracy:0.500542888165038\n",
      "The training loss at 761th epoch : 229.999999642956  Training Accuracy:0.500542888165038\n",
      "The training loss at 762th epoch : 229.99999964295597  Training Accuracy:0.500542888165038\n",
      "The training loss at 763th epoch : 229.9999996429559  Training Accuracy:0.500542888165038\n",
      "The training loss at 764th epoch : 229.99999964295586  Training Accuracy:0.500542888165038\n",
      "The training loss at 765th epoch : 229.9999996429558  Training Accuracy:0.500542888165038\n",
      "The training loss at 766th epoch : 229.99999964295577  Training Accuracy:0.500542888165038\n",
      "The training loss at 767th epoch : 229.99999964295574  Training Accuracy:0.500542888165038\n",
      "The training loss at 768th epoch : 229.9999996429557  Training Accuracy:0.500542888165038\n",
      "The training loss at 769th epoch : 229.99999964295563  Training Accuracy:0.500542888165038\n",
      "The training loss at 770th epoch : 229.9999996429556  Training Accuracy:0.500542888165038\n",
      "The training loss at 771th epoch : 229.99999964295557  Training Accuracy:0.500542888165038\n",
      "The training loss at 772th epoch : 229.99999964295552  Training Accuracy:0.500542888165038\n",
      "The training loss at 773th epoch : 229.9999996429555  Training Accuracy:0.500542888165038\n",
      "The training loss at 774th epoch : 229.99999964295546  Training Accuracy:0.500542888165038\n",
      "The training loss at 775th epoch : 229.9999996429554  Training Accuracy:0.500542888165038\n",
      "The training loss at 776th epoch : 229.99999964295534  Training Accuracy:0.500542888165038\n",
      "The training loss at 777th epoch : 229.99999964295532  Training Accuracy:0.500542888165038\n",
      "The training loss at 778th epoch : 229.99999964295526  Training Accuracy:0.500542888165038\n",
      "The training loss at 779th epoch : 229.99999964295523  Training Accuracy:0.500542888165038\n",
      "The training loss at 780th epoch : 229.99999964295517  Training Accuracy:0.500542888165038\n",
      "The training loss at 781th epoch : 229.99999964295512  Training Accuracy:0.500542888165038\n",
      "The training loss at 782th epoch : 229.99999964295512  Training Accuracy:0.500542888165038\n",
      "The training loss at 783th epoch : 229.99999964295503  Training Accuracy:0.500542888165038\n",
      "The training loss at 784th epoch : 229.999999642955  Training Accuracy:0.500542888165038\n",
      "The training loss at 785th epoch : 229.99999964295495  Training Accuracy:0.500542888165038\n",
      "The training loss at 786th epoch : 229.99999964295492  Training Accuracy:0.500542888165038\n",
      "The training loss at 787th epoch : 229.99999964295486  Training Accuracy:0.500542888165038\n",
      "The training loss at 788th epoch : 229.99999964295483  Training Accuracy:0.500542888165038\n",
      "The training loss at 789th epoch : 229.99999964295478  Training Accuracy:0.500542888165038\n",
      "The training loss at 790th epoch : 229.99999964295475  Training Accuracy:0.500542888165038\n",
      "The training loss at 791th epoch : 229.99999964295472  Training Accuracy:0.500542888165038\n",
      "The training loss at 792th epoch : 229.99999964295466  Training Accuracy:0.500542888165038\n",
      "The training loss at 793th epoch : 229.9999996429546  Training Accuracy:0.500542888165038\n",
      "The training loss at 794th epoch : 229.9999996429546  Training Accuracy:0.500542888165038\n",
      "The training loss at 795th epoch : 229.99999964295455  Training Accuracy:0.500542888165038\n",
      "The training loss at 796th epoch : 229.9999996429545  Training Accuracy:0.500542888165038\n",
      "The training loss at 797th epoch : 229.99999964295444  Training Accuracy:0.500542888165038\n",
      "The training loss at 798th epoch : 229.9999996429544  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 799th epoch : 229.99999964295435  Training Accuracy:0.500542888165038\n",
      "The training loss at 800th epoch : 229.99999964295432  Training Accuracy:0.500542888165038\n",
      "The training loss at 801th epoch : 229.99999964295426  Training Accuracy:0.500542888165038\n",
      "The training loss at 802th epoch : 229.9999996429542  Training Accuracy:0.500542888165038\n",
      "The training loss at 803th epoch : 229.99999964295418  Training Accuracy:0.500542888165038\n",
      "The training loss at 804th epoch : 229.99999964295415  Training Accuracy:0.500542888165038\n",
      "The training loss at 805th epoch : 229.9999996429541  Training Accuracy:0.500542888165038\n",
      "The training loss at 806th epoch : 229.99999964295404  Training Accuracy:0.500542888165038\n",
      "The training loss at 807th epoch : 229.99999964295398  Training Accuracy:0.500542888165038\n",
      "The training loss at 808th epoch : 229.99999964295395  Training Accuracy:0.500542888165038\n",
      "The training loss at 809th epoch : 229.99999964295392  Training Accuracy:0.500542888165038\n",
      "The training loss at 810th epoch : 229.99999964295387  Training Accuracy:0.500542888165038\n",
      "The training loss at 811th epoch : 229.9999996429538  Training Accuracy:0.500542888165038\n",
      "The training loss at 812th epoch : 229.9999996429538  Training Accuracy:0.500542888165038\n",
      "The training loss at 813th epoch : 229.99999964295375  Training Accuracy:0.500542888165038\n",
      "The training loss at 814th epoch : 229.99999964295372  Training Accuracy:0.500542888165038\n",
      "The training loss at 815th epoch : 229.99999964295367  Training Accuracy:0.500542888165038\n",
      "The training loss at 816th epoch : 229.99999964295364  Training Accuracy:0.500542888165038\n",
      "The training loss at 817th epoch : 229.99999964295358  Training Accuracy:0.500542888165038\n",
      "The training loss at 818th epoch : 229.99999964295353  Training Accuracy:0.500542888165038\n",
      "The training loss at 819th epoch : 229.9999996429535  Training Accuracy:0.500542888165038\n",
      "The training loss at 820th epoch : 229.99999964295344  Training Accuracy:0.500542888165038\n",
      "The training loss at 821th epoch : 229.9999996429534  Training Accuracy:0.500542888165038\n",
      "The training loss at 822th epoch : 229.99999964295336  Training Accuracy:0.500542888165038\n",
      "The training loss at 823th epoch : 229.99999964295333  Training Accuracy:0.500542888165038\n",
      "The training loss at 824th epoch : 229.99999964295324  Training Accuracy:0.500542888165038\n",
      "The training loss at 825th epoch : 229.9999996429532  Training Accuracy:0.500542888165038\n",
      "The training loss at 826th epoch : 229.99999964295318  Training Accuracy:0.500542888165038\n",
      "The training loss at 827th epoch : 229.99999964295313  Training Accuracy:0.500542888165038\n",
      "The training loss at 828th epoch : 229.9999996429531  Training Accuracy:0.500542888165038\n",
      "The training loss at 829th epoch : 229.99999964295304  Training Accuracy:0.500542888165038\n",
      "The training loss at 830th epoch : 229.99999964295301  Training Accuracy:0.500542888165038\n",
      "The training loss at 831th epoch : 229.99999964295296  Training Accuracy:0.500542888165038\n",
      "The training loss at 832th epoch : 229.99999964295293  Training Accuracy:0.500542888165038\n",
      "The training loss at 833th epoch : 229.99999964295287  Training Accuracy:0.500542888165038\n",
      "The training loss at 834th epoch : 229.99999964295284  Training Accuracy:0.500542888165038\n",
      "The training loss at 835th epoch : 229.9999996429528  Training Accuracy:0.500542888165038\n",
      "The training loss at 836th epoch : 229.99999964295276  Training Accuracy:0.500542888165038\n",
      "The training loss at 837th epoch : 229.9999996429527  Training Accuracy:0.500542888165038\n",
      "The training loss at 838th epoch : 229.99999964295267  Training Accuracy:0.500542888165038\n",
      "The training loss at 839th epoch : 229.99999964295262  Training Accuracy:0.500542888165038\n",
      "The training loss at 840th epoch : 229.9999996429526  Training Accuracy:0.500542888165038\n",
      "The training loss at 841th epoch : 229.99999964295253  Training Accuracy:0.500542888165038\n",
      "The training loss at 842th epoch : 229.9999996429525  Training Accuracy:0.500542888165038\n",
      "The training loss at 843th epoch : 229.99999964295245  Training Accuracy:0.500542888165038\n",
      "The training loss at 844th epoch : 229.99999964295242  Training Accuracy:0.500542888165038\n",
      "The training loss at 845th epoch : 229.99999964295236  Training Accuracy:0.500542888165038\n",
      "The training loss at 846th epoch : 229.99999964295233  Training Accuracy:0.500542888165038\n",
      "The training loss at 847th epoch : 229.99999964295228  Training Accuracy:0.500542888165038\n",
      "The training loss at 848th epoch : 229.99999964295222  Training Accuracy:0.500542888165038\n",
      "The training loss at 849th epoch : 229.9999996429522  Training Accuracy:0.500542888165038\n",
      "The training loss at 850th epoch : 229.99999964295216  Training Accuracy:0.500542888165038\n",
      "The training loss at 851th epoch : 229.9999996429521  Training Accuracy:0.500542888165038\n",
      "The training loss at 852th epoch : 229.99999964295205  Training Accuracy:0.500542888165038\n",
      "The training loss at 853th epoch : 229.99999964295205  Training Accuracy:0.500542888165038\n",
      "The training loss at 854th epoch : 229.999999642952  Training Accuracy:0.500542888165038\n",
      "The training loss at 855th epoch : 229.99999964295193  Training Accuracy:0.500542888165038\n",
      "The training loss at 856th epoch : 229.99999964295188  Training Accuracy:0.500542888165038\n",
      "The training loss at 857th epoch : 229.99999964295185  Training Accuracy:0.500542888165038\n",
      "The training loss at 858th epoch : 229.99999964295182  Training Accuracy:0.500542888165038\n",
      "The training loss at 859th epoch : 229.99999964295176  Training Accuracy:0.500542888165038\n",
      "The training loss at 860th epoch : 229.99999964295174  Training Accuracy:0.500542888165038\n",
      "The training loss at 861th epoch : 229.99999964295168  Training Accuracy:0.500542888165038\n",
      "The training loss at 862th epoch : 229.99999964295162  Training Accuracy:0.500542888165038\n",
      "The training loss at 863th epoch : 229.9999996429516  Training Accuracy:0.500542888165038\n",
      "The training loss at 864th epoch : 229.99999964295154  Training Accuracy:0.500542888165038\n",
      "The training loss at 865th epoch : 229.9999996429515  Training Accuracy:0.500542888165038\n",
      "The training loss at 866th epoch : 229.99999964295145  Training Accuracy:0.500542888165038\n",
      "The training loss at 867th epoch : 229.99999964295142  Training Accuracy:0.500542888165038\n",
      "The training loss at 868th epoch : 229.99999964295137  Training Accuracy:0.500542888165038\n",
      "The training loss at 869th epoch : 229.99999964295134  Training Accuracy:0.500542888165038\n",
      "The training loss at 870th epoch : 229.99999964295128  Training Accuracy:0.500542888165038\n",
      "The training loss at 871th epoch : 229.99999964295125  Training Accuracy:0.500542888165038\n",
      "The training loss at 872th epoch : 229.9999996429512  Training Accuracy:0.500542888165038\n",
      "The training loss at 873th epoch : 229.99999964295117  Training Accuracy:0.500542888165038\n",
      "The training loss at 874th epoch : 229.9999996429511  Training Accuracy:0.500542888165038\n",
      "The training loss at 875th epoch : 229.99999964295108  Training Accuracy:0.500542888165038\n",
      "The training loss at 876th epoch : 229.99999964295102  Training Accuracy:0.500542888165038\n",
      "The training loss at 877th epoch : 229.99999964295097  Training Accuracy:0.500542888165038\n",
      "The training loss at 878th epoch : 229.99999964295094  Training Accuracy:0.500542888165038\n",
      "The training loss at 879th epoch : 229.9999996429509  Training Accuracy:0.500542888165038\n",
      "The training loss at 880th epoch : 229.99999964295085  Training Accuracy:0.500542888165038\n",
      "The training loss at 881th epoch : 229.99999964295083  Training Accuracy:0.500542888165038\n",
      "The training loss at 882th epoch : 229.99999964295074  Training Accuracy:0.500542888165038\n",
      "The training loss at 883th epoch : 229.99999964295074  Training Accuracy:0.500542888165038\n",
      "The training loss at 884th epoch : 229.99999964295068  Training Accuracy:0.500542888165038\n",
      "The training loss at 885th epoch : 229.99999964295063  Training Accuracy:0.500542888165038\n",
      "The training loss at 886th epoch : 229.9999996429506  Training Accuracy:0.500542888165038\n",
      "The training loss at 887th epoch : 229.99999964295054  Training Accuracy:0.500542888165038\n",
      "The training loss at 888th epoch : 229.9999996429505  Training Accuracy:0.500542888165038\n",
      "The training loss at 889th epoch : 229.99999964295046  Training Accuracy:0.500542888165038\n",
      "The training loss at 890th epoch : 229.99999964295043  Training Accuracy:0.500542888165038\n",
      "The training loss at 891th epoch : 229.99999964295037  Training Accuracy:0.500542888165038\n",
      "The training loss at 892th epoch : 229.99999964295034  Training Accuracy:0.500542888165038\n",
      "The training loss at 893th epoch : 229.99999964295029  Training Accuracy:0.500542888165038\n",
      "The training loss at 894th epoch : 229.99999964295023  Training Accuracy:0.500542888165038\n",
      "The training loss at 895th epoch : 229.9999996429502  Training Accuracy:0.500542888165038\n",
      "The training loss at 896th epoch : 229.99999964295014  Training Accuracy:0.500542888165038\n",
      "The training loss at 897th epoch : 229.99999964295012  Training Accuracy:0.500542888165038\n",
      "The training loss at 898th epoch : 229.99999964295006  Training Accuracy:0.500542888165038\n",
      "The training loss at 899th epoch : 229.99999964295  Training Accuracy:0.500542888165038\n",
      "The training loss at 900th epoch : 229.99999964295  Training Accuracy:0.500542888165038\n",
      "The training loss at 901th epoch : 229.99999964294994  Training Accuracy:0.500542888165038\n",
      "The training loss at 902th epoch : 229.99999964294992  Training Accuracy:0.500542888165038\n",
      "The training loss at 903th epoch : 229.99999964294986  Training Accuracy:0.500542888165038\n",
      "The training loss at 904th epoch : 229.99999964294983  Training Accuracy:0.500542888165038\n",
      "The training loss at 905th epoch : 229.99999964294977  Training Accuracy:0.500542888165038\n",
      "The training loss at 906th epoch : 229.99999964294972  Training Accuracy:0.500542888165038\n",
      "The training loss at 907th epoch : 229.99999964294966  Training Accuracy:0.500542888165038\n",
      "The training loss at 908th epoch : 229.99999964294963  Training Accuracy:0.500542888165038\n",
      "The training loss at 909th epoch : 229.9999996429496  Training Accuracy:0.500542888165038\n",
      "The training loss at 910th epoch : 229.99999964294955  Training Accuracy:0.500542888165038\n",
      "The training loss at 911th epoch : 229.99999964294952  Training Accuracy:0.500542888165038\n",
      "The training loss at 912th epoch : 229.99999964294946  Training Accuracy:0.500542888165038\n",
      "The training loss at 913th epoch : 229.99999964294943  Training Accuracy:0.500542888165038\n",
      "The training loss at 914th epoch : 229.99999964294938  Training Accuracy:0.500542888165038\n",
      "The training loss at 915th epoch : 229.99999964294932  Training Accuracy:0.500542888165038\n",
      "The training loss at 916th epoch : 229.9999996429493  Training Accuracy:0.500542888165038\n",
      "The training loss at 917th epoch : 229.99999964294926  Training Accuracy:0.500542888165038\n",
      "The training loss at 918th epoch : 229.9999996429492  Training Accuracy:0.500542888165038\n",
      "The training loss at 919th epoch : 229.99999964294915  Training Accuracy:0.500542888165038\n",
      "The training loss at 920th epoch : 229.99999964294912  Training Accuracy:0.500542888165038\n",
      "The training loss at 921th epoch : 229.9999996429491  Training Accuracy:0.500542888165038\n",
      "The training loss at 922th epoch : 229.99999964294904  Training Accuracy:0.500542888165038\n",
      "The training loss at 923th epoch : 229.99999964294898  Training Accuracy:0.500542888165038\n",
      "The training loss at 924th epoch : 229.99999964294892  Training Accuracy:0.500542888165038\n",
      "The training loss at 925th epoch : 229.99999964294892  Training Accuracy:0.500542888165038\n",
      "The training loss at 926th epoch : 229.99999964294886  Training Accuracy:0.500542888165038\n",
      "The training loss at 927th epoch : 229.9999996429488  Training Accuracy:0.500542888165038\n",
      "The training loss at 928th epoch : 229.99999964294875  Training Accuracy:0.500542888165038\n",
      "The training loss at 929th epoch : 229.99999964294872  Training Accuracy:0.500542888165038\n",
      "The training loss at 930th epoch : 229.9999996429487  Training Accuracy:0.500542888165038\n",
      "The training loss at 931th epoch : 229.99999964294864  Training Accuracy:0.500542888165038\n",
      "The training loss at 932th epoch : 229.9999996429486  Training Accuracy:0.500542888165038\n",
      "The training loss at 933th epoch : 229.99999964294858  Training Accuracy:0.500542888165038\n",
      "The training loss at 934th epoch : 229.99999964294852  Training Accuracy:0.500542888165038\n",
      "The training loss at 935th epoch : 229.99999964294847  Training Accuracy:0.500542888165038\n",
      "The training loss at 936th epoch : 229.9999996429484  Training Accuracy:0.500542888165038\n",
      "The training loss at 937th epoch : 229.99999964294838  Training Accuracy:0.500542888165038\n",
      "The training loss at 938th epoch : 229.99999964294832  Training Accuracy:0.500542888165038\n",
      "The training loss at 939th epoch : 229.9999996429483  Training Accuracy:0.500542888165038\n",
      "The training loss at 940th epoch : 229.99999964294824  Training Accuracy:0.500542888165038\n",
      "The training loss at 941th epoch : 229.9999996429482  Training Accuracy:0.500542888165038\n",
      "The training loss at 942th epoch : 229.99999964294815  Training Accuracy:0.500542888165038\n",
      "The training loss at 943th epoch : 229.99999964294813  Training Accuracy:0.500542888165038\n",
      "The training loss at 944th epoch : 229.99999964294807  Training Accuracy:0.500542888165038\n",
      "The training loss at 945th epoch : 229.999999642948  Training Accuracy:0.500542888165038\n",
      "The training loss at 946th epoch : 229.99999964294798  Training Accuracy:0.500542888165038\n",
      "The training loss at 947th epoch : 229.99999964294796  Training Accuracy:0.500542888165038\n",
      "The training loss at 948th epoch : 229.9999996429479  Training Accuracy:0.500542888165038\n",
      "The training loss at 949th epoch : 229.99999964294787  Training Accuracy:0.500542888165038\n",
      "The training loss at 950th epoch : 229.9999996429478  Training Accuracy:0.500542888165038\n",
      "The training loss at 951th epoch : 229.99999964294778  Training Accuracy:0.500542888165038\n",
      "The training loss at 952th epoch : 229.99999964294773  Training Accuracy:0.500542888165038\n",
      "The training loss at 953th epoch : 229.9999996429477  Training Accuracy:0.500542888165038\n",
      "The training loss at 954th epoch : 229.99999964294764  Training Accuracy:0.500542888165038\n",
      "The training loss at 955th epoch : 229.9999996429476  Training Accuracy:0.500542888165038\n",
      "The training loss at 956th epoch : 229.99999964294756  Training Accuracy:0.500542888165038\n",
      "The training loss at 957th epoch : 229.99999964294753  Training Accuracy:0.500542888165038\n",
      "The training loss at 958th epoch : 229.99999964294747  Training Accuracy:0.500542888165038\n",
      "The training loss at 959th epoch : 229.99999964294742  Training Accuracy:0.500542888165038\n",
      "The training loss at 960th epoch : 229.9999996429474  Training Accuracy:0.500542888165038\n",
      "The training loss at 961th epoch : 229.99999964294733  Training Accuracy:0.500542888165038\n",
      "The training loss at 962th epoch : 229.9999996429473  Training Accuracy:0.500542888165038\n",
      "The training loss at 963th epoch : 229.99999964294724  Training Accuracy:0.500542888165038\n",
      "The training loss at 964th epoch : 229.99999964294722  Training Accuracy:0.500542888165038\n",
      "The training loss at 965th epoch : 229.99999964294716  Training Accuracy:0.500542888165038\n",
      "The training loss at 966th epoch : 229.9999996429471  Training Accuracy:0.500542888165038\n",
      "The training loss at 967th epoch : 229.9999996429471  Training Accuracy:0.500542888165038\n",
      "The training loss at 968th epoch : 229.99999964294705  Training Accuracy:0.500542888165038\n",
      "The training loss at 969th epoch : 229.999999642947  Training Accuracy:0.500542888165038\n",
      "The training loss at 970th epoch : 229.99999964294696  Training Accuracy:0.500542888165038\n",
      "The training loss at 971th epoch : 229.99999964294693  Training Accuracy:0.500542888165038\n",
      "The training loss at 972th epoch : 229.99999964294688  Training Accuracy:0.500542888165038\n",
      "The training loss at 973th epoch : 229.99999964294682  Training Accuracy:0.500542888165038\n",
      "The training loss at 974th epoch : 229.9999996429468  Training Accuracy:0.500542888165038\n",
      "The training loss at 975th epoch : 229.9999996429467  Training Accuracy:0.500542888165038\n",
      "The training loss at 976th epoch : 229.9999996429467  Training Accuracy:0.500542888165038\n",
      "The training loss at 977th epoch : 229.99999964294665  Training Accuracy:0.500542888165038\n",
      "The training loss at 978th epoch : 229.99999964294662  Training Accuracy:0.500542888165038\n",
      "The training loss at 979th epoch : 229.99999964294656  Training Accuracy:0.500542888165038\n",
      "The training loss at 980th epoch : 229.99999964294653  Training Accuracy:0.500542888165038\n",
      "The training loss at 981th epoch : 229.99999964294648  Training Accuracy:0.500542888165038\n",
      "The training loss at 982th epoch : 229.99999964294642  Training Accuracy:0.500542888165038\n",
      "The training loss at 983th epoch : 229.99999964294636  Training Accuracy:0.500542888165038\n",
      "The training loss at 984th epoch : 229.99999964294634  Training Accuracy:0.500542888165038\n",
      "The training loss at 985th epoch : 229.9999996429463  Training Accuracy:0.500542888165038\n",
      "The training loss at 986th epoch : 229.99999964294625  Training Accuracy:0.500542888165038\n",
      "The training loss at 987th epoch : 229.99999964294622  Training Accuracy:0.500542888165038\n",
      "The training loss at 988th epoch : 229.99999964294616  Training Accuracy:0.500542888165038\n",
      "The training loss at 989th epoch : 229.99999964294614  Training Accuracy:0.500542888165038\n",
      "The training loss at 990th epoch : 229.99999964294608  Training Accuracy:0.500542888165038\n",
      "The training loss at 991th epoch : 229.99999964294602  Training Accuracy:0.500542888165038\n",
      "The training loss at 992th epoch : 229.99999964294602  Training Accuracy:0.500542888165038\n",
      "The training loss at 993th epoch : 229.99999964294597  Training Accuracy:0.500542888165038\n",
      "The training loss at 994th epoch : 229.9999996429459  Training Accuracy:0.500542888165038\n",
      "The training loss at 995th epoch : 229.99999964294588  Training Accuracy:0.500542888165038\n",
      "The training loss at 996th epoch : 229.99999964294585  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 997th epoch : 229.9999996429458  Training Accuracy:0.500542888165038\n",
      "The training loss at 998th epoch : 229.99999964294574  Training Accuracy:0.500542888165038\n",
      "The training loss at 999th epoch : 229.9999996429457  Training Accuracy:0.500542888165038\n",
      "The training loss at 1000th epoch : 229.99999964294565  Training Accuracy:0.500542888165038\n",
      "The training loss at 1001th epoch : 229.99999964294562  Training Accuracy:0.500542888165038\n",
      "The training loss at 1002th epoch : 229.99999964294557  Training Accuracy:0.500542888165038\n",
      "The training loss at 1003th epoch : 229.9999996429455  Training Accuracy:0.500542888165038\n",
      "The training loss at 1004th epoch : 229.99999964294548  Training Accuracy:0.500542888165038\n",
      "The training loss at 1005th epoch : 229.99999964294545  Training Accuracy:0.500542888165038\n",
      "The training loss at 1006th epoch : 229.9999996429454  Training Accuracy:0.500542888165038\n",
      "The training loss at 1007th epoch : 229.99999964294534  Training Accuracy:0.500542888165038\n",
      "The training loss at 1008th epoch : 229.9999996429453  Training Accuracy:0.500542888165038\n",
      "The training loss at 1009th epoch : 229.99999964294526  Training Accuracy:0.500542888165038\n",
      "The training loss at 1010th epoch : 229.99999964294523  Training Accuracy:0.500542888165038\n",
      "The training loss at 1011th epoch : 229.99999964294517  Training Accuracy:0.500542888165038\n",
      "The training loss at 1012th epoch : 229.9999996429451  Training Accuracy:0.500542888165038\n",
      "The training loss at 1013th epoch : 229.99999964294508  Training Accuracy:0.500542888165038\n",
      "The training loss at 1014th epoch : 229.99999964294506  Training Accuracy:0.500542888165038\n",
      "The training loss at 1015th epoch : 229.999999642945  Training Accuracy:0.500542888165038\n",
      "The training loss at 1016th epoch : 229.99999964294497  Training Accuracy:0.500542888165038\n",
      "The training loss at 1017th epoch : 229.9999996429449  Training Accuracy:0.500542888165038\n",
      "The training loss at 1018th epoch : 229.99999964294489  Training Accuracy:0.500542888165038\n",
      "The training loss at 1019th epoch : 229.99999964294483  Training Accuracy:0.500542888165038\n",
      "The training loss at 1020th epoch : 229.9999996429448  Training Accuracy:0.500542888165038\n",
      "The training loss at 1021th epoch : 229.99999964294474  Training Accuracy:0.500542888165038\n",
      "The training loss at 1022th epoch : 229.99999964294472  Training Accuracy:0.500542888165038\n",
      "The training loss at 1023th epoch : 229.99999964294466  Training Accuracy:0.500542888165038\n",
      "The training loss at 1024th epoch : 229.9999996429446  Training Accuracy:0.500542888165038\n",
      "The training loss at 1025th epoch : 229.99999964294457  Training Accuracy:0.500542888165038\n",
      "The training loss at 1026th epoch : 229.99999964294454  Training Accuracy:0.500542888165038\n",
      "The training loss at 1027th epoch : 229.9999996429445  Training Accuracy:0.500542888165038\n",
      "The training loss at 1028th epoch : 229.99999964294443  Training Accuracy:0.500542888165038\n",
      "The training loss at 1029th epoch : 229.99999964294437  Training Accuracy:0.500542888165038\n",
      "The training loss at 1030th epoch : 229.99999964294435  Training Accuracy:0.500542888165038\n",
      "The training loss at 1031th epoch : 229.99999964294432  Training Accuracy:0.500542888165038\n",
      "The training loss at 1032th epoch : 229.99999964294426  Training Accuracy:0.500542888165038\n",
      "The training loss at 1033th epoch : 229.9999996429442  Training Accuracy:0.500542888165038\n",
      "The training loss at 1034th epoch : 229.9999996429442  Training Accuracy:0.500542888165038\n",
      "The training loss at 1035th epoch : 229.99999964294412  Training Accuracy:0.500542888165038\n",
      "The training loss at 1036th epoch : 229.9999996429441  Training Accuracy:0.500542888165038\n",
      "The training loss at 1037th epoch : 229.99999964294403  Training Accuracy:0.500542888165038\n",
      "The training loss at 1038th epoch : 229.999999642944  Training Accuracy:0.500542888165038\n",
      "The training loss at 1039th epoch : 229.99999964294398  Training Accuracy:0.500542888165038\n",
      "The training loss at 1040th epoch : 229.99999964294392  Training Accuracy:0.500542888165038\n",
      "The training loss at 1041th epoch : 229.99999964294386  Training Accuracy:0.500542888165038\n",
      "The training loss at 1042th epoch : 229.99999964294383  Training Accuracy:0.500542888165038\n",
      "The training loss at 1043th epoch : 229.9999996429438  Training Accuracy:0.500542888165038\n",
      "The training loss at 1044th epoch : 229.99999964294375  Training Accuracy:0.500542888165038\n",
      "The training loss at 1045th epoch : 229.9999996429437  Training Accuracy:0.500542888165038\n",
      "The training loss at 1046th epoch : 229.99999964294366  Training Accuracy:0.500542888165038\n",
      "The training loss at 1047th epoch : 229.99999964294364  Training Accuracy:0.500542888165038\n",
      "The training loss at 1048th epoch : 229.99999964294358  Training Accuracy:0.500542888165038\n",
      "The training loss at 1049th epoch : 229.99999964294352  Training Accuracy:0.500542888165038\n",
      "The training loss at 1050th epoch : 229.9999996429435  Training Accuracy:0.500542888165038\n",
      "The training loss at 1051th epoch : 229.99999964294346  Training Accuracy:0.500542888165038\n",
      "The training loss at 1052th epoch : 229.9999996429434  Training Accuracy:0.500542888165038\n",
      "The training loss at 1053th epoch : 229.99999964294335  Training Accuracy:0.500542888165038\n",
      "The training loss at 1054th epoch : 229.9999996429433  Training Accuracy:0.500542888165038\n",
      "The training loss at 1055th epoch : 229.9999996429433  Training Accuracy:0.500542888165038\n",
      "The training loss at 1056th epoch : 229.99999964294324  Training Accuracy:0.500542888165038\n",
      "The training loss at 1057th epoch : 229.99999964294318  Training Accuracy:0.500542888165038\n",
      "The training loss at 1058th epoch : 229.99999964294312  Training Accuracy:0.500542888165038\n",
      "The training loss at 1059th epoch : 229.9999996429431  Training Accuracy:0.500542888165038\n",
      "The training loss at 1060th epoch : 229.99999964294304  Training Accuracy:0.500542888165038\n",
      "The training loss at 1061th epoch : 229.999999642943  Training Accuracy:0.500542888165038\n",
      "The training loss at 1062th epoch : 229.99999964294295  Training Accuracy:0.500542888165038\n",
      "The training loss at 1063th epoch : 229.99999964294292  Training Accuracy:0.500542888165038\n",
      "The training loss at 1064th epoch : 229.9999996429429  Training Accuracy:0.500542888165038\n",
      "The training loss at 1065th epoch : 229.99999964294284  Training Accuracy:0.500542888165038\n",
      "The training loss at 1066th epoch : 229.9999996429428  Training Accuracy:0.500542888165038\n",
      "The training loss at 1067th epoch : 229.99999964294275  Training Accuracy:0.500542888165038\n",
      "The training loss at 1068th epoch : 229.99999964294273  Training Accuracy:0.500542888165038\n",
      "The training loss at 1069th epoch : 229.99999964294267  Training Accuracy:0.500542888165038\n",
      "The training loss at 1070th epoch : 229.9999996429426  Training Accuracy:0.500542888165038\n",
      "The training loss at 1071th epoch : 229.99999964294258  Training Accuracy:0.500542888165038\n",
      "The training loss at 1072th epoch : 229.99999964294253  Training Accuracy:0.500542888165038\n",
      "The training loss at 1073th epoch : 229.9999996429425  Training Accuracy:0.500542888165038\n",
      "The training loss at 1074th epoch : 229.99999964294244  Training Accuracy:0.500542888165038\n",
      "The training loss at 1075th epoch : 229.99999964294238  Training Accuracy:0.500542888165038\n",
      "The training loss at 1076th epoch : 229.99999964294236  Training Accuracy:0.500542888165038\n",
      "The training loss at 1077th epoch : 229.99999964294233  Training Accuracy:0.500542888165038\n",
      "The training loss at 1078th epoch : 229.99999964294227  Training Accuracy:0.500542888165038\n",
      "The training loss at 1079th epoch : 229.99999964294224  Training Accuracy:0.500542888165038\n",
      "The training loss at 1080th epoch : 229.9999996429422  Training Accuracy:0.500542888165038\n",
      "The training loss at 1081th epoch : 229.99999964294216  Training Accuracy:0.500542888165038\n",
      "The training loss at 1082th epoch : 229.9999996429421  Training Accuracy:0.500542888165038\n",
      "The training loss at 1083th epoch : 229.99999964294204  Training Accuracy:0.500542888165038\n",
      "The training loss at 1084th epoch : 229.99999964294204  Training Accuracy:0.500542888165038\n",
      "The training loss at 1085th epoch : 229.999999642942  Training Accuracy:0.500542888165038\n",
      "The training loss at 1086th epoch : 229.99999964294193  Training Accuracy:0.500542888165038\n",
      "The training loss at 1087th epoch : 229.9999996429419  Training Accuracy:0.500542888165038\n",
      "The training loss at 1088th epoch : 229.99999964294184  Training Accuracy:0.500542888165038\n",
      "The training loss at 1089th epoch : 229.99999964294182  Training Accuracy:0.500542888165038\n",
      "The training loss at 1090th epoch : 229.99999964294176  Training Accuracy:0.500542888165038\n",
      "The training loss at 1091th epoch : 229.99999964294173  Training Accuracy:0.500542888165038\n",
      "The training loss at 1092th epoch : 229.99999964294167  Training Accuracy:0.500542888165038\n",
      "The training loss at 1093th epoch : 229.99999964294165  Training Accuracy:0.500542888165038\n",
      "The training loss at 1094th epoch : 229.9999996429416  Training Accuracy:0.500542888165038\n",
      "The training loss at 1095th epoch : 229.99999964294153  Training Accuracy:0.500542888165038\n",
      "The training loss at 1096th epoch : 229.9999996429415  Training Accuracy:0.500542888165038\n",
      "The training loss at 1097th epoch : 229.99999964294145  Training Accuracy:0.500542888165038\n",
      "The training loss at 1098th epoch : 229.99999964294142  Training Accuracy:0.500542888165038\n",
      "The training loss at 1099th epoch : 229.99999964294136  Training Accuracy:0.500542888165038\n",
      "The training loss at 1100th epoch : 229.99999964294133  Training Accuracy:0.500542888165038\n",
      "The training loss at 1101th epoch : 229.9999996429413  Training Accuracy:0.500542888165038\n",
      "The training loss at 1102th epoch : 229.99999964294122  Training Accuracy:0.500542888165038\n",
      "The training loss at 1103th epoch : 229.9999996429412  Training Accuracy:0.500542888165038\n",
      "The training loss at 1104th epoch : 229.99999964294113  Training Accuracy:0.500542888165038\n",
      "The training loss at 1105th epoch : 229.99999964294113  Training Accuracy:0.500542888165038\n",
      "The training loss at 1106th epoch : 229.99999964294108  Training Accuracy:0.500542888165038\n",
      "The training loss at 1107th epoch : 229.99999964294102  Training Accuracy:0.500542888165038\n",
      "The training loss at 1108th epoch : 229.999999642941  Training Accuracy:0.500542888165038\n",
      "The training loss at 1109th epoch : 229.99999964294094  Training Accuracy:0.500542888165038\n",
      "The training loss at 1110th epoch : 229.9999996429409  Training Accuracy:0.500542888165038\n",
      "The training loss at 1111th epoch : 229.99999964294085  Training Accuracy:0.500542888165038\n",
      "The training loss at 1112th epoch : 229.99999964294082  Training Accuracy:0.500542888165038\n",
      "The training loss at 1113th epoch : 229.99999964294076  Training Accuracy:0.500542888165038\n",
      "The training loss at 1114th epoch : 229.99999964294074  Training Accuracy:0.500542888165038\n",
      "The training loss at 1115th epoch : 229.99999964294068  Training Accuracy:0.500542888165038\n",
      "The training loss at 1116th epoch : 229.99999964294062  Training Accuracy:0.500542888165038\n",
      "The training loss at 1117th epoch : 229.9999996429406  Training Accuracy:0.500542888165038\n",
      "The training loss at 1118th epoch : 229.99999964294057  Training Accuracy:0.500542888165038\n",
      "The training loss at 1119th epoch : 229.9999996429405  Training Accuracy:0.500542888165038\n",
      "The training loss at 1120th epoch : 229.99999964294045  Training Accuracy:0.500542888165038\n",
      "The training loss at 1121th epoch : 229.9999996429404  Training Accuracy:0.500542888165038\n",
      "The training loss at 1122th epoch : 229.99999964294037  Training Accuracy:0.500542888165038\n",
      "The training loss at 1123th epoch : 229.9999996429403  Training Accuracy:0.500542888165038\n",
      "The training loss at 1124th epoch : 229.99999964294028  Training Accuracy:0.500542888165038\n",
      "The training loss at 1125th epoch : 229.99999964294022  Training Accuracy:0.500542888165038\n",
      "The training loss at 1126th epoch : 229.99999964294022  Training Accuracy:0.500542888165038\n",
      "The training loss at 1127th epoch : 229.99999964294017  Training Accuracy:0.500542888165038\n",
      "The training loss at 1128th epoch : 229.9999996429401  Training Accuracy:0.500542888165038\n",
      "The training loss at 1129th epoch : 229.99999964294008  Training Accuracy:0.500542888165038\n",
      "The training loss at 1130th epoch : 229.99999964294005  Training Accuracy:0.500542888165038\n",
      "The training loss at 1131th epoch : 229.99999964294  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 1132th epoch : 229.99999964293994  Training Accuracy:0.500542888165038\n",
      "The training loss at 1133th epoch : 229.99999964293988  Training Accuracy:0.500542888165038\n",
      "The training loss at 1134th epoch : 229.99999964293983  Training Accuracy:0.500542888165038\n",
      "The training loss at 1135th epoch : 229.99999964293983  Training Accuracy:0.500542888165038\n",
      "The training loss at 1136th epoch : 229.99999964293977  Training Accuracy:0.500542888165038\n",
      "The training loss at 1137th epoch : 229.9999996429397  Training Accuracy:0.500542888165038\n",
      "The training loss at 1138th epoch : 229.99999964293966  Training Accuracy:0.500542888165038\n",
      "The training loss at 1139th epoch : 229.99999964293966  Training Accuracy:0.500542888165038\n",
      "The training loss at 1140th epoch : 229.9999996429396  Training Accuracy:0.500542888165038\n",
      "The training loss at 1141th epoch : 229.99999964293954  Training Accuracy:0.500542888165038\n",
      "The training loss at 1142th epoch : 229.9999996429395  Training Accuracy:0.500542888165038\n",
      "The training loss at 1143th epoch : 229.99999964293946  Training Accuracy:0.500542888165038\n",
      "The training loss at 1144th epoch : 229.99999964293943  Training Accuracy:0.500542888165038\n",
      "The training loss at 1145th epoch : 229.99999964293937  Training Accuracy:0.500542888165038\n",
      "The training loss at 1146th epoch : 229.99999964293931  Training Accuracy:0.500542888165038\n",
      "The training loss at 1147th epoch : 229.9999996429393  Training Accuracy:0.500542888165038\n",
      "The training loss at 1148th epoch : 229.99999964293926  Training Accuracy:0.500542888165038\n",
      "The training loss at 1149th epoch : 229.9999996429392  Training Accuracy:0.500542888165038\n",
      "The training loss at 1150th epoch : 229.99999964293914  Training Accuracy:0.500542888165038\n",
      "The training loss at 1151th epoch : 229.99999964293914  Training Accuracy:0.500542888165038\n",
      "The training loss at 1152th epoch : 229.9999996429391  Training Accuracy:0.500542888165038\n",
      "The training loss at 1153th epoch : 229.99999964293903  Training Accuracy:0.500542888165038\n",
      "The training loss at 1154th epoch : 229.999999642939  Training Accuracy:0.500542888165038\n",
      "The training loss at 1155th epoch : 229.99999964293892  Training Accuracy:0.500542888165038\n",
      "The training loss at 1156th epoch : 229.99999964293892  Training Accuracy:0.500542888165038\n",
      "The training loss at 1157th epoch : 229.99999964293886  Training Accuracy:0.500542888165038\n",
      "The training loss at 1158th epoch : 229.9999996429388  Training Accuracy:0.500542888165038\n",
      "The training loss at 1159th epoch : 229.99999964293877  Training Accuracy:0.500542888165038\n",
      "The training loss at 1160th epoch : 229.99999964293875  Training Accuracy:0.500542888165038\n",
      "The training loss at 1161th epoch : 229.9999996429387  Training Accuracy:0.500542888165038\n",
      "The training loss at 1162th epoch : 229.99999964293863  Training Accuracy:0.500542888165038\n",
      "The training loss at 1163th epoch : 229.9999996429386  Training Accuracy:0.500542888165038\n",
      "The training loss at 1164th epoch : 229.99999964293855  Training Accuracy:0.500542888165038\n",
      "The training loss at 1165th epoch : 229.99999964293852  Training Accuracy:0.500542888165038\n",
      "The training loss at 1166th epoch : 229.99999964293846  Training Accuracy:0.500542888165038\n",
      "The training loss at 1167th epoch : 229.9999996429384  Training Accuracy:0.500542888165038\n",
      "The training loss at 1168th epoch : 229.99999964293838  Training Accuracy:0.500542888165038\n",
      "The training loss at 1169th epoch : 229.99999964293835  Training Accuracy:0.500542888165038\n",
      "The training loss at 1170th epoch : 229.9999996429383  Training Accuracy:0.500542888165038\n",
      "The training loss at 1171th epoch : 229.99999964293823  Training Accuracy:0.500542888165038\n",
      "The training loss at 1172th epoch : 229.9999996429382  Training Accuracy:0.500542888165038\n",
      "The training loss at 1173th epoch : 229.99999964293818  Training Accuracy:0.500542888165038\n",
      "The training loss at 1174th epoch : 229.99999964293812  Training Accuracy:0.500542888165038\n",
      "The training loss at 1175th epoch : 229.9999996429381  Training Accuracy:0.500542888165038\n",
      "The training loss at 1176th epoch : 229.99999964293806  Training Accuracy:0.500542888165038\n",
      "The training loss at 1177th epoch : 229.999999642938  Training Accuracy:0.500542888165038\n",
      "The training loss at 1178th epoch : 229.99999964293795  Training Accuracy:0.500542888165038\n",
      "The training loss at 1179th epoch : 229.99999964293792  Training Accuracy:0.500542888165038\n",
      "The training loss at 1180th epoch : 229.99999964293787  Training Accuracy:0.500542888165038\n",
      "The training loss at 1181th epoch : 229.99999964293784  Training Accuracy:0.500542888165038\n",
      "The training loss at 1182th epoch : 229.99999964293778  Training Accuracy:0.500542888165038\n",
      "The training loss at 1183th epoch : 229.99999964293772  Training Accuracy:0.500542888165038\n",
      "The training loss at 1184th epoch : 229.9999996429377  Training Accuracy:0.500542888165038\n",
      "The training loss at 1185th epoch : 229.99999964293764  Training Accuracy:0.500542888165038\n",
      "The training loss at 1186th epoch : 229.9999996429376  Training Accuracy:0.500542888165038\n",
      "The training loss at 1187th epoch : 229.99999964293755  Training Accuracy:0.500542888165038\n",
      "The training loss at 1188th epoch : 229.9999996429375  Training Accuracy:0.500542888165038\n",
      "The training loss at 1189th epoch : 229.9999996429375  Training Accuracy:0.500542888165038\n",
      "The training loss at 1190th epoch : 229.99999964293744  Training Accuracy:0.500542888165038\n",
      "The training loss at 1191th epoch : 229.99999964293738  Training Accuracy:0.500542888165038\n",
      "The training loss at 1192th epoch : 229.99999964293733  Training Accuracy:0.500542888165038\n",
      "The training loss at 1193th epoch : 229.99999964293733  Training Accuracy:0.500542888165038\n",
      "The training loss at 1194th epoch : 229.99999964293727  Training Accuracy:0.500542888165038\n",
      "The training loss at 1195th epoch : 229.9999996429372  Training Accuracy:0.500542888165038\n",
      "The training loss at 1196th epoch : 229.99999964293715  Training Accuracy:0.500542888165038\n",
      "The training loss at 1197th epoch : 229.99999964293713  Training Accuracy:0.500542888165038\n",
      "The training loss at 1198th epoch : 229.9999996429371  Training Accuracy:0.500542888165038\n",
      "The training loss at 1199th epoch : 229.99999964293704  Training Accuracy:0.500542888165038\n",
      "The training loss at 1200th epoch : 229.99999964293698  Training Accuracy:0.500542888165038\n",
      "The training loss at 1201th epoch : 229.99999964293696  Training Accuracy:0.500542888165038\n",
      "The training loss at 1202th epoch : 229.99999964293693  Training Accuracy:0.500542888165038\n",
      "The training loss at 1203th epoch : 229.99999964293687  Training Accuracy:0.500542888165038\n",
      "The training loss at 1204th epoch : 229.9999996429368  Training Accuracy:0.500542888165038\n",
      "The training loss at 1205th epoch : 229.99999964293679  Training Accuracy:0.500542888165038\n",
      "The training loss at 1206th epoch : 229.99999964293676  Training Accuracy:0.500542888165038\n",
      "The training loss at 1207th epoch : 229.9999996429367  Training Accuracy:0.500542888165038\n",
      "The training loss at 1208th epoch : 229.99999964293664  Training Accuracy:0.500542888165038\n",
      "The training loss at 1209th epoch : 229.99999964293661  Training Accuracy:0.500542888165038\n",
      "The training loss at 1210th epoch : 229.99999964293656  Training Accuracy:0.500542888165038\n",
      "The training loss at 1211th epoch : 229.99999964293653  Training Accuracy:0.500542888165038\n",
      "The training loss at 1212th epoch : 229.99999964293647  Training Accuracy:0.500542888165038\n",
      "The training loss at 1213th epoch : 229.99999964293642  Training Accuracy:0.500542888165038\n",
      "The training loss at 1214th epoch : 229.99999964293642  Training Accuracy:0.500542888165038\n",
      "The training loss at 1215th epoch : 229.99999964293633  Training Accuracy:0.500542888165038\n",
      "The training loss at 1216th epoch : 229.9999996429363  Training Accuracy:0.500542888165038\n",
      "The training loss at 1217th epoch : 229.99999964293625  Training Accuracy:0.500542888165038\n",
      "The training loss at 1218th epoch : 229.99999964293622  Training Accuracy:0.500542888165038\n",
      "The training loss at 1219th epoch : 229.9999996429362  Training Accuracy:0.500542888165038\n",
      "The training loss at 1220th epoch : 229.99999964293613  Training Accuracy:0.500542888165038\n",
      "The training loss at 1221th epoch : 229.99999964293607  Training Accuracy:0.500542888165038\n",
      "The training loss at 1222th epoch : 229.99999964293607  Training Accuracy:0.500542888165038\n",
      "The training loss at 1223th epoch : 229.99999964293602  Training Accuracy:0.500542888165038\n",
      "The training loss at 1224th epoch : 229.99999964293596  Training Accuracy:0.500542888165038\n",
      "The training loss at 1225th epoch : 229.99999964293593  Training Accuracy:0.500542888165038\n",
      "The training loss at 1226th epoch : 229.99999964293588  Training Accuracy:0.500542888165038\n",
      "The training loss at 1227th epoch : 229.99999964293585  Training Accuracy:0.500542888165038\n",
      "The training loss at 1228th epoch : 229.9999996429358  Training Accuracy:0.500542888165038\n",
      "The training loss at 1229th epoch : 229.99999964293573  Training Accuracy:0.500542888165038\n",
      "The training loss at 1230th epoch : 229.9999996429357  Training Accuracy:0.500542888165038\n",
      "The training loss at 1231th epoch : 229.99999964293568  Training Accuracy:0.500542888165038\n",
      "The training loss at 1232th epoch : 229.99999964293562  Training Accuracy:0.500542888165038\n",
      "The training loss at 1233th epoch : 229.99999964293556  Training Accuracy:0.500542888165038\n",
      "The training loss at 1234th epoch : 229.9999996429355  Training Accuracy:0.500542888165038\n",
      "The training loss at 1235th epoch : 229.9999996429355  Training Accuracy:0.500542888165038\n",
      "The training loss at 1236th epoch : 229.99999964293545  Training Accuracy:0.500542888165038\n",
      "The training loss at 1237th epoch : 229.9999996429354  Training Accuracy:0.500542888165038\n",
      "The training loss at 1238th epoch : 229.99999964293534  Training Accuracy:0.500542888165038\n",
      "The training loss at 1239th epoch : 229.99999964293534  Training Accuracy:0.500542888165038\n",
      "The training loss at 1240th epoch : 229.99999964293528  Training Accuracy:0.500542888165038\n",
      "The training loss at 1241th epoch : 229.99999964293522  Training Accuracy:0.500542888165038\n",
      "The training loss at 1242th epoch : 229.99999964293517  Training Accuracy:0.500542888165038\n",
      "The training loss at 1243th epoch : 229.99999964293514  Training Accuracy:0.500542888165038\n",
      "The training loss at 1244th epoch : 229.9999996429351  Training Accuracy:0.500542888165038\n",
      "The training loss at 1245th epoch : 229.99999964293505  Training Accuracy:0.500542888165038\n",
      "The training loss at 1246th epoch : 229.999999642935  Training Accuracy:0.500542888165038\n",
      "The training loss at 1247th epoch : 229.99999964293497  Training Accuracy:0.500542888165038\n",
      "The training loss at 1248th epoch : 229.99999964293494  Training Accuracy:0.500542888165038\n",
      "The training loss at 1249th epoch : 229.99999964293488  Training Accuracy:0.500542888165038\n",
      "The training loss at 1250th epoch : 229.99999964293482  Training Accuracy:0.500542888165038\n",
      "The training loss at 1251th epoch : 229.9999996429348  Training Accuracy:0.500542888165038\n",
      "The training loss at 1252th epoch : 229.99999964293474  Training Accuracy:0.500542888165038\n",
      "The training loss at 1253th epoch : 229.9999996429347  Training Accuracy:0.500542888165038\n",
      "The training loss at 1254th epoch : 229.99999964293465  Training Accuracy:0.500542888165038\n",
      "The training loss at 1255th epoch : 229.99999964293465  Training Accuracy:0.500542888165038\n",
      "The training loss at 1256th epoch : 229.99999964293457  Training Accuracy:0.500542888165038\n",
      "The training loss at 1257th epoch : 229.99999964293454  Training Accuracy:0.500542888165038\n",
      "The training loss at 1258th epoch : 229.99999964293448  Training Accuracy:0.500542888165038\n",
      "The training loss at 1259th epoch : 229.99999964293445  Training Accuracy:0.500542888165038\n",
      "The training loss at 1260th epoch : 229.9999996429344  Training Accuracy:0.500542888165038\n",
      "The training loss at 1261th epoch : 229.99999964293437  Training Accuracy:0.500542888165038\n",
      "The training loss at 1262th epoch : 229.9999996429343  Training Accuracy:0.500542888165038\n",
      "The training loss at 1263th epoch : 229.99999964293426  Training Accuracy:0.500542888165038\n",
      "The training loss at 1264th epoch : 229.99999964293426  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 1265th epoch : 229.9999996429342  Training Accuracy:0.500542888165038\n",
      "The training loss at 1266th epoch : 229.99999964293414  Training Accuracy:0.500542888165038\n",
      "The training loss at 1267th epoch : 229.9999996429341  Training Accuracy:0.500542888165038\n",
      "The training loss at 1268th epoch : 229.99999964293406  Training Accuracy:0.500542888165038\n",
      "The training loss at 1269th epoch : 229.99999964293403  Training Accuracy:0.500542888165038\n",
      "The training loss at 1270th epoch : 229.99999964293397  Training Accuracy:0.500542888165038\n",
      "The training loss at 1271th epoch : 229.99999964293391  Training Accuracy:0.500542888165038\n",
      "The training loss at 1272th epoch : 229.9999996429339  Training Accuracy:0.500542888165038\n",
      "The training loss at 1273th epoch : 229.99999964293386  Training Accuracy:0.500542888165038\n",
      "The training loss at 1274th epoch : 229.9999996429338  Training Accuracy:0.500542888165038\n",
      "The training loss at 1275th epoch : 229.99999964293374  Training Accuracy:0.500542888165038\n",
      "The training loss at 1276th epoch : 229.99999964293374  Training Accuracy:0.500542888165038\n",
      "The training loss at 1277th epoch : 229.99999964293366  Training Accuracy:0.500542888165038\n",
      "The training loss at 1278th epoch : 229.99999964293363  Training Accuracy:0.500542888165038\n",
      "The training loss at 1279th epoch : 229.99999964293357  Training Accuracy:0.500542888165038\n",
      "The training loss at 1280th epoch : 229.99999964293352  Training Accuracy:0.500542888165038\n",
      "The training loss at 1281th epoch : 229.99999964293346  Training Accuracy:0.500542888165038\n",
      "The training loss at 1282th epoch : 229.99999964293343  Training Accuracy:0.500542888165038\n",
      "The training loss at 1283th epoch : 229.9999996429334  Training Accuracy:0.500542888165038\n",
      "The training loss at 1284th epoch : 229.99999964293335  Training Accuracy:0.500542888165038\n",
      "The training loss at 1285th epoch : 229.99999964293332  Training Accuracy:0.500542888165038\n",
      "The training loss at 1286th epoch : 229.99999964293326  Training Accuracy:0.500542888165038\n",
      "The training loss at 1287th epoch : 229.99999964293323  Training Accuracy:0.500542888165038\n",
      "The training loss at 1288th epoch : 229.9999996429332  Training Accuracy:0.500542888165038\n",
      "The training loss at 1289th epoch : 229.99999964293318  Training Accuracy:0.500542888165038\n",
      "The training loss at 1290th epoch : 229.99999964293312  Training Accuracy:0.500542888165038\n",
      "The training loss at 1291th epoch : 229.99999964293306  Training Accuracy:0.500542888165038\n",
      "The training loss at 1292th epoch : 229.999999642933  Training Accuracy:0.500542888165038\n",
      "The training loss at 1293th epoch : 229.99999964293298  Training Accuracy:0.500542888165038\n",
      "The training loss at 1294th epoch : 229.99999964293295  Training Accuracy:0.500542888165038\n",
      "The training loss at 1295th epoch : 229.9999996429329  Training Accuracy:0.500542888165038\n",
      "The training loss at 1296th epoch : 229.99999964293283  Training Accuracy:0.500542888165038\n",
      "The training loss at 1297th epoch : 229.99999964293283  Training Accuracy:0.500542888165038\n",
      "The training loss at 1298th epoch : 229.99999964293275  Training Accuracy:0.500542888165038\n",
      "The training loss at 1299th epoch : 229.99999964293272  Training Accuracy:0.500542888165038\n",
      "The training loss at 1300th epoch : 229.99999964293266  Training Accuracy:0.500542888165038\n",
      "The training loss at 1301th epoch : 229.9999996429326  Training Accuracy:0.500542888165038\n",
      "The training loss at 1302th epoch : 229.99999964293258  Training Accuracy:0.500542888165038\n",
      "The training loss at 1303th epoch : 229.99999964293252  Training Accuracy:0.500542888165038\n",
      "The training loss at 1304th epoch : 229.9999996429325  Training Accuracy:0.500542888165038\n",
      "The training loss at 1305th epoch : 229.99999964293244  Training Accuracy:0.500542888165038\n",
      "The training loss at 1306th epoch : 229.99999964293244  Training Accuracy:0.500542888165038\n",
      "The training loss at 1307th epoch : 229.99999964293238  Training Accuracy:0.500542888165038\n",
      "The training loss at 1308th epoch : 229.99999964293232  Training Accuracy:0.500542888165038\n",
      "The training loss at 1309th epoch : 229.99999964293227  Training Accuracy:0.500542888165038\n",
      "The training loss at 1310th epoch : 229.99999964293224  Training Accuracy:0.500542888165038\n",
      "The training loss at 1311th epoch : 229.99999964293218  Training Accuracy:0.500542888165038\n",
      "The training loss at 1312th epoch : 229.99999964293215  Training Accuracy:0.500542888165038\n",
      "The training loss at 1313th epoch : 229.99999964293212  Training Accuracy:0.500542888165038\n",
      "The training loss at 1314th epoch : 229.99999964293207  Training Accuracy:0.500542888165038\n",
      "The training loss at 1315th epoch : 229.999999642932  Training Accuracy:0.500542888165038\n",
      "The training loss at 1316th epoch : 229.99999964293198  Training Accuracy:0.500542888165038\n",
      "The training loss at 1317th epoch : 229.99999964293193  Training Accuracy:0.500542888165038\n",
      "The training loss at 1318th epoch : 229.9999996429319  Training Accuracy:0.500542888165038\n",
      "The training loss at 1319th epoch : 229.99999964293187  Training Accuracy:0.500542888165038\n",
      "The training loss at 1320th epoch : 229.9999996429318  Training Accuracy:0.500542888165038\n",
      "The training loss at 1321th epoch : 229.99999964293175  Training Accuracy:0.500542888165038\n",
      "The training loss at 1322th epoch : 229.9999996429317  Training Accuracy:0.500542888165038\n",
      "The training loss at 1323th epoch : 229.99999964293167  Training Accuracy:0.500542888165038\n",
      "The training loss at 1324th epoch : 229.99999964293164  Training Accuracy:0.500542888165038\n",
      "The training loss at 1325th epoch : 229.99999964293158  Training Accuracy:0.500542888165038\n",
      "The training loss at 1326th epoch : 229.99999964293153  Training Accuracy:0.500542888165038\n",
      "The training loss at 1327th epoch : 229.99999964293147  Training Accuracy:0.500542888165038\n",
      "The training loss at 1328th epoch : 229.99999964293144  Training Accuracy:0.500542888165038\n",
      "The training loss at 1329th epoch : 229.9999996429314  Training Accuracy:0.500542888165038\n",
      "The training loss at 1330th epoch : 229.99999964293139  Training Accuracy:0.500542888165038\n",
      "The training loss at 1331th epoch : 229.99999964293133  Training Accuracy:0.500542888165038\n",
      "The training loss at 1332th epoch : 229.9999996429313  Training Accuracy:0.500542888165038\n",
      "The training loss at 1333th epoch : 229.99999964293124  Training Accuracy:0.500542888165038\n",
      "The training loss at 1334th epoch : 229.99999964293121  Training Accuracy:0.500542888165038\n",
      "The training loss at 1335th epoch : 229.99999964293113  Training Accuracy:0.500542888165038\n",
      "The training loss at 1336th epoch : 229.99999964293113  Training Accuracy:0.500542888165038\n",
      "The training loss at 1337th epoch : 229.99999964293107  Training Accuracy:0.500542888165038\n",
      "The training loss at 1338th epoch : 229.99999964293102  Training Accuracy:0.500542888165038\n",
      "The training loss at 1339th epoch : 229.999999642931  Training Accuracy:0.500542888165038\n",
      "The training loss at 1340th epoch : 229.99999964293093  Training Accuracy:0.500542888165038\n",
      "The training loss at 1341th epoch : 229.9999996429309  Training Accuracy:0.500542888165038\n",
      "The training loss at 1342th epoch : 229.99999964293085  Training Accuracy:0.500542888165038\n",
      "The training loss at 1343th epoch : 229.99999964293082  Training Accuracy:0.500542888165038\n",
      "The training loss at 1344th epoch : 229.99999964293076  Training Accuracy:0.500542888165038\n",
      "The training loss at 1345th epoch : 229.9999996429307  Training Accuracy:0.500542888165038\n",
      "The training loss at 1346th epoch : 229.99999964293067  Training Accuracy:0.500542888165038\n",
      "The training loss at 1347th epoch : 229.99999964293062  Training Accuracy:0.500542888165038\n",
      "The training loss at 1348th epoch : 229.9999996429306  Training Accuracy:0.500542888165038\n",
      "The training loss at 1349th epoch : 229.99999964293056  Training Accuracy:0.500542888165038\n",
      "The training loss at 1350th epoch : 229.9999996429305  Training Accuracy:0.500542888165038\n",
      "The training loss at 1351th epoch : 229.99999964293045  Training Accuracy:0.500542888165038\n",
      "The training loss at 1352th epoch : 229.99999964293042  Training Accuracy:0.500542888165038\n",
      "The training loss at 1353th epoch : 229.9999996429304  Training Accuracy:0.500542888165038\n",
      "The training loss at 1354th epoch : 229.99999964293033  Training Accuracy:0.500542888165038\n",
      "The training loss at 1355th epoch : 229.99999964293028  Training Accuracy:0.500542888165038\n",
      "The training loss at 1356th epoch : 229.99999964293022  Training Accuracy:0.500542888165038\n",
      "The training loss at 1357th epoch : 229.99999964293022  Training Accuracy:0.500542888165038\n",
      "The training loss at 1358th epoch : 229.99999964293016  Training Accuracy:0.500542888165038\n",
      "The training loss at 1359th epoch : 229.99999964293013  Training Accuracy:0.500542888165038\n",
      "The training loss at 1360th epoch : 229.99999964293008  Training Accuracy:0.500542888165038\n",
      "The training loss at 1361th epoch : 229.99999964293005  Training Accuracy:0.500542888165038\n",
      "The training loss at 1362th epoch : 229.99999964293  Training Accuracy:0.500542888165038\n",
      "The training loss at 1363th epoch : 229.99999964292994  Training Accuracy:0.500542888165038\n",
      "The training loss at 1364th epoch : 229.9999996429299  Training Accuracy:0.500542888165038\n",
      "The training loss at 1365th epoch : 229.99999964292985  Training Accuracy:0.500542888165038\n",
      "The training loss at 1366th epoch : 229.99999964292982  Training Accuracy:0.500542888165038\n",
      "The training loss at 1367th epoch : 229.99999964292977  Training Accuracy:0.500542888165038\n",
      "The training loss at 1368th epoch : 229.9999996429297  Training Accuracy:0.500542888165038\n",
      "The training loss at 1369th epoch : 229.9999996429297  Training Accuracy:0.500542888165038\n",
      "The training loss at 1370th epoch : 229.99999964292962  Training Accuracy:0.500542888165038\n",
      "The training loss at 1371th epoch : 229.9999996429296  Training Accuracy:0.500542888165038\n",
      "The training loss at 1372th epoch : 229.99999964292954  Training Accuracy:0.500542888165038\n",
      "The training loss at 1373th epoch : 229.9999996429295  Training Accuracy:0.500542888165038\n",
      "The training loss at 1374th epoch : 229.99999964292948  Training Accuracy:0.500542888165038\n",
      "The training loss at 1375th epoch : 229.99999964292945  Training Accuracy:0.500542888165038\n",
      "The training loss at 1376th epoch : 229.9999996429294  Training Accuracy:0.500542888165038\n",
      "The training loss at 1377th epoch : 229.99999964292934  Training Accuracy:0.500542888165038\n",
      "The training loss at 1378th epoch : 229.9999996429293  Training Accuracy:0.500542888165038\n",
      "The training loss at 1379th epoch : 229.99999964292925  Training Accuracy:0.500542888165038\n",
      "The training loss at 1380th epoch : 229.9999996429292  Training Accuracy:0.500542888165038\n",
      "The training loss at 1381th epoch : 229.99999964292917  Training Accuracy:0.500542888165038\n",
      "The training loss at 1382th epoch : 229.99999964292914  Training Accuracy:0.500542888165038\n",
      "The training loss at 1383th epoch : 229.99999964292908  Training Accuracy:0.500542888165038\n",
      "The training loss at 1384th epoch : 229.99999964292903  Training Accuracy:0.500542888165038\n",
      "The training loss at 1385th epoch : 229.999999642929  Training Accuracy:0.500542888165038\n",
      "The training loss at 1386th epoch : 229.99999964292897  Training Accuracy:0.500542888165038\n",
      "The training loss at 1387th epoch : 229.9999996429289  Training Accuracy:0.500542888165038\n",
      "The training loss at 1388th epoch : 229.99999964292886  Training Accuracy:0.500542888165038\n",
      "The training loss at 1389th epoch : 229.9999996429288  Training Accuracy:0.500542888165038\n",
      "The training loss at 1390th epoch : 229.99999964292877  Training Accuracy:0.500542888165038\n",
      "The training loss at 1391th epoch : 229.99999964292874  Training Accuracy:0.500542888165038\n",
      "The training loss at 1392th epoch : 229.99999964292869  Training Accuracy:0.500542888165038\n",
      "The training loss at 1393th epoch : 229.99999964292863  Training Accuracy:0.500542888165038\n",
      "The training loss at 1394th epoch : 229.99999964292863  Training Accuracy:0.500542888165038\n",
      "The training loss at 1395th epoch : 229.99999964292854  Training Accuracy:0.500542888165038\n",
      "The training loss at 1396th epoch : 229.99999964292851  Training Accuracy:0.500542888165038\n",
      "The training loss at 1397th epoch : 229.99999964292846  Training Accuracy:0.500542888165038\n",
      "The training loss at 1398th epoch : 229.9999996429284  Training Accuracy:0.500542888165038\n",
      "The training loss at 1399th epoch : 229.99999964292837  Training Accuracy:0.500542888165038\n",
      "The training loss at 1400th epoch : 229.99999964292834  Training Accuracy:0.500542888165038\n",
      "The training loss at 1401th epoch : 229.9999996429283  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 1402th epoch : 229.99999964292826  Training Accuracy:0.500542888165038\n",
      "The training loss at 1403th epoch : 229.99999964292823  Training Accuracy:0.500542888165038\n",
      "The training loss at 1404th epoch : 229.99999964292817  Training Accuracy:0.500542888165038\n",
      "The training loss at 1405th epoch : 229.99999964292815  Training Accuracy:0.500542888165038\n",
      "The training loss at 1406th epoch : 229.9999996429281  Training Accuracy:0.500542888165038\n",
      "The training loss at 1407th epoch : 229.99999964292806  Training Accuracy:0.500542888165038\n",
      "The training loss at 1408th epoch : 229.999999642928  Training Accuracy:0.500542888165038\n",
      "The training loss at 1409th epoch : 229.99999964292795  Training Accuracy:0.500542888165038\n",
      "The training loss at 1410th epoch : 229.9999996429279  Training Accuracy:0.500542888165038\n",
      "The training loss at 1411th epoch : 229.99999964292786  Training Accuracy:0.500542888165038\n",
      "The training loss at 1412th epoch : 229.99999964292783  Training Accuracy:0.500542888165038\n",
      "The training loss at 1413th epoch : 229.99999964292778  Training Accuracy:0.500542888165038\n",
      "The training loss at 1414th epoch : 229.99999964292772  Training Accuracy:0.500542888165038\n",
      "The training loss at 1415th epoch : 229.99999964292772  Training Accuracy:0.500542888165038\n",
      "The training loss at 1416th epoch : 229.99999964292763  Training Accuracy:0.500542888165038\n",
      "The training loss at 1417th epoch : 229.9999996429276  Training Accuracy:0.500542888165038\n",
      "The training loss at 1418th epoch : 229.99999964292755  Training Accuracy:0.500542888165038\n",
      "The training loss at 1419th epoch : 229.9999996429275  Training Accuracy:0.500542888165038\n",
      "The training loss at 1420th epoch : 229.9999996429275  Training Accuracy:0.500542888165038\n",
      "The training loss at 1421th epoch : 229.99999964292743  Training Accuracy:0.500542888165038\n",
      "The training loss at 1422th epoch : 229.99999964292738  Training Accuracy:0.500542888165038\n",
      "The training loss at 1423th epoch : 229.99999964292732  Training Accuracy:0.500542888165038\n",
      "The training loss at 1424th epoch : 229.9999996429273  Training Accuracy:0.500542888165038\n",
      "The training loss at 1425th epoch : 229.99999964292726  Training Accuracy:0.500542888165038\n",
      "The training loss at 1426th epoch : 229.9999996429272  Training Accuracy:0.500542888165038\n",
      "The training loss at 1427th epoch : 229.99999964292718  Training Accuracy:0.500542888165038\n",
      "The training loss at 1428th epoch : 229.9999996429271  Training Accuracy:0.500542888165038\n",
      "The training loss at 1429th epoch : 229.9999996429271  Training Accuracy:0.500542888165038\n",
      "The training loss at 1430th epoch : 229.99999964292704  Training Accuracy:0.500542888165038\n",
      "The training loss at 1431th epoch : 229.999999642927  Training Accuracy:0.500542888165038\n",
      "The training loss at 1432th epoch : 229.99999964292695  Training Accuracy:0.500542888165038\n",
      "The training loss at 1433th epoch : 229.99999964292692  Training Accuracy:0.500542888165038\n",
      "The training loss at 1434th epoch : 229.99999964292687  Training Accuracy:0.500542888165038\n",
      "The training loss at 1435th epoch : 229.9999996429268  Training Accuracy:0.500542888165038\n",
      "The training loss at 1436th epoch : 229.99999964292678  Training Accuracy:0.500542888165038\n",
      "The training loss at 1437th epoch : 229.99999964292675  Training Accuracy:0.500542888165038\n",
      "The training loss at 1438th epoch : 229.9999996429267  Training Accuracy:0.500542888165038\n",
      "The training loss at 1439th epoch : 229.99999964292664  Training Accuracy:0.500542888165038\n",
      "The training loss at 1440th epoch : 229.99999964292658  Training Accuracy:0.500542888165038\n",
      "The training loss at 1441th epoch : 229.99999964292658  Training Accuracy:0.500542888165038\n",
      "The training loss at 1442th epoch : 229.99999964292653  Training Accuracy:0.500542888165038\n",
      "The training loss at 1443th epoch : 229.99999964292647  Training Accuracy:0.500542888165038\n",
      "The training loss at 1444th epoch : 229.9999996429264  Training Accuracy:0.500542888165038\n",
      "The training loss at 1445th epoch : 229.9999996429264  Training Accuracy:0.500542888165038\n",
      "The training loss at 1446th epoch : 229.99999964292635  Training Accuracy:0.500542888165038\n",
      "The training loss at 1447th epoch : 229.9999996429263  Training Accuracy:0.500542888165038\n",
      "The training loss at 1448th epoch : 229.99999964292627  Training Accuracy:0.500542888165038\n",
      "The training loss at 1449th epoch : 229.99999964292624  Training Accuracy:0.500542888165038\n",
      "The training loss at 1450th epoch : 229.99999964292618  Training Accuracy:0.500542888165038\n",
      "The training loss at 1451th epoch : 229.99999964292613  Training Accuracy:0.500542888165038\n",
      "The training loss at 1452th epoch : 229.9999996429261  Training Accuracy:0.500542888165038\n",
      "The training loss at 1453th epoch : 229.99999964292607  Training Accuracy:0.500542888165038\n",
      "The training loss at 1454th epoch : 229.999999642926  Training Accuracy:0.500542888165038\n",
      "The training loss at 1455th epoch : 229.99999964292596  Training Accuracy:0.500542888165038\n",
      "The training loss at 1456th epoch : 229.9999996429259  Training Accuracy:0.500542888165038\n",
      "The training loss at 1457th epoch : 229.99999964292587  Training Accuracy:0.500542888165038\n",
      "The training loss at 1458th epoch : 229.99999964292584  Training Accuracy:0.500542888165038\n",
      "The training loss at 1459th epoch : 229.9999996429258  Training Accuracy:0.500542888165038\n",
      "The training loss at 1460th epoch : 229.99999964292573  Training Accuracy:0.500542888165038\n",
      "The training loss at 1461th epoch : 229.99999964292567  Training Accuracy:0.500542888165038\n",
      "The training loss at 1462th epoch : 229.99999964292564  Training Accuracy:0.500542888165038\n",
      "The training loss at 1463th epoch : 229.99999964292562  Training Accuracy:0.500542888165038\n",
      "The training loss at 1464th epoch : 229.99999964292556  Training Accuracy:0.500542888165038\n",
      "The training loss at 1465th epoch : 229.9999996429255  Training Accuracy:0.500542888165038\n",
      "The training loss at 1466th epoch : 229.9999996429255  Training Accuracy:0.500542888165038\n",
      "The training loss at 1467th epoch : 229.99999964292545  Training Accuracy:0.500542888165038\n",
      "The training loss at 1468th epoch : 229.9999996429254  Training Accuracy:0.500542888165038\n",
      "The training loss at 1469th epoch : 229.99999964292536  Training Accuracy:0.500542888165038\n",
      "The training loss at 1470th epoch : 229.99999964292527  Training Accuracy:0.500542888165038\n",
      "The training loss at 1471th epoch : 229.99999964292527  Training Accuracy:0.500542888165038\n",
      "The training loss at 1472th epoch : 229.99999964292522  Training Accuracy:0.500542888165038\n",
      "The training loss at 1473th epoch : 229.9999996429252  Training Accuracy:0.500542888165038\n",
      "The training loss at 1474th epoch : 229.99999964292513  Training Accuracy:0.500542888165038\n",
      "The training loss at 1475th epoch : 229.9999996429251  Training Accuracy:0.500542888165038\n",
      "The training loss at 1476th epoch : 229.99999964292505  Training Accuracy:0.500542888165038\n",
      "The training loss at 1477th epoch : 229.99999964292502  Training Accuracy:0.500542888165038\n",
      "The training loss at 1478th epoch : 229.99999964292496  Training Accuracy:0.500542888165038\n",
      "The training loss at 1479th epoch : 229.9999996429249  Training Accuracy:0.500542888165038\n",
      "The training loss at 1480th epoch : 229.99999964292488  Training Accuracy:0.500542888165038\n",
      "The training loss at 1481th epoch : 229.99999964292482  Training Accuracy:0.500542888165038\n",
      "The training loss at 1482th epoch : 229.9999996429248  Training Accuracy:0.500542888165038\n",
      "The training loss at 1483th epoch : 229.99999964292473  Training Accuracy:0.500542888165038\n",
      "The training loss at 1484th epoch : 229.9999996429247  Training Accuracy:0.500542888165038\n",
      "The training loss at 1485th epoch : 229.99999964292465  Training Accuracy:0.500542888165038\n",
      "The training loss at 1486th epoch : 229.99999964292462  Training Accuracy:0.500542888165038\n",
      "The training loss at 1487th epoch : 229.9999996429246  Training Accuracy:0.500542888165038\n",
      "The training loss at 1488th epoch : 229.99999964292454  Training Accuracy:0.500542888165038\n",
      "The training loss at 1489th epoch : 229.99999964292448  Training Accuracy:0.500542888165038\n",
      "The training loss at 1490th epoch : 229.99999964292448  Training Accuracy:0.500542888165038\n",
      "The training loss at 1491th epoch : 229.99999964292442  Training Accuracy:0.500542888165038\n",
      "The training loss at 1492th epoch : 229.99999964292437  Training Accuracy:0.500542888165038\n",
      "The training loss at 1493th epoch : 229.9999996429243  Training Accuracy:0.500542888165038\n",
      "The training loss at 1494th epoch : 229.99999964292428  Training Accuracy:0.500542888165038\n",
      "The training loss at 1495th epoch : 229.99999964292422  Training Accuracy:0.500542888165038\n",
      "The training loss at 1496th epoch : 229.9999996429242  Training Accuracy:0.500542888165038\n",
      "The training loss at 1497th epoch : 229.99999964292414  Training Accuracy:0.500542888165038\n",
      "The training loss at 1498th epoch : 229.9999996429241  Training Accuracy:0.500542888165038\n",
      "The training loss at 1499th epoch : 229.99999964292405  Training Accuracy:0.500542888165038\n",
      "The training loss at 1500th epoch : 229.99999964292402  Training Accuracy:0.500542888165038\n",
      "The training loss at 1501th epoch : 229.99999964292397  Training Accuracy:0.500542888165038\n",
      "The training loss at 1502th epoch : 229.9999996429239  Training Accuracy:0.500542888165038\n",
      "The training loss at 1503th epoch : 229.99999964292388  Training Accuracy:0.500542888165038\n",
      "The training loss at 1504th epoch : 229.99999964292383  Training Accuracy:0.500542888165038\n",
      "The training loss at 1505th epoch : 229.9999996429238  Training Accuracy:0.500542888165038\n",
      "The training loss at 1506th epoch : 229.99999964292374  Training Accuracy:0.500542888165038\n",
      "The training loss at 1507th epoch : 229.99999964292368  Training Accuracy:0.500542888165038\n",
      "The training loss at 1508th epoch : 229.99999964292365  Training Accuracy:0.500542888165038\n",
      "The training loss at 1509th epoch : 229.9999996429236  Training Accuracy:0.500542888165038\n",
      "The training loss at 1510th epoch : 229.99999964292357  Training Accuracy:0.500542888165038\n",
      "The training loss at 1511th epoch : 229.9999996429235  Training Accuracy:0.500542888165038\n",
      "The training loss at 1512th epoch : 229.9999996429235  Training Accuracy:0.500542888165038\n",
      "The training loss at 1513th epoch : 229.99999964292346  Training Accuracy:0.500542888165038\n",
      "The training loss at 1514th epoch : 229.9999996429234  Training Accuracy:0.500542888165038\n",
      "The training loss at 1515th epoch : 229.99999964292334  Training Accuracy:0.500542888165038\n",
      "The training loss at 1516th epoch : 229.99999964292334  Training Accuracy:0.500542888165038\n",
      "The training loss at 1517th epoch : 229.99999964292326  Training Accuracy:0.500542888165038\n",
      "The training loss at 1518th epoch : 229.99999964292323  Training Accuracy:0.500542888165038\n",
      "The training loss at 1519th epoch : 229.9999996429232  Training Accuracy:0.500542888165038\n",
      "The training loss at 1520th epoch : 229.99999964292314  Training Accuracy:0.500542888165038\n",
      "The training loss at 1521th epoch : 229.99999964292311  Training Accuracy:0.500542888165038\n",
      "The training loss at 1522th epoch : 229.99999964292306  Training Accuracy:0.500542888165038\n",
      "The training loss at 1523th epoch : 229.999999642923  Training Accuracy:0.500542888165038\n",
      "The training loss at 1524th epoch : 229.99999964292297  Training Accuracy:0.500542888165038\n",
      "The training loss at 1525th epoch : 229.99999964292294  Training Accuracy:0.500542888165038\n",
      "The training loss at 1526th epoch : 229.9999996429229  Training Accuracy:0.500542888165038\n",
      "The training loss at 1527th epoch : 229.99999964292283  Training Accuracy:0.500542888165038\n",
      "The training loss at 1528th epoch : 229.99999964292277  Training Accuracy:0.500542888165038\n",
      "The training loss at 1529th epoch : 229.99999964292275  Training Accuracy:0.500542888165038\n",
      "The training loss at 1530th epoch : 229.99999964292272  Training Accuracy:0.500542888165038\n",
      "The training loss at 1531th epoch : 229.99999964292266  Training Accuracy:0.500542888165038\n",
      "The training loss at 1532th epoch : 229.99999964292266  Training Accuracy:0.500542888165038\n",
      "The training loss at 1533th epoch : 229.9999996429226  Training Accuracy:0.500542888165038\n",
      "The training loss at 1534th epoch : 229.99999964292255  Training Accuracy:0.500542888165038\n",
      "The training loss at 1535th epoch : 229.9999996429225  Training Accuracy:0.500542888165038\n",
      "The training loss at 1536th epoch : 229.99999964292246  Training Accuracy:0.500542888165038\n",
      "The training loss at 1537th epoch : 229.99999964292243  Training Accuracy:0.500542888165038\n",
      "The training loss at 1538th epoch : 229.99999964292238  Training Accuracy:0.500542888165038\n",
      "The training loss at 1539th epoch : 229.99999964292232  Training Accuracy:0.500542888165038\n",
      "The training loss at 1540th epoch : 229.9999996429223  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 1541th epoch : 229.99999964292223  Training Accuracy:0.500542888165038\n",
      "The training loss at 1542th epoch : 229.9999996429222  Training Accuracy:0.500542888165038\n",
      "The training loss at 1543th epoch : 229.99999964292215  Training Accuracy:0.500542888165038\n",
      "The training loss at 1544th epoch : 229.9999996429221  Training Accuracy:0.500542888165038\n",
      "The training loss at 1545th epoch : 229.99999964292206  Training Accuracy:0.500542888165038\n",
      "The training loss at 1546th epoch : 229.99999964292203  Training Accuracy:0.500542888165038\n",
      "The training loss at 1547th epoch : 229.99999964292198  Training Accuracy:0.500542888165038\n",
      "The training loss at 1548th epoch : 229.99999964292192  Training Accuracy:0.500542888165038\n",
      "The training loss at 1549th epoch : 229.9999996429219  Training Accuracy:0.500542888165038\n",
      "The training loss at 1550th epoch : 229.99999964292186  Training Accuracy:0.500542888165038\n",
      "The training loss at 1551th epoch : 229.9999996429218  Training Accuracy:0.500542888165038\n",
      "The training loss at 1552th epoch : 229.99999964292175  Training Accuracy:0.500542888165038\n",
      "The training loss at 1553th epoch : 229.99999964292175  Training Accuracy:0.500542888165038\n",
      "The training loss at 1554th epoch : 229.9999996429217  Training Accuracy:0.500542888165038\n",
      "The training loss at 1555th epoch : 229.99999964292164  Training Accuracy:0.500542888165038\n",
      "The training loss at 1556th epoch : 229.99999964292158  Training Accuracy:0.500542888165038\n",
      "The training loss at 1557th epoch : 229.99999964292155  Training Accuracy:0.500542888165038\n",
      "The training loss at 1558th epoch : 229.99999964292152  Training Accuracy:0.500542888165038\n",
      "The training loss at 1559th epoch : 229.99999964292147  Training Accuracy:0.500542888165038\n",
      "The training loss at 1560th epoch : 229.9999996429214  Training Accuracy:0.500542888165038\n",
      "The training loss at 1561th epoch : 229.99999964292135  Training Accuracy:0.500542888165038\n",
      "The training loss at 1562th epoch : 229.99999964292135  Training Accuracy:0.500542888165038\n",
      "The training loss at 1563th epoch : 229.9999996429213  Training Accuracy:0.500542888165038\n",
      "The training loss at 1564th epoch : 229.99999964292124  Training Accuracy:0.500542888165038\n",
      "The training loss at 1565th epoch : 229.99999964292118  Training Accuracy:0.500542888165038\n",
      "The training loss at 1566th epoch : 229.99999964292115  Training Accuracy:0.500542888165038\n",
      "The training loss at 1567th epoch : 229.99999964292113  Training Accuracy:0.500542888165038\n",
      "The training loss at 1568th epoch : 229.99999964292107  Training Accuracy:0.500542888165038\n",
      "The training loss at 1569th epoch : 229.99999964292104  Training Accuracy:0.500542888165038\n",
      "The training loss at 1570th epoch : 229.999999642921  Training Accuracy:0.500542888165038\n",
      "The training loss at 1571th epoch : 229.99999964292095  Training Accuracy:0.500542888165038\n",
      "The training loss at 1572th epoch : 229.9999996429209  Training Accuracy:0.500542888165038\n",
      "The training loss at 1573th epoch : 229.99999964292084  Training Accuracy:0.500542888165038\n",
      "The training loss at 1574th epoch : 229.99999964292078  Training Accuracy:0.500542888165038\n",
      "The training loss at 1575th epoch : 229.99999964292076  Training Accuracy:0.500542888165038\n",
      "The training loss at 1576th epoch : 229.99999964292073  Training Accuracy:0.500542888165038\n",
      "The training loss at 1577th epoch : 229.9999996429207  Training Accuracy:0.500542888165038\n",
      "The training loss at 1578th epoch : 229.9999996429206  Training Accuracy:0.500542888165038\n",
      "The training loss at 1579th epoch : 229.99999964292056  Training Accuracy:0.500542888165038\n",
      "The training loss at 1580th epoch : 229.99999964292056  Training Accuracy:0.500542888165038\n",
      "The training loss at 1581th epoch : 229.9999996429205  Training Accuracy:0.500542888165038\n",
      "The training loss at 1582th epoch : 229.99999964292047  Training Accuracy:0.500542888165038\n",
      "The training loss at 1583th epoch : 229.99999964292044  Training Accuracy:0.500542888165038\n",
      "The training loss at 1584th epoch : 229.9999996429204  Training Accuracy:0.500542888165038\n",
      "The training loss at 1585th epoch : 229.99999964292033  Training Accuracy:0.500542888165038\n",
      "The training loss at 1586th epoch : 229.9999996429203  Training Accuracy:0.500542888165038\n",
      "The training loss at 1587th epoch : 229.99999964292024  Training Accuracy:0.500542888165038\n",
      "The training loss at 1588th epoch : 229.99999964292022  Training Accuracy:0.500542888165038\n",
      "The training loss at 1589th epoch : 229.99999964292016  Training Accuracy:0.500542888165038\n",
      "The training loss at 1590th epoch : 229.9999996429201  Training Accuracy:0.500542888165038\n",
      "The training loss at 1591th epoch : 229.99999964292007  Training Accuracy:0.500542888165038\n",
      "The training loss at 1592th epoch : 229.99999964292002  Training Accuracy:0.500542888165038\n",
      "The training loss at 1593th epoch : 229.99999964292  Training Accuracy:0.500542888165038\n",
      "The training loss at 1594th epoch : 229.99999964291993  Training Accuracy:0.500542888165038\n",
      "The training loss at 1595th epoch : 229.99999964291987  Training Accuracy:0.500542888165038\n",
      "The training loss at 1596th epoch : 229.99999964291985  Training Accuracy:0.500542888165038\n",
      "The training loss at 1597th epoch : 229.9999996429198  Training Accuracy:0.500542888165038\n",
      "The training loss at 1598th epoch : 229.99999964291976  Training Accuracy:0.500542888165038\n",
      "The training loss at 1599th epoch : 229.99999964291973  Training Accuracy:0.500542888165038\n",
      "The training loss at 1600th epoch : 229.99999964291968  Training Accuracy:0.500542888165038\n",
      "The training loss at 1601th epoch : 229.99999964291965  Training Accuracy:0.500542888165038\n",
      "The training loss at 1602th epoch : 229.9999996429196  Training Accuracy:0.500542888165038\n",
      "The training loss at 1603th epoch : 229.99999964291953  Training Accuracy:0.500542888165038\n",
      "The training loss at 1604th epoch : 229.9999996429195  Training Accuracy:0.500542888165038\n",
      "The training loss at 1605th epoch : 229.99999964291948  Training Accuracy:0.500542888165038\n",
      "The training loss at 1606th epoch : 229.99999964291942  Training Accuracy:0.500542888165038\n",
      "The training loss at 1607th epoch : 229.9999996429194  Training Accuracy:0.500542888165038\n",
      "The training loss at 1608th epoch : 229.99999964291933  Training Accuracy:0.500542888165038\n",
      "The training loss at 1609th epoch : 229.9999996429193  Training Accuracy:0.500542888165038\n",
      "The training loss at 1610th epoch : 229.99999964291925  Training Accuracy:0.500542888165038\n",
      "The training loss at 1611th epoch : 229.9999996429192  Training Accuracy:0.500542888165038\n",
      "The training loss at 1612th epoch : 229.99999964291916  Training Accuracy:0.500542888165038\n",
      "The training loss at 1613th epoch : 229.99999964291914  Training Accuracy:0.500542888165038\n",
      "The training loss at 1614th epoch : 229.99999964291908  Training Accuracy:0.500542888165038\n",
      "The training loss at 1615th epoch : 229.99999964291905  Training Accuracy:0.500542888165038\n",
      "The training loss at 1616th epoch : 229.999999642919  Training Accuracy:0.500542888165038\n",
      "The training loss at 1617th epoch : 229.99999964291897  Training Accuracy:0.500542888165038\n",
      "The training loss at 1618th epoch : 229.9999996429189  Training Accuracy:0.500542888165038\n",
      "The training loss at 1619th epoch : 229.99999964291885  Training Accuracy:0.500542888165038\n",
      "The training loss at 1620th epoch : 229.99999964291882  Training Accuracy:0.500542888165038\n",
      "The training loss at 1621th epoch : 229.99999964291877  Training Accuracy:0.500542888165038\n",
      "The training loss at 1622th epoch : 229.99999964291874  Training Accuracy:0.500542888165038\n",
      "The training loss at 1623th epoch : 229.99999964291868  Training Accuracy:0.500542888165038\n",
      "The training loss at 1624th epoch : 229.99999964291865  Training Accuracy:0.500542888165038\n",
      "The training loss at 1625th epoch : 229.9999996429186  Training Accuracy:0.500542888165038\n",
      "The training loss at 1626th epoch : 229.99999964291857  Training Accuracy:0.500542888165038\n",
      "The training loss at 1627th epoch : 229.9999996429185  Training Accuracy:0.500542888165038\n",
      "The training loss at 1628th epoch : 229.99999964291845  Training Accuracy:0.500542888165038\n",
      "The training loss at 1629th epoch : 229.99999964291843  Training Accuracy:0.500542888165038\n",
      "The training loss at 1630th epoch : 229.9999996429184  Training Accuracy:0.500542888165038\n",
      "The training loss at 1631th epoch : 229.99999964291834  Training Accuracy:0.500542888165038\n",
      "The training loss at 1632th epoch : 229.9999996429183  Training Accuracy:0.500542888165038\n",
      "The training loss at 1633th epoch : 229.99999964291825  Training Accuracy:0.500542888165038\n",
      "The training loss at 1634th epoch : 229.99999964291823  Training Accuracy:0.500542888165038\n",
      "The training loss at 1635th epoch : 229.99999964291817  Training Accuracy:0.500542888165038\n",
      "The training loss at 1636th epoch : 229.9999996429181  Training Accuracy:0.500542888165038\n",
      "The training loss at 1637th epoch : 229.99999964291808  Training Accuracy:0.500542888165038\n",
      "The training loss at 1638th epoch : 229.99999964291803  Training Accuracy:0.500542888165038\n",
      "The training loss at 1639th epoch : 229.999999642918  Training Accuracy:0.500542888165038\n",
      "The training loss at 1640th epoch : 229.99999964291794  Training Accuracy:0.500542888165038\n",
      "The training loss at 1641th epoch : 229.99999964291789  Training Accuracy:0.500542888165038\n",
      "The training loss at 1642th epoch : 229.99999964291786  Training Accuracy:0.500542888165038\n",
      "The training loss at 1643th epoch : 229.99999964291783  Training Accuracy:0.500542888165038\n",
      "The training loss at 1644th epoch : 229.99999964291777  Training Accuracy:0.500542888165038\n",
      "The training loss at 1645th epoch : 229.99999964291771  Training Accuracy:0.500542888165038\n",
      "The training loss at 1646th epoch : 229.99999964291771  Training Accuracy:0.500542888165038\n",
      "The training loss at 1647th epoch : 229.99999964291766  Training Accuracy:0.500542888165038\n",
      "The training loss at 1648th epoch : 229.9999996429176  Training Accuracy:0.500542888165038\n",
      "The training loss at 1649th epoch : 229.99999964291754  Training Accuracy:0.500542888165038\n",
      "The training loss at 1650th epoch : 229.99999964291754  Training Accuracy:0.500542888165038\n",
      "The training loss at 1651th epoch : 229.9999996429175  Training Accuracy:0.500542888165038\n",
      "The training loss at 1652th epoch : 229.99999964291743  Training Accuracy:0.500542888165038\n",
      "The training loss at 1653th epoch : 229.99999964291737  Training Accuracy:0.500542888165038\n",
      "The training loss at 1654th epoch : 229.99999964291734  Training Accuracy:0.500542888165038\n",
      "The training loss at 1655th epoch : 229.99999964291732  Training Accuracy:0.500542888165038\n",
      "The training loss at 1656th epoch : 229.99999964291726  Training Accuracy:0.500542888165038\n",
      "The training loss at 1657th epoch : 229.9999996429172  Training Accuracy:0.500542888165038\n",
      "The training loss at 1658th epoch : 229.99999964291717  Training Accuracy:0.500542888165038\n",
      "The training loss at 1659th epoch : 229.99999964291712  Training Accuracy:0.500542888165038\n",
      "The training loss at 1660th epoch : 229.9999996429171  Training Accuracy:0.500542888165038\n",
      "The training loss at 1661th epoch : 229.99999964291703  Training Accuracy:0.500542888165038\n",
      "The training loss at 1662th epoch : 229.99999964291698  Training Accuracy:0.500542888165038\n",
      "The training loss at 1663th epoch : 229.99999964291698  Training Accuracy:0.500542888165038\n",
      "The training loss at 1664th epoch : 229.99999964291692  Training Accuracy:0.500542888165038\n",
      "The training loss at 1665th epoch : 229.99999964291686  Training Accuracy:0.500542888165038\n",
      "The training loss at 1666th epoch : 229.9999996429168  Training Accuracy:0.500542888165038\n",
      "The training loss at 1667th epoch : 229.99999964291678  Training Accuracy:0.500542888165038\n",
      "The training loss at 1668th epoch : 229.99999964291672  Training Accuracy:0.500542888165038\n",
      "The training loss at 1669th epoch : 229.9999996429167  Training Accuracy:0.500542888165038\n",
      "The training loss at 1670th epoch : 229.99999964291663  Training Accuracy:0.500542888165038\n",
      "The training loss at 1671th epoch : 229.99999964291663  Training Accuracy:0.500542888165038\n",
      "The training loss at 1672th epoch : 229.99999964291658  Training Accuracy:0.500542888165038\n",
      "The training loss at 1673th epoch : 229.99999964291655  Training Accuracy:0.500542888165038\n",
      "The training loss at 1674th epoch : 229.9999996429165  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 1675th epoch : 229.99999964291646  Training Accuracy:0.500542888165038\n",
      "The training loss at 1676th epoch : 229.9999996429164  Training Accuracy:0.500542888165038\n",
      "The training loss at 1677th epoch : 229.99999964291635  Training Accuracy:0.500542888165038\n",
      "The training loss at 1678th epoch : 229.9999996429163  Training Accuracy:0.500542888165038\n",
      "The training loss at 1679th epoch : 229.99999964291626  Training Accuracy:0.500542888165038\n",
      "The training loss at 1680th epoch : 229.99999964291624  Training Accuracy:0.500542888165038\n",
      "The training loss at 1681th epoch : 229.99999964291618  Training Accuracy:0.500542888165038\n",
      "The training loss at 1682th epoch : 229.99999964291612  Training Accuracy:0.500542888165038\n",
      "The training loss at 1683th epoch : 229.9999996429161  Training Accuracy:0.500542888165038\n",
      "The training loss at 1684th epoch : 229.99999964291604  Training Accuracy:0.500542888165038\n",
      "The training loss at 1685th epoch : 229.999999642916  Training Accuracy:0.500542888165038\n",
      "The training loss at 1686th epoch : 229.99999964291595  Training Accuracy:0.500542888165038\n",
      "The training loss at 1687th epoch : 229.99999964291592  Training Accuracy:0.500542888165038\n",
      "The training loss at 1688th epoch : 229.99999964291587  Training Accuracy:0.500542888165038\n",
      "The training loss at 1689th epoch : 229.99999964291584  Training Accuracy:0.500542888165038\n",
      "The training loss at 1690th epoch : 229.99999964291578  Training Accuracy:0.500542888165038\n",
      "The training loss at 1691th epoch : 229.99999964291572  Training Accuracy:0.500542888165038\n",
      "The training loss at 1692th epoch : 229.9999996429157  Training Accuracy:0.500542888165038\n",
      "The training loss at 1693th epoch : 229.99999964291567  Training Accuracy:0.500542888165038\n",
      "The training loss at 1694th epoch : 229.9999996429156  Training Accuracy:0.500542888165038\n",
      "The training loss at 1695th epoch : 229.99999964291558  Training Accuracy:0.500542888165038\n",
      "The training loss at 1696th epoch : 229.99999964291555  Training Accuracy:0.500542888165038\n",
      "The training loss at 1697th epoch : 229.9999996429155  Training Accuracy:0.500542888165038\n",
      "The training loss at 1698th epoch : 229.99999964291544  Training Accuracy:0.500542888165038\n",
      "The training loss at 1699th epoch : 229.9999996429154  Training Accuracy:0.500542888165038\n",
      "The training loss at 1700th epoch : 229.99999964291538  Training Accuracy:0.500542888165038\n",
      "The training loss at 1701th epoch : 229.99999964291533  Training Accuracy:0.500542888165038\n",
      "The training loss at 1702th epoch : 229.99999964291527  Training Accuracy:0.500542888165038\n",
      "The training loss at 1703th epoch : 229.99999964291524  Training Accuracy:0.500542888165038\n",
      "The training loss at 1704th epoch : 229.99999964291518  Training Accuracy:0.500542888165038\n",
      "The training loss at 1705th epoch : 229.99999964291513  Training Accuracy:0.500542888165038\n",
      "The training loss at 1706th epoch : 229.9999996429151  Training Accuracy:0.500542888165038\n",
      "The training loss at 1707th epoch : 229.99999964291504  Training Accuracy:0.500542888165038\n",
      "The training loss at 1708th epoch : 229.99999964291501  Training Accuracy:0.500542888165038\n",
      "The training loss at 1709th epoch : 229.99999964291496  Training Accuracy:0.500542888165038\n",
      "The training loss at 1710th epoch : 229.99999964291493  Training Accuracy:0.500542888165038\n",
      "The training loss at 1711th epoch : 229.99999964291487  Training Accuracy:0.500542888165038\n",
      "The training loss at 1712th epoch : 229.99999964291482  Training Accuracy:0.500542888165038\n",
      "The training loss at 1713th epoch : 229.99999964291476  Training Accuracy:0.500542888165038\n",
      "The training loss at 1714th epoch : 229.99999964291476  Training Accuracy:0.500542888165038\n",
      "The training loss at 1715th epoch : 229.9999996429147  Training Accuracy:0.500542888165038\n",
      "The training loss at 1716th epoch : 229.99999964291464  Training Accuracy:0.500542888165038\n",
      "The training loss at 1717th epoch : 229.9999996429146  Training Accuracy:0.500542888165038\n",
      "The training loss at 1718th epoch : 229.9999996429146  Training Accuracy:0.500542888165038\n",
      "The training loss at 1719th epoch : 229.99999964291453  Training Accuracy:0.500542888165038\n",
      "The training loss at 1720th epoch : 229.9999996429145  Training Accuracy:0.500542888165038\n",
      "The training loss at 1721th epoch : 229.99999964291445  Training Accuracy:0.500542888165038\n",
      "The training loss at 1722th epoch : 229.99999964291442  Training Accuracy:0.500542888165038\n",
      "The training loss at 1723th epoch : 229.99999964291436  Training Accuracy:0.500542888165038\n",
      "The training loss at 1724th epoch : 229.9999996429143  Training Accuracy:0.500542888165038\n",
      "The training loss at 1725th epoch : 229.99999964291428  Training Accuracy:0.500542888165038\n",
      "The training loss at 1726th epoch : 229.99999964291425  Training Accuracy:0.500542888165038\n",
      "The training loss at 1727th epoch : 229.9999996429142  Training Accuracy:0.500542888165038\n",
      "The training loss at 1728th epoch : 229.99999964291413  Training Accuracy:0.500542888165038\n",
      "The training loss at 1729th epoch : 229.9999996429141  Training Accuracy:0.500542888165038\n",
      "The training loss at 1730th epoch : 229.99999964291405  Training Accuracy:0.500542888165038\n",
      "The training loss at 1731th epoch : 229.99999964291402  Training Accuracy:0.500542888165038\n",
      "The training loss at 1732th epoch : 229.99999964291396  Training Accuracy:0.500542888165038\n",
      "The training loss at 1733th epoch : 229.9999996429139  Training Accuracy:0.500542888165038\n",
      "The training loss at 1734th epoch : 229.99999964291388  Training Accuracy:0.500542888165038\n",
      "The training loss at 1735th epoch : 229.99999964291382  Training Accuracy:0.500542888165038\n",
      "The training loss at 1736th epoch : 229.9999996429138  Training Accuracy:0.500542888165038\n",
      "The training loss at 1737th epoch : 229.99999964291374  Training Accuracy:0.500542888165038\n",
      "The training loss at 1738th epoch : 229.9999996429137  Training Accuracy:0.500542888165038\n",
      "The training loss at 1739th epoch : 229.99999964291368  Training Accuracy:0.500542888165038\n",
      "The training loss at 1740th epoch : 229.99999964291362  Training Accuracy:0.500542888165038\n",
      "The training loss at 1741th epoch : 229.9999996429136  Training Accuracy:0.500542888165038\n",
      "The training loss at 1742th epoch : 229.9999996429135  Training Accuracy:0.500542888165038\n",
      "The training loss at 1743th epoch : 229.9999996429135  Training Accuracy:0.500542888165038\n",
      "The training loss at 1744th epoch : 229.99999964291345  Training Accuracy:0.500542888165038\n",
      "The training loss at 1745th epoch : 229.9999996429134  Training Accuracy:0.500542888165038\n",
      "The training loss at 1746th epoch : 229.99999964291337  Training Accuracy:0.500542888165038\n",
      "The training loss at 1747th epoch : 229.9999996429133  Training Accuracy:0.500542888165038\n",
      "The training loss at 1748th epoch : 229.99999964291328  Training Accuracy:0.500542888165038\n",
      "The training loss at 1749th epoch : 229.99999964291322  Training Accuracy:0.500542888165038\n",
      "The training loss at 1750th epoch : 229.9999996429132  Training Accuracy:0.500542888165038\n",
      "The training loss at 1751th epoch : 229.99999964291314  Training Accuracy:0.500542888165038\n",
      "The training loss at 1752th epoch : 229.9999996429131  Training Accuracy:0.500542888165038\n",
      "The training loss at 1753th epoch : 229.99999964291305  Training Accuracy:0.500542888165038\n",
      "The training loss at 1754th epoch : 229.999999642913  Training Accuracy:0.500542888165038\n",
      "The training loss at 1755th epoch : 229.99999964291297  Training Accuracy:0.500542888165038\n",
      "The training loss at 1756th epoch : 229.9999996429129  Training Accuracy:0.500542888165038\n",
      "The training loss at 1757th epoch : 229.99999964291288  Training Accuracy:0.500542888165038\n",
      "The training loss at 1758th epoch : 229.99999964291283  Training Accuracy:0.500542888165038\n",
      "The training loss at 1759th epoch : 229.9999996429128  Training Accuracy:0.500542888165038\n",
      "The training loss at 1760th epoch : 229.99999964291274  Training Accuracy:0.500542888165038\n",
      "The training loss at 1761th epoch : 229.9999996429127  Training Accuracy:0.500542888165038\n",
      "The training loss at 1762th epoch : 229.99999964291266  Training Accuracy:0.500542888165038\n",
      "The training loss at 1763th epoch : 229.9999996429126  Training Accuracy:0.500542888165038\n",
      "The training loss at 1764th epoch : 229.9999996429126  Training Accuracy:0.500542888165038\n",
      "The training loss at 1765th epoch : 229.99999964291254  Training Accuracy:0.500542888165038\n",
      "The training loss at 1766th epoch : 229.99999964291248  Training Accuracy:0.500542888165038\n",
      "The training loss at 1767th epoch : 229.99999964291246  Training Accuracy:0.500542888165038\n",
      "The training loss at 1768th epoch : 229.99999964291243  Training Accuracy:0.500542888165038\n",
      "The training loss at 1769th epoch : 229.99999964291237  Training Accuracy:0.500542888165038\n",
      "The training loss at 1770th epoch : 229.99999964291231  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 1771th epoch : 229.9999996429123  Training Accuracy:0.500542888165038\n",
      "The training loss at 1772th epoch : 229.99999964291223  Training Accuracy:0.500542888165038\n",
      "The training loss at 1773th epoch : 229.9999996429122  Training Accuracy:0.500542888165038\n",
      "The training loss at 1774th epoch : 229.99999964291214  Training Accuracy:0.500542888165038\n",
      "The training loss at 1775th epoch : 229.99999964291212  Training Accuracy:0.500542888165038\n",
      "The training loss at 1776th epoch : 229.99999964291206  Training Accuracy:0.500542888165038\n",
      "The training loss at 1777th epoch : 229.99999964291203  Training Accuracy:0.500542888165038\n",
      "The training loss at 1778th epoch : 229.99999964291197  Training Accuracy:0.500542888165038\n",
      "The training loss at 1779th epoch : 229.99999964291192  Training Accuracy:0.500542888165038\n",
      "The training loss at 1780th epoch : 229.9999996429119  Training Accuracy:0.500542888165038\n",
      "The training loss at 1781th epoch : 229.99999964291186  Training Accuracy:0.500542888165038\n",
      "The training loss at 1782th epoch : 229.9999996429118  Training Accuracy:0.500542888165038\n",
      "The training loss at 1783th epoch : 229.99999964291175  Training Accuracy:0.500542888165038\n",
      "The training loss at 1784th epoch : 229.99999964291172  Training Accuracy:0.500542888165038\n",
      "The training loss at 1785th epoch : 229.9999996429117  Training Accuracy:0.500542888165038\n",
      "The training loss at 1786th epoch : 229.99999964291163  Training Accuracy:0.500542888165038\n",
      "The training loss at 1787th epoch : 229.99999964291158  Training Accuracy:0.500542888165038\n",
      "The training loss at 1788th epoch : 229.99999964291152  Training Accuracy:0.500542888165038\n",
      "The training loss at 1789th epoch : 229.99999964291152  Training Accuracy:0.500542888165038\n",
      "The training loss at 1790th epoch : 229.99999964291146  Training Accuracy:0.500542888165038\n",
      "The training loss at 1791th epoch : 229.9999996429114  Training Accuracy:0.500542888165038\n",
      "The training loss at 1792th epoch : 229.99999964291138  Training Accuracy:0.500542888165038\n",
      "The training loss at 1793th epoch : 229.99999964291135  Training Accuracy:0.500542888165038\n",
      "The training loss at 1794th epoch : 229.9999996429113  Training Accuracy:0.500542888165038\n",
      "The training loss at 1795th epoch : 229.99999964291123  Training Accuracy:0.500542888165038\n",
      "The training loss at 1796th epoch : 229.99999964291118  Training Accuracy:0.500542888165038\n",
      "The training loss at 1797th epoch : 229.99999964291115  Training Accuracy:0.500542888165038\n",
      "The training loss at 1798th epoch : 229.99999964291112  Training Accuracy:0.500542888165038\n",
      "The training loss at 1799th epoch : 229.99999964291106  Training Accuracy:0.500542888165038\n",
      "The training loss at 1800th epoch : 229.999999642911  Training Accuracy:0.500542888165038\n",
      "The training loss at 1801th epoch : 229.99999964291098  Training Accuracy:0.500542888165038\n",
      "The training loss at 1802th epoch : 229.99999964291095  Training Accuracy:0.500542888165038\n",
      "The training loss at 1803th epoch : 229.9999996429109  Training Accuracy:0.500542888165038\n",
      "The training loss at 1804th epoch : 229.99999964291084  Training Accuracy:0.500542888165038\n",
      "The training loss at 1805th epoch : 229.9999996429108  Training Accuracy:0.500542888165038\n",
      "The training loss at 1806th epoch : 229.99999964291078  Training Accuracy:0.500542888165038\n",
      "The training loss at 1807th epoch : 229.99999964291072  Training Accuracy:0.500542888165038\n",
      "The training loss at 1808th epoch : 229.9999996429107  Training Accuracy:0.500542888165038\n",
      "The training loss at 1809th epoch : 229.99999964291064  Training Accuracy:0.500542888165038\n",
      "The training loss at 1810th epoch : 229.9999996429106  Training Accuracy:0.500542888165038\n",
      "The training loss at 1811th epoch : 229.99999964291055  Training Accuracy:0.500542888165038\n",
      "The training loss at 1812th epoch : 229.9999996429105  Training Accuracy:0.500542888165038\n",
      "The training loss at 1813th epoch : 229.99999964291047  Training Accuracy:0.500542888165038\n",
      "The training loss at 1814th epoch : 229.99999964291044  Training Accuracy:0.500542888165038\n",
      "The training loss at 1815th epoch : 229.99999964291038  Training Accuracy:0.500542888165038\n",
      "The training loss at 1816th epoch : 229.99999964291032  Training Accuracy:0.500542888165038\n",
      "The training loss at 1817th epoch : 229.99999964291027  Training Accuracy:0.500542888165038\n",
      "The training loss at 1818th epoch : 229.99999964291024  Training Accuracy:0.500542888165038\n",
      "The training loss at 1819th epoch : 229.9999996429102  Training Accuracy:0.500542888165038\n",
      "The training loss at 1820th epoch : 229.99999964291015  Training Accuracy:0.500542888165038\n",
      "The training loss at 1821th epoch : 229.9999996429101  Training Accuracy:0.500542888165038\n",
      "The training loss at 1822th epoch : 229.9999996429101  Training Accuracy:0.500542888165038\n",
      "The training loss at 1823th epoch : 229.99999964291004  Training Accuracy:0.500542888165038\n",
      "The training loss at 1824th epoch : 229.99999964290998  Training Accuracy:0.500542888165038\n",
      "The training loss at 1825th epoch : 229.99999964290996  Training Accuracy:0.500542888165038\n",
      "The training loss at 1826th epoch : 229.99999964290993  Training Accuracy:0.500542888165038\n",
      "The training loss at 1827th epoch : 229.99999964290987  Training Accuracy:0.500542888165038\n",
      "The training loss at 1828th epoch : 229.9999996429098  Training Accuracy:0.500542888165038\n",
      "The training loss at 1829th epoch : 229.99999964290976  Training Accuracy:0.500542888165038\n",
      "The training loss at 1830th epoch : 229.99999964290973  Training Accuracy:0.500542888165038\n",
      "The training loss at 1831th epoch : 229.99999964290967  Training Accuracy:0.500542888165038\n",
      "The training loss at 1832th epoch : 229.99999964290964  Training Accuracy:0.500542888165038\n",
      "The training loss at 1833th epoch : 229.9999996429096  Training Accuracy:0.500542888165038\n",
      "The training loss at 1834th epoch : 229.99999964290956  Training Accuracy:0.500542888165038\n",
      "The training loss at 1835th epoch : 229.99999964290953  Training Accuracy:0.500542888165038\n",
      "The training loss at 1836th epoch : 229.99999964290947  Training Accuracy:0.500542888165038\n",
      "The training loss at 1837th epoch : 229.99999964290942  Training Accuracy:0.500542888165038\n",
      "The training loss at 1838th epoch : 229.9999996429094  Training Accuracy:0.500542888165038\n",
      "The training loss at 1839th epoch : 229.99999964290933  Training Accuracy:0.500542888165038\n",
      "The training loss at 1840th epoch : 229.9999996429093  Training Accuracy:0.500542888165038\n",
      "The training loss at 1841th epoch : 229.99999964290924  Training Accuracy:0.500542888165038\n",
      "The training loss at 1842th epoch : 229.9999996429092  Training Accuracy:0.500542888165038\n",
      "The training loss at 1843th epoch : 229.99999964290916  Training Accuracy:0.500542888165038\n",
      "The training loss at 1844th epoch : 229.99999964290913  Training Accuracy:0.500542888165038\n",
      "The training loss at 1845th epoch : 229.99999964290907  Training Accuracy:0.500542888165038\n",
      "The training loss at 1846th epoch : 229.99999964290902  Training Accuracy:0.500542888165038\n",
      "The training loss at 1847th epoch : 229.999999642909  Training Accuracy:0.500542888165038\n",
      "The training loss at 1848th epoch : 229.99999964290893  Training Accuracy:0.500542888165038\n",
      "The training loss at 1849th epoch : 229.9999996429089  Training Accuracy:0.500542888165038\n",
      "The training loss at 1850th epoch : 229.99999964290885  Training Accuracy:0.500542888165038\n",
      "The training loss at 1851th epoch : 229.9999996429088  Training Accuracy:0.500542888165038\n",
      "The training loss at 1852th epoch : 229.99999964290876  Training Accuracy:0.500542888165038\n",
      "The training loss at 1853th epoch : 229.99999964290873  Training Accuracy:0.500542888165038\n",
      "The training loss at 1854th epoch : 229.99999964290868  Training Accuracy:0.500542888165038\n",
      "The training loss at 1855th epoch : 229.99999964290862  Training Accuracy:0.500542888165038\n",
      "The training loss at 1856th epoch : 229.99999964290862  Training Accuracy:0.500542888165038\n",
      "The training loss at 1857th epoch : 229.99999964290856  Training Accuracy:0.500542888165038\n",
      "The training loss at 1858th epoch : 229.9999996429085  Training Accuracy:0.500542888165038\n",
      "The training loss at 1859th epoch : 229.99999964290848  Training Accuracy:0.500542888165038\n",
      "The training loss at 1860th epoch : 229.99999964290842  Training Accuracy:0.500542888165038\n",
      "The training loss at 1861th epoch : 229.9999996429084  Training Accuracy:0.500542888165038\n",
      "The training loss at 1862th epoch : 229.99999964290834  Training Accuracy:0.500542888165038\n",
      "The training loss at 1863th epoch : 229.99999964290828  Training Accuracy:0.500542888165038\n",
      "The training loss at 1864th epoch : 229.99999964290825  Training Accuracy:0.500542888165038\n",
      "The training loss at 1865th epoch : 229.9999996429082  Training Accuracy:0.500542888165038\n",
      "The training loss at 1866th epoch : 229.99999964290816  Training Accuracy:0.500542888165038\n",
      "The training loss at 1867th epoch : 229.9999996429081  Training Accuracy:0.500542888165038\n",
      "The training loss at 1868th epoch : 229.99999964290808  Training Accuracy:0.500542888165038\n",
      "The training loss at 1869th epoch : 229.99999964290805  Training Accuracy:0.500542888165038\n",
      "The training loss at 1870th epoch : 229.999999642908  Training Accuracy:0.500542888165038\n",
      "The training loss at 1871th epoch : 229.99999964290794  Training Accuracy:0.500542888165038\n",
      "The training loss at 1872th epoch : 229.9999996429079  Training Accuracy:0.500542888165038\n",
      "The training loss at 1873th epoch : 229.99999964290788  Training Accuracy:0.500542888165038\n",
      "The training loss at 1874th epoch : 229.99999964290782  Training Accuracy:0.500542888165038\n",
      "The training loss at 1875th epoch : 229.99999964290777  Training Accuracy:0.500542888165038\n",
      "The training loss at 1876th epoch : 229.99999964290774  Training Accuracy:0.500542888165038\n",
      "The training loss at 1877th epoch : 229.9999996429077  Training Accuracy:0.500542888165038\n",
      "The training loss at 1878th epoch : 229.99999964290765  Training Accuracy:0.500542888165038\n",
      "The training loss at 1879th epoch : 229.99999964290762  Training Accuracy:0.500542888165038\n",
      "The training loss at 1880th epoch : 229.99999964290757  Training Accuracy:0.500542888165038\n",
      "The training loss at 1881th epoch : 229.9999996429075  Training Accuracy:0.500542888165038\n",
      "The training loss at 1882th epoch : 229.99999964290748  Training Accuracy:0.500542888165038\n",
      "The training loss at 1883th epoch : 229.99999964290743  Training Accuracy:0.500542888165038\n",
      "The training loss at 1884th epoch : 229.9999996429074  Training Accuracy:0.500542888165038\n",
      "The training loss at 1885th epoch : 229.99999964290734  Training Accuracy:0.500542888165038\n",
      "The training loss at 1886th epoch : 229.9999996429073  Training Accuracy:0.500542888165038\n",
      "The training loss at 1887th epoch : 229.99999964290726  Training Accuracy:0.500542888165038\n",
      "The training loss at 1888th epoch : 229.9999996429072  Training Accuracy:0.500542888165038\n",
      "The training loss at 1889th epoch : 229.99999964290717  Training Accuracy:0.500542888165038\n",
      "The training loss at 1890th epoch : 229.9999996429071  Training Accuracy:0.500542888165038\n",
      "The training loss at 1891th epoch : 229.99999964290708  Training Accuracy:0.500542888165038\n",
      "The training loss at 1892th epoch : 229.99999964290703  Training Accuracy:0.500542888165038\n",
      "The training loss at 1893th epoch : 229.99999964290697  Training Accuracy:0.500542888165038\n",
      "The training loss at 1894th epoch : 229.99999964290697  Training Accuracy:0.500542888165038\n",
      "The training loss at 1895th epoch : 229.99999964290691  Training Accuracy:0.500542888165038\n",
      "The training loss at 1896th epoch : 229.99999964290686  Training Accuracy:0.500542888165038\n",
      "The training loss at 1897th epoch : 229.99999964290683  Training Accuracy:0.500542888165038\n",
      "The training loss at 1898th epoch : 229.9999996429068  Training Accuracy:0.500542888165038\n",
      "The training loss at 1899th epoch : 229.99999964290674  Training Accuracy:0.500542888165038\n",
      "The training loss at 1900th epoch : 229.99999964290672  Training Accuracy:0.500542888165038\n",
      "The training loss at 1901th epoch : 229.99999964290666  Training Accuracy:0.500542888165038\n",
      "The training loss at 1902th epoch : 229.9999996429066  Training Accuracy:0.500542888165038\n",
      "The training loss at 1903th epoch : 229.99999964290657  Training Accuracy:0.500542888165038\n",
      "The training loss at 1904th epoch : 229.99999964290652  Training Accuracy:0.500542888165038\n",
      "The training loss at 1905th epoch : 229.99999964290646  Training Accuracy:0.500542888165038\n",
      "The training loss at 1906th epoch : 229.99999964290643  Training Accuracy:0.500542888165038\n",
      "The training loss at 1907th epoch : 229.9999996429064  Training Accuracy:0.500542888165038\n",
      "The training loss at 1908th epoch : 229.99999964290635  Training Accuracy:0.500542888165038\n",
      "The training loss at 1909th epoch : 229.99999964290632  Training Accuracy:0.500542888165038\n",
      "The training loss at 1910th epoch : 229.99999964290626  Training Accuracy:0.500542888165038\n",
      "The training loss at 1911th epoch : 229.99999964290623  Training Accuracy:0.500542888165038\n",
      "The training loss at 1912th epoch : 229.99999964290618  Training Accuracy:0.500542888165038\n",
      "The training loss at 1913th epoch : 229.99999964290612  Training Accuracy:0.500542888165038\n",
      "The training loss at 1914th epoch : 229.9999996429061  Training Accuracy:0.500542888165038\n",
      "The training loss at 1915th epoch : 229.99999964290603  Training Accuracy:0.500542888165038\n",
      "The training loss at 1916th epoch : 229.999999642906  Training Accuracy:0.500542888165038\n",
      "The training loss at 1917th epoch : 229.99999964290595  Training Accuracy:0.500542888165038\n",
      "The training loss at 1918th epoch : 229.99999964290595  Training Accuracy:0.500542888165038\n",
      "The training loss at 1919th epoch : 229.9999996429059  Training Accuracy:0.500542888165038\n",
      "The training loss at 1920th epoch : 229.99999964290583  Training Accuracy:0.500542888165038\n",
      "The training loss at 1921th epoch : 229.99999964290578  Training Accuracy:0.500542888165038\n",
      "The training loss at 1922th epoch : 229.99999964290572  Training Accuracy:0.500542888165038\n",
      "The training loss at 1923th epoch : 229.99999964290572  Training Accuracy:0.500542888165038\n",
      "The training loss at 1924th epoch : 229.99999964290566  Training Accuracy:0.500542888165038\n",
      "The training loss at 1925th epoch : 229.9999996429056  Training Accuracy:0.500542888165038\n",
      "The training loss at 1926th epoch : 229.99999964290558  Training Accuracy:0.500542888165038\n",
      "The training loss at 1927th epoch : 229.99999964290552  Training Accuracy:0.500542888165038\n",
      "The training loss at 1928th epoch : 229.9999996429055  Training Accuracy:0.500542888165038\n",
      "The training loss at 1929th epoch : 229.99999964290544  Training Accuracy:0.500542888165038\n",
      "The training loss at 1930th epoch : 229.9999996429054  Training Accuracy:0.500542888165038\n",
      "The training loss at 1931th epoch : 229.99999964290535  Training Accuracy:0.500542888165038\n",
      "The training loss at 1932th epoch : 229.99999964290532  Training Accuracy:0.500542888165038\n",
      "The training loss at 1933th epoch : 229.99999964290527  Training Accuracy:0.500542888165038\n",
      "The training loss at 1934th epoch : 229.9999996429052  Training Accuracy:0.500542888165038\n",
      "The training loss at 1935th epoch : 229.99999964290518  Training Accuracy:0.500542888165038\n",
      "The training loss at 1936th epoch : 229.99999964290515  Training Accuracy:0.500542888165038\n",
      "The training loss at 1937th epoch : 229.9999996429051  Training Accuracy:0.500542888165038\n",
      "The training loss at 1938th epoch : 229.99999964290504  Training Accuracy:0.500542888165038\n",
      "The training loss at 1939th epoch : 229.99999964290498  Training Accuracy:0.500542888165038\n",
      "The training loss at 1940th epoch : 229.99999964290498  Training Accuracy:0.500542888165038\n",
      "The training loss at 1941th epoch : 229.99999964290492  Training Accuracy:0.500542888165038\n",
      "The training loss at 1942th epoch : 229.99999964290487  Training Accuracy:0.500542888165038\n",
      "The training loss at 1943th epoch : 229.99999964290484  Training Accuracy:0.500542888165038\n",
      "The training loss at 1944th epoch : 229.9999996429048  Training Accuracy:0.500542888165038\n",
      "The training loss at 1945th epoch : 229.99999964290475  Training Accuracy:0.500542888165038\n",
      "The training loss at 1946th epoch : 229.9999996429047  Training Accuracy:0.500542888165038\n",
      "The training loss at 1947th epoch : 229.99999964290467  Training Accuracy:0.500542888165038\n",
      "The training loss at 1948th epoch : 229.99999964290464  Training Accuracy:0.500542888165038\n",
      "The training loss at 1949th epoch : 229.99999964290458  Training Accuracy:0.500542888165038\n",
      "The training loss at 1950th epoch : 229.99999964290453  Training Accuracy:0.500542888165038\n",
      "The training loss at 1951th epoch : 229.99999964290447  Training Accuracy:0.500542888165038\n",
      "The training loss at 1952th epoch : 229.99999964290444  Training Accuracy:0.500542888165038\n",
      "The training loss at 1953th epoch : 229.9999996429044  Training Accuracy:0.500542888165038\n",
      "The training loss at 1954th epoch : 229.99999964290436  Training Accuracy:0.500542888165038\n",
      "The training loss at 1955th epoch : 229.9999996429043  Training Accuracy:0.500542888165038\n",
      "The training loss at 1956th epoch : 229.99999964290427  Training Accuracy:0.500542888165038\n",
      "The training loss at 1957th epoch : 229.99999964290424  Training Accuracy:0.500542888165038\n",
      "The training loss at 1958th epoch : 229.99999964290419  Training Accuracy:0.500542888165038\n",
      "The training loss at 1959th epoch : 229.99999964290413  Training Accuracy:0.500542888165038\n",
      "The training loss at 1960th epoch : 229.9999996429041  Training Accuracy:0.500542888165038\n",
      "The training loss at 1961th epoch : 229.99999964290404  Training Accuracy:0.500542888165038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss at 1962th epoch : 229.99999964290402  Training Accuracy:0.500542888165038\n",
      "The training loss at 1963th epoch : 229.99999964290396  Training Accuracy:0.500542888165038\n",
      "The training loss at 1964th epoch : 229.9999996429039  Training Accuracy:0.500542888165038\n",
      "The training loss at 1965th epoch : 229.99999964290387  Training Accuracy:0.500542888165038\n",
      "The training loss at 1966th epoch : 229.99999964290384  Training Accuracy:0.500542888165038\n",
      "The training loss at 1967th epoch : 229.9999996429038  Training Accuracy:0.500542888165038\n",
      "The training loss at 1968th epoch : 229.99999964290373  Training Accuracy:0.500542888165038\n",
      "The training loss at 1969th epoch : 229.9999996429037  Training Accuracy:0.500542888165038\n",
      "The training loss at 1970th epoch : 229.99999964290367  Training Accuracy:0.500542888165038\n",
      "The training loss at 1971th epoch : 229.99999964290362  Training Accuracy:0.500542888165038\n",
      "The training loss at 1972th epoch : 229.9999996429036  Training Accuracy:0.500542888165038\n",
      "The training loss at 1973th epoch : 229.99999964290356  Training Accuracy:0.500542888165038\n",
      "The training loss at 1974th epoch : 229.9999996429035  Training Accuracy:0.500542888165038\n",
      "The training loss at 1975th epoch : 229.99999964290345  Training Accuracy:0.500542888165038\n",
      "The training loss at 1976th epoch : 229.99999964290342  Training Accuracy:0.500542888165038\n",
      "The training loss at 1977th epoch : 229.99999964290336  Training Accuracy:0.500542888165038\n",
      "The training loss at 1978th epoch : 229.9999996429033  Training Accuracy:0.500542888165038\n",
      "The training loss at 1979th epoch : 229.99999964290328  Training Accuracy:0.500542888165038\n",
      "The training loss at 1980th epoch : 229.99999964290322  Training Accuracy:0.500542888165038\n",
      "The training loss at 1981th epoch : 229.99999964290316  Training Accuracy:0.500542888165038\n",
      "The training loss at 1982th epoch : 229.99999964290313  Training Accuracy:0.500542888165038\n",
      "The training loss at 1983th epoch : 229.9999996429031  Training Accuracy:0.500542888165038\n",
      "The training loss at 1984th epoch : 229.99999964290305  Training Accuracy:0.500542888165038\n",
      "The training loss at 1985th epoch : 229.99999964290305  Training Accuracy:0.500542888165038\n",
      "The training loss at 1986th epoch : 229.999999642903  Training Accuracy:0.500542888165038\n",
      "The training loss at 1987th epoch : 229.99999964290294  Training Accuracy:0.500542888165038\n",
      "The training loss at 1988th epoch : 229.99999964290288  Training Accuracy:0.500542888165038\n",
      "The training loss at 1989th epoch : 229.99999964290288  Training Accuracy:0.500542888165038\n",
      "The training loss at 1990th epoch : 229.99999964290282  Training Accuracy:0.500542888165038\n",
      "The training loss at 1991th epoch : 229.99999964290276  Training Accuracy:0.500542888165038\n",
      "The training loss at 1992th epoch : 229.9999996429027  Training Accuracy:0.500542888165038\n",
      "The training loss at 1993th epoch : 229.99999964290268  Training Accuracy:0.500542888165038\n",
      "The training loss at 1994th epoch : 229.99999964290262  Training Accuracy:0.500542888165038\n",
      "The training loss at 1995th epoch : 229.9999996429026  Training Accuracy:0.500542888165038\n",
      "The training loss at 1996th epoch : 229.99999964290254  Training Accuracy:0.500542888165038\n",
      "The training loss at 1997th epoch : 229.99999964290248  Training Accuracy:0.500542888165038\n",
      "The training loss at 1998th epoch : 229.99999964290245  Training Accuracy:0.500542888165038\n",
      "The training loss at 1999th epoch : 229.99999964290242  Training Accuracy:0.500542888165038\n"
     ]
    }
   ],
   "source": [
    "train(model ,loss_m,X_train,Y_train , 2000,alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:0.500542888165038\n",
      "Test accuracy:0.49514563106796117\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy:{}\".format(accuracy(model,X_train, Y_train)))\n",
    "\n",
    "print(\"Test accuracy:{}\".format(accuracy(model,X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
