{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.seterr('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am building a normal forward propogation for a perceptron layer\n",
    "# and the various function i would use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Declaring Training Data        ############\n",
    "#############################################\n",
    "X_train = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "Y_train = np.array([[1],[0],[0],[0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultiLayerPerceptron import MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model , X , Y):\n",
    "    pred,_ = model.forward(X)\n",
    "    pred =pred > 0.5\n",
    "    acc = np.sum(pred == Y)\n",
    "    acc = float(acc) / Y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1) (1,)\n",
      "<function sigmoid at 0x7f0ee8a90378>\n"
     ]
    }
   ],
   "source": [
    "# Declare a neuron with shape of weights as [shape_of_input,1]\n",
    "model = MultiLayerPerceptron([2,1],['sigmoid'])\n",
    "# print(model.layers[1].W)\n",
    "# print(model.layers[1].b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model outputs\n",
    "pred , _ = model.forward(X_train)\n",
    "# print(np.sum((pred > 0.5)== Y_train) / Y_train.shape[0])\n",
    "# accuracy(model , X_train,Y_train)\n",
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is [0.15377332]\n",
      "And the error to be back propogated is:\n",
      " [[-0.125     ]\n",
      " [ 0.16124503]\n",
      " [ 0.11302115]\n",
      " [ 0.14995973]]\n"
     ]
    }
   ],
   "source": [
    "# Checking for testing purposes(BCE should be used here ideally)\n",
    "from Loss import mean_abs_error,mean_square_error\n",
    "loss,d_back = mean_square_error(pred,Y_train)\n",
    "print(\"The loss is {}\\nAnd the error to be back propogated is:\\n {}\".format(loss , d_back))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is [3.24625113]\n",
      "And the error to be back propogated is:\n",
      " [[-2.        ]\n",
      " [ 2.81674354]\n",
      " [ 1.82509925]\n",
      " [ 2.49899372]]\n"
     ]
    }
   ],
   "source": [
    "from Loss import binary_cross_entropy\n",
    "loss,d_back = binary_cross_entropy(pred,Y_train)\n",
    "print(\"The loss is {}\\nAnd the error to be back propogated is:\\n {}\".format(loss , d_back))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) (3,)\n",
      "<function sigmoid at 0x7f0ee8a90378>\n",
      "(3, 1) (1,)\n",
      "<function sigmoid at 0x7f0ee8a90378>\n",
      "The training loss at 0th epoch : [2.28988323]  Training Accuracy:0.75\n",
      "The training loss at 1th epoch : [2.09854785]  Training Accuracy:0.75\n",
      "The training loss at 2th epoch : [1.96345838]  Training Accuracy:0.75\n",
      "The training loss at 3th epoch : [1.85680762]  Training Accuracy:0.75\n",
      "The training loss at 4th epoch : [1.76139773]  Training Accuracy:0.75\n",
      "The training loss at 5th epoch : [1.66815315]  Training Accuracy:0.75\n",
      "The training loss at 6th epoch : [1.57297909]  Training Accuracy:0.75\n",
      "The training loss at 7th epoch : [1.47463612]  Training Accuracy:0.75\n",
      "The training loss at 8th epoch : [1.37352834]  Training Accuracy:0.75\n",
      "The training loss at 9th epoch : [1.27100815]  Training Accuracy:0.75\n"
     ]
    }
   ],
   "source": [
    "# Now we can train the model by iteratively on each datapoint.\n",
    "\n",
    "layer_list = [2,3, 1]\n",
    "activation_list = ['sigmoid','sigmoid']\n",
    "model = MultiLayerPerceptron(layer_list,activation_list)\n",
    "\n",
    "def train(model ,X_train , Y_train,epochs,alpha =0.1):\n",
    "    for i in range(epochs):\n",
    "        act , cache = model.forward(X_train)\n",
    "        loss,d_back= binary_cross_entropy(act,Y_train)\n",
    "        acc = accuracy(model ,X_train,Y_train)\n",
    "        print(\"The training loss at {}th epoch : {}  Training Accuracy:{}\".format(i , loss , acc))\n",
    "        model.update_gradient(cache,d_back,alpha)        \n",
    "\n",
    "train(model , X_train,Y_train , 10,alpha = 0.4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can predict the values for unseen data or trained data also\n",
    "# We can also calculate the accuracy of the model we have trained\n",
    "accuracy(model , X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N Bit XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Lets try working with just a little better data. A n XOR operator. So lets create the dataset for n bit xor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would have atmost 2^n data point in this type of data set.BUt we would limit our dataset to a 1000 data points\n",
    "whichever is smaller.\n",
    "\n",
    "Then we can divide into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 10\n",
    "max_datapoint = 10000\n",
    "datapoints = min(pow(2,n) , max_datapoint)\n",
    "\n",
    "X = np.zeros((datapoints , n) , dtype=np.int32)\n",
    "Y = np.zeros((datapoints , 1), dtype=np.int32)\n",
    "\n",
    "for i in range(datapoints):\n",
    "    tmp = i\n",
    "    y_tmp = 0\n",
    "    for j in range(n-1 , -1 , -1):\n",
    "        X[i,j] = tmp&1\n",
    "        y_tmp = y_tmp^X[i,j]\n",
    "        tmp = tmp>>1\n",
    "    Y[i] = y_tmp\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 1] [1]\n"
     ]
    }
   ],
   "source": [
    "# for sanity check lets print one example\n",
    "ind = 11\n",
    "print(X[ind] , Y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets divide the set in training and testing\n",
    "div = 0.9\n",
    "train_n = int(div * datapoints)\n",
    "X_train = X[:train_n]\n",
    "Y_train = Y[:train_n]\n",
    "\n",
    "X_test = X[train_n:]\n",
    "Y_test = Y[train_n:]\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8) (8,)\n",
      "<function sigmoid at 0x7f1fe57bd840>\n",
      "(8, 2) (2,)\n",
      "<function relu at 0x7f1fc631a620>\n",
      "(2, 1) (1,)\n",
      "<function sigmoid at 0x7f1fe57bd840>\n"
     ]
    }
   ],
   "source": [
    "layer_list = [n,8,2,1]\n",
    "activation_list = ['sigmoid','relu','sigmoid']\n",
    "\n",
    "model = MultiLayerPerceptron(layer_list,activation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0116a5809927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-6e8e1d2934f4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X_train, Y_train, epochs, alpha)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mact\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_back\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mehul/New Volume/DC++/Study/Sem 3-2/NNFl/Neural-Network-Assignments/Assignment-3/MultiLayerPerceptron.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X_train)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mehul/New Volume/DC++/Study/Sem 3-2/NNFl/Neural-Network-Assignments/Assignment-3/MultiLayerPerceptron.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mh_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# print(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mehul/New Volume/DC++/Study/Sem 3-2/NNFl/Neural-Network-Assignments/Assignment-3/Activations.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "train(model,X_train,Y_train , 2000,alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:0.500542888165038\n",
      "Test accuracy:0.49514563106796117\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy:{}\".format(accuracy(model,X_train, Y_train)))\n",
    "\n",
    "print(\"Test accuracy:{}\".format(accuracy(model,X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
