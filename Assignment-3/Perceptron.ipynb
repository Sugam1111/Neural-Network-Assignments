{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "np.seterr('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultiLayerPerceptron import MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(epoch_his, train_loss_his, test_loss_his):\n",
    "    train_line, = plt.plot(epoch_his,train_loss_his,label = 'train')\n",
    "    test_line, = plt.plot(epoch_his,test_loss_his,label = 'test')\n",
    "    plt.xlabel('EPOCHS')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend([train_line, test_line] , ['train','test'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(epoch_his, train_acc_his, test_acc_his):\n",
    "    train_line, = plt.plot(epoch_his,train_acc_his,label = 'train')\n",
    "    test_line, = plt.plot(epoch_his,test_acc_his,label = 'test')\n",
    "    plt.xlabel('EPOCHS')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend([train_line, test_line] , ['train','test'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am building a normal forward propogation for a perceptron layer\n",
    "# and the various function i would use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Declaring Training Data        ############\n",
    "#############################################\n",
    "X_train = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "Y_train = np.array([[1],[0],[0],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1) (1,)\n",
      "<function sigmoid at 0x7f1c106109d8>\n"
     ]
    }
   ],
   "source": [
    "# Declare a neuron with shape of weights as [shape_of_input,1]\n",
    "model = MultiLayerPerceptron([2,1],['sigmoid'])\n",
    "# print(model.layers[1].W)\n",
    "# print(model.layers[1].b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model outputs\n",
    "pred , _ = model.forward(X_train)\n",
    "# print(np.sum((pred > 0.5)== Y_train) / Y_train.shape[0])\n",
    "# accuracy(model , X_train,Y_train)\n",
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is [0.24392534]\n",
      "And the error to be back propogated is:\n",
      " [[-0.125     ]\n",
      " [ 0.17977535]\n",
      " [ 0.17087618]\n",
      " [ 0.21170693]]\n"
     ]
    }
   ],
   "source": [
    "# Checking for testing purposes(BCE should be used here ideally)\n",
    "from Loss import mean_abs_error,mean_square_error\n",
    "loss,d_back = mean_square_error(pred,Y_train)\n",
    "print(\"The loss is {}\\nAnd the error to be back propogated is:\\n {}\".format(loss , d_back))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss is [4.98954764]\n",
      "And the error to be back propogated is:\n",
      " [[-2.        ]\n",
      " [ 3.56000351]\n",
      " [ 3.15960491]\n",
      " [ 6.52859617]]\n"
     ]
    }
   ],
   "source": [
    "from Loss import binary_cross_entropy,mean_binary_cross_entropy\n",
    "loss,d_back = binary_cross_entropy(pred,Y_train)\n",
    "print(\"The loss is {}\\nAnd the error to be back propogated is:\\n {}\".format(loss , d_back))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) (3,)\n",
      "<function sigmoid at 0x7f1c106109d8>\n",
      "(3, 1) (1,)\n",
      "<function sigmoid at 0x7f1c106109d8>\n",
      "0th EPOCH:\n",
      "Training Loss:[1.36303916]|Training Accuracy:0.25|Test Loss:[1.28001308]|Test Accuracy:0.25\n",
      "1th EPOCH:\n",
      "Training Loss:[1.28001308]|Training Accuracy:0.25|Test Loss:[1.20468821]|Test Accuracy:0.25\n",
      "2th EPOCH:\n",
      "Training Loss:[1.20468821]|Training Accuracy:0.25|Test Loss:[1.13657694]|Test Accuracy:0.25\n",
      "3th EPOCH:\n",
      "Training Loss:[1.13657694]|Training Accuracy:0.25|Test Loss:[1.0751673]|Test Accuracy:0.25\n",
      "4th EPOCH:\n",
      "Training Loss:[1.0751673]|Training Accuracy:0.25|Test Loss:[1.01993657]|Test Accuracy:0.25\n",
      "5th EPOCH:\n",
      "Training Loss:[1.01993657]|Training Accuracy:0.25|Test Loss:[0.97036373]|Test Accuracy:0.25\n",
      "6th EPOCH:\n",
      "Training Loss:[0.97036373]|Training Accuracy:0.25|Test Loss:[0.92594025]|Test Accuracy:0.25\n",
      "7th EPOCH:\n",
      "Training Loss:[0.92594025]|Training Accuracy:0.25|Test Loss:[0.88617864]|Test Accuracy:0.25\n",
      "8th EPOCH:\n",
      "Training Loss:[0.88617864]|Training Accuracy:0.25|Test Loss:[0.85061874]|Test Accuracy:0.25\n",
      "9th EPOCH:\n",
      "Training Loss:[0.85061874]|Training Accuracy:0.25|Test Loss:[0.81883181]|Test Accuracy:0.25\n",
      "10th EPOCH:\n",
      "Training Loss:[0.81883181]|Training Accuracy:0.25|Test Loss:[0.79042283]|Test Accuracy:0.25\n",
      "11th EPOCH:\n",
      "Training Loss:[0.79042283]|Training Accuracy:0.25|Test Loss:[0.76503113]|Test Accuracy:0.25\n",
      "12th EPOCH:\n",
      "Training Loss:[0.76503113]|Training Accuracy:0.25|Test Loss:[0.74232989]|Test Accuracy:0.0\n",
      "13th EPOCH:\n",
      "Training Loss:[0.74232989]|Training Accuracy:0.0|Test Loss:[0.72202482]|Test Accuracy:0.0\n",
      "14th EPOCH:\n",
      "Training Loss:[0.72202482]|Training Accuracy:0.0|Test Loss:[0.70385219]|Test Accuracy:0.5\n",
      "15th EPOCH:\n",
      "Training Loss:[0.70385219]|Training Accuracy:0.5|Test Loss:[0.68757658]|Test Accuracy:0.75\n",
      "16th EPOCH:\n",
      "Training Loss:[0.68757658]|Training Accuracy:0.75|Test Loss:[0.67298847]|Test Accuracy:0.75\n",
      "17th EPOCH:\n",
      "Training Loss:[0.67298847]|Training Accuracy:0.75|Test Loss:[0.6599018]|Test Accuracy:0.75\n",
      "18th EPOCH:\n",
      "Training Loss:[0.6599018]|Training Accuracy:0.75|Test Loss:[0.6481516]|Test Accuracy:0.75\n",
      "19th EPOCH:\n",
      "Training Loss:[0.6481516]|Training Accuracy:0.75|Test Loss:[0.63759173]|Test Accuracy:0.75\n",
      "20th EPOCH:\n",
      "Training Loss:[0.63759173]|Training Accuracy:0.75|Test Loss:[0.62809283]|Test Accuracy:0.75\n",
      "21th EPOCH:\n",
      "Training Loss:[0.62809283]|Training Accuracy:0.75|Test Loss:[0.61954038]|Test Accuracy:0.75\n",
      "22th EPOCH:\n",
      "Training Loss:[0.61954038]|Training Accuracy:0.75|Test Loss:[0.61183299]|Test Accuracy:0.75\n",
      "23th EPOCH:\n",
      "Training Loss:[0.61183299]|Training Accuracy:0.75|Test Loss:[0.60488087]|Test Accuracy:0.75\n",
      "24th EPOCH:\n",
      "Training Loss:[0.60488087]|Training Accuracy:0.75|Test Loss:[0.59860443]|Test Accuracy:0.75\n",
      "25th EPOCH:\n",
      "Training Loss:[0.59860443]|Training Accuracy:0.75|Test Loss:[0.5929331]|Test Accuracy:0.75\n",
      "26th EPOCH:\n",
      "Training Loss:[0.5929331]|Training Accuracy:0.75|Test Loss:[0.58780421]|Test Accuracy:0.75\n",
      "27th EPOCH:\n",
      "Training Loss:[0.58780421]|Training Accuracy:0.75|Test Loss:[0.58316206]|Test Accuracy:0.75\n",
      "28th EPOCH:\n",
      "Training Loss:[0.58316206]|Training Accuracy:0.75|Test Loss:[0.5789571]|Test Accuracy:0.75\n",
      "29th EPOCH:\n",
      "Training Loss:[0.5789571]|Training Accuracy:0.75|Test Loss:[0.57514519]|Test Accuracy:0.75\n",
      "30th EPOCH:\n",
      "Training Loss:[0.57514519]|Training Accuracy:0.75|Test Loss:[0.57168696]|Test Accuracy:0.75\n",
      "31th EPOCH:\n",
      "Training Loss:[0.57168696]|Training Accuracy:0.75|Test Loss:[0.56854726]|Test Accuracy:0.75\n",
      "32th EPOCH:\n",
      "Training Loss:[0.56854726]|Training Accuracy:0.75|Test Loss:[0.56569465]|Test Accuracy:0.75\n",
      "33th EPOCH:\n",
      "Training Loss:[0.56569465]|Training Accuracy:0.75|Test Loss:[0.56310099]|Test Accuracy:0.75\n",
      "34th EPOCH:\n",
      "Training Loss:[0.56310099]|Training Accuracy:0.75|Test Loss:[0.56074104]|Test Accuracy:0.75\n",
      "35th EPOCH:\n",
      "Training Loss:[0.56074104]|Training Accuracy:0.75|Test Loss:[0.55859218]|Test Accuracy:0.75\n",
      "36th EPOCH:\n",
      "Training Loss:[0.55859218]|Training Accuracy:0.75|Test Loss:[0.55663404]|Test Accuracy:0.75\n",
      "37th EPOCH:\n",
      "Training Loss:[0.55663404]|Training Accuracy:0.75|Test Loss:[0.55484831]|Test Accuracy:0.75\n",
      "38th EPOCH:\n",
      "Training Loss:[0.55484831]|Training Accuracy:0.75|Test Loss:[0.55321851]|Test Accuracy:0.75\n",
      "39th EPOCH:\n",
      "Training Loss:[0.55321851]|Training Accuracy:0.75|Test Loss:[0.55172974]|Test Accuracy:0.75\n",
      "40th EPOCH:\n",
      "Training Loss:[0.55172974]|Training Accuracy:0.75|Test Loss:[0.55036858]|Test Accuracy:0.75\n",
      "41th EPOCH:\n",
      "Training Loss:[0.55036858]|Training Accuracy:0.75|Test Loss:[0.54912288]|Test Accuracy:0.75\n",
      "42th EPOCH:\n",
      "Training Loss:[0.54912288]|Training Accuracy:0.75|Test Loss:[0.54798166]|Test Accuracy:0.75\n",
      "43th EPOCH:\n",
      "Training Loss:[0.54798166]|Training Accuracy:0.75|Test Loss:[0.54693495]|Test Accuracy:0.75\n",
      "44th EPOCH:\n",
      "Training Loss:[0.54693495]|Training Accuracy:0.75|Test Loss:[0.54597373]|Test Accuracy:0.75\n",
      "45th EPOCH:\n",
      "Training Loss:[0.54597373]|Training Accuracy:0.75|Test Loss:[0.5450898]|Test Accuracy:0.75\n",
      "46th EPOCH:\n",
      "Training Loss:[0.5450898]|Training Accuracy:0.75|Test Loss:[0.54427572]|Test Accuracy:0.75\n",
      "47th EPOCH:\n",
      "Training Loss:[0.54427572]|Training Accuracy:0.75|Test Loss:[0.54352472]|Test Accuracy:0.75\n",
      "48th EPOCH:\n",
      "Training Loss:[0.54352472]|Training Accuracy:0.75|Test Loss:[0.54283064]|Test Accuracy:0.75\n",
      "49th EPOCH:\n",
      "Training Loss:[0.54283064]|Training Accuracy:0.75|Test Loss:[0.54218786]|Test Accuracy:0.75\n",
      "50th EPOCH:\n",
      "Training Loss:[0.54218786]|Training Accuracy:0.75|Test Loss:[0.54159127]|Test Accuracy:0.75\n",
      "51th EPOCH:\n",
      "Training Loss:[0.54159127]|Training Accuracy:0.75|Test Loss:[0.5410362]|Test Accuracy:0.75\n",
      "52th EPOCH:\n",
      "Training Loss:[0.5410362]|Training Accuracy:0.75|Test Loss:[0.54051839]|Test Accuracy:0.75\n",
      "53th EPOCH:\n",
      "Training Loss:[0.54051839]|Training Accuracy:0.75|Test Loss:[0.54003395]|Test Accuracy:0.75\n",
      "54th EPOCH:\n",
      "Training Loss:[0.54003395]|Training Accuracy:0.75|Test Loss:[0.53957933]|Test Accuracy:0.75\n",
      "55th EPOCH:\n",
      "Training Loss:[0.53957933]|Training Accuracy:0.75|Test Loss:[0.53915126]|Test Accuracy:0.75\n",
      "56th EPOCH:\n",
      "Training Loss:[0.53915126]|Training Accuracy:0.75|Test Loss:[0.53874678]|Test Accuracy:0.75\n",
      "57th EPOCH:\n",
      "Training Loss:[0.53874678]|Training Accuracy:0.75|Test Loss:[0.53836315]|Test Accuracy:0.75\n",
      "58th EPOCH:\n",
      "Training Loss:[0.53836315]|Training Accuracy:0.75|Test Loss:[0.53799788]|Test Accuracy:0.75\n",
      "59th EPOCH:\n",
      "Training Loss:[0.53799788]|Training Accuracy:0.75|Test Loss:[0.53764868]|Test Accuracy:0.75\n",
      "60th EPOCH:\n",
      "Training Loss:[0.53764868]|Training Accuracy:0.75|Test Loss:[0.53731346]|Test Accuracy:0.75\n",
      "61th EPOCH:\n",
      "Training Loss:[0.53731346]|Training Accuracy:0.75|Test Loss:[0.53699028]|Test Accuracy:0.75\n",
      "62th EPOCH:\n",
      "Training Loss:[0.53699028]|Training Accuracy:0.75|Test Loss:[0.53667739]|Test Accuracy:0.75\n",
      "63th EPOCH:\n",
      "Training Loss:[0.53667739]|Training Accuracy:0.75|Test Loss:[0.53637317]|Test Accuracy:0.75\n",
      "64th EPOCH:\n",
      "Training Loss:[0.53637317]|Training Accuracy:0.75|Test Loss:[0.53607613]|Test Accuracy:0.75\n",
      "65th EPOCH:\n",
      "Training Loss:[0.53607613]|Training Accuracy:0.75|Test Loss:[0.5357849]|Test Accuracy:0.75\n",
      "66th EPOCH:\n",
      "Training Loss:[0.5357849]|Training Accuracy:0.75|Test Loss:[0.53549824]|Test Accuracy:0.75\n",
      "67th EPOCH:\n",
      "Training Loss:[0.53549824]|Training Accuracy:0.75|Test Loss:[0.53521499]|Test Accuracy:0.75\n",
      "68th EPOCH:\n",
      "Training Loss:[0.53521499]|Training Accuracy:0.75|Test Loss:[0.5349341]|Test Accuracy:0.75\n",
      "69th EPOCH:\n",
      "Training Loss:[0.5349341]|Training Accuracy:0.75|Test Loss:[0.5346546]|Test Accuracy:0.75\n",
      "70th EPOCH:\n",
      "Training Loss:[0.5346546]|Training Accuracy:0.75|Test Loss:[0.53437558]|Test Accuracy:0.75\n",
      "71th EPOCH:\n",
      "Training Loss:[0.53437558]|Training Accuracy:0.75|Test Loss:[0.53409625]|Test Accuracy:0.75\n",
      "72th EPOCH:\n",
      "Training Loss:[0.53409625]|Training Accuracy:0.75|Test Loss:[0.53381584]|Test Accuracy:0.75\n",
      "73th EPOCH:\n",
      "Training Loss:[0.53381584]|Training Accuracy:0.75|Test Loss:[0.53353367]|Test Accuracy:0.75\n",
      "74th EPOCH:\n",
      "Training Loss:[0.53353367]|Training Accuracy:0.75|Test Loss:[0.5332491]|Test Accuracy:0.75\n",
      "75th EPOCH:\n",
      "Training Loss:[0.5332491]|Training Accuracy:0.75|Test Loss:[0.53296154]|Test Accuracy:0.75\n",
      "76th EPOCH:\n",
      "Training Loss:[0.53296154]|Training Accuracy:0.75|Test Loss:[0.53267048]|Test Accuracy:0.75\n",
      "77th EPOCH:\n",
      "Training Loss:[0.53267048]|Training Accuracy:0.75|Test Loss:[0.53237541]|Test Accuracy:0.75\n",
      "78th EPOCH:\n",
      "Training Loss:[0.53237541]|Training Accuracy:0.75|Test Loss:[0.53207589]|Test Accuracy:0.75\n",
      "79th EPOCH:\n",
      "Training Loss:[0.53207589]|Training Accuracy:0.75|Test Loss:[0.53177151]|Test Accuracy:0.75\n",
      "80th EPOCH:\n",
      "Training Loss:[0.53177151]|Training Accuracy:0.75|Test Loss:[0.53146189]|Test Accuracy:0.75\n",
      "81th EPOCH:\n",
      "Training Loss:[0.53146189]|Training Accuracy:0.75|Test Loss:[0.53114668]|Test Accuracy:0.75\n",
      "82th EPOCH:\n",
      "Training Loss:[0.53114668]|Training Accuracy:0.75|Test Loss:[0.53082558]|Test Accuracy:0.75\n",
      "83th EPOCH:\n",
      "Training Loss:[0.53082558]|Training Accuracy:0.75|Test Loss:[0.53049828]|Test Accuracy:0.75\n",
      "84th EPOCH:\n",
      "Training Loss:[0.53049828]|Training Accuracy:0.75|Test Loss:[0.53016453]|Test Accuracy:0.75\n",
      "85th EPOCH:\n",
      "Training Loss:[0.53016453]|Training Accuracy:0.75|Test Loss:[0.52982409]|Test Accuracy:0.75\n",
      "86th EPOCH:\n",
      "Training Loss:[0.52982409]|Training Accuracy:0.75|Test Loss:[0.52947674]|Test Accuracy:0.75\n",
      "87th EPOCH:\n",
      "Training Loss:[0.52947674]|Training Accuracy:0.75|Test Loss:[0.52912227]|Test Accuracy:0.75\n",
      "88th EPOCH:\n",
      "Training Loss:[0.52912227]|Training Accuracy:0.75|Test Loss:[0.52876051]|Test Accuracy:0.75\n",
      "89th EPOCH:\n",
      "Training Loss:[0.52876051]|Training Accuracy:0.75|Test Loss:[0.52839129]|Test Accuracy:0.75\n",
      "90th EPOCH:\n",
      "Training Loss:[0.52839129]|Training Accuracy:0.75|Test Loss:[0.52801446]|Test Accuracy:0.75\n",
      "91th EPOCH:\n",
      "Training Loss:[0.52801446]|Training Accuracy:0.75|Test Loss:[0.52762988]|Test Accuracy:0.75\n",
      "92th EPOCH:\n",
      "Training Loss:[0.52762988]|Training Accuracy:0.75|Test Loss:[0.52723743]|Test Accuracy:0.75\n",
      "93th EPOCH:\n",
      "Training Loss:[0.52723743]|Training Accuracy:0.75|Test Loss:[0.52683701]|Test Accuracy:0.75\n",
      "94th EPOCH:\n",
      "Training Loss:[0.52683701]|Training Accuracy:0.75|Test Loss:[0.5264285]|Test Accuracy:0.75\n",
      "95th EPOCH:\n",
      "Training Loss:[0.5264285]|Training Accuracy:0.75|Test Loss:[0.52601182]|Test Accuracy:0.75\n",
      "96th EPOCH:\n",
      "Training Loss:[0.52601182]|Training Accuracy:0.75|Test Loss:[0.52558689]|Test Accuracy:0.75\n",
      "97th EPOCH:\n",
      "Training Loss:[0.52558689]|Training Accuracy:0.75|Test Loss:[0.52515364]|Test Accuracy:0.75\n",
      "98th EPOCH:\n",
      "Training Loss:[0.52515364]|Training Accuracy:0.75|Test Loss:[0.524712]|Test Accuracy:0.75\n",
      "99th EPOCH:\n",
      "Training Loss:[0.524712]|Training Accuracy:0.75|Test Loss:[0.52426192]|Test Accuracy:0.75\n",
      "100th EPOCH:\n",
      "Training Loss:[0.52426192]|Training Accuracy:0.75|Test Loss:[0.52380334]|Test Accuracy:0.75\n",
      "101th EPOCH:\n",
      "Training Loss:[0.52380334]|Training Accuracy:0.75|Test Loss:[0.52333622]|Test Accuracy:0.75\n",
      "102th EPOCH:\n",
      "Training Loss:[0.52333622]|Training Accuracy:0.75|Test Loss:[0.52286053]|Test Accuracy:0.75\n",
      "103th EPOCH:\n",
      "Training Loss:[0.52286053]|Training Accuracy:0.75|Test Loss:[0.52237623]|Test Accuracy:0.75\n",
      "104th EPOCH:\n",
      "Training Loss:[0.52237623]|Training Accuracy:0.75|Test Loss:[0.52188328]|Test Accuracy:0.75\n",
      "105th EPOCH:\n",
      "Training Loss:[0.52188328]|Training Accuracy:0.75|Test Loss:[0.52138167]|Test Accuracy:0.75\n",
      "106th EPOCH:\n",
      "Training Loss:[0.52138167]|Training Accuracy:0.75|Test Loss:[0.52087138]|Test Accuracy:0.75\n",
      "107th EPOCH:\n",
      "Training Loss:[0.52087138]|Training Accuracy:0.75|Test Loss:[0.52035239]|Test Accuracy:0.75\n",
      "108th EPOCH:\n",
      "Training Loss:[0.52035239]|Training Accuracy:0.75|Test Loss:[0.51982468]|Test Accuracy:0.75\n",
      "109th EPOCH:\n",
      "Training Loss:[0.51982468]|Training Accuracy:0.75|Test Loss:[0.51928824]|Test Accuracy:0.75\n",
      "110th EPOCH:\n",
      "Training Loss:[0.51928824]|Training Accuracy:0.75|Test Loss:[0.51874307]|Test Accuracy:0.75\n",
      "111th EPOCH:\n",
      "Training Loss:[0.51874307]|Training Accuracy:0.75|Test Loss:[0.51818916]|Test Accuracy:0.75\n",
      "112th EPOCH:\n",
      "Training Loss:[0.51818916]|Training Accuracy:0.75|Test Loss:[0.5176265]|Test Accuracy:0.75\n",
      "113th EPOCH:\n",
      "Training Loss:[0.5176265]|Training Accuracy:0.75|Test Loss:[0.5170551]|Test Accuracy:0.75\n",
      "114th EPOCH:\n",
      "Training Loss:[0.5170551]|Training Accuracy:0.75|Test Loss:[0.51647496]|Test Accuracy:0.75\n",
      "115th EPOCH:\n",
      "Training Loss:[0.51647496]|Training Accuracy:0.75|Test Loss:[0.51588607]|Test Accuracy:0.75\n",
      "116th EPOCH:\n",
      "Training Loss:[0.51588607]|Training Accuracy:0.75|Test Loss:[0.51528844]|Test Accuracy:0.75\n",
      "117th EPOCH:\n",
      "Training Loss:[0.51528844]|Training Accuracy:0.75|Test Loss:[0.51468208]|Test Accuracy:0.75\n",
      "118th EPOCH:\n",
      "Training Loss:[0.51468208]|Training Accuracy:0.75|Test Loss:[0.51406699]|Test Accuracy:0.75\n",
      "119th EPOCH:\n",
      "Training Loss:[0.51406699]|Training Accuracy:0.75|Test Loss:[0.51344317]|Test Accuracy:0.75\n",
      "120th EPOCH:\n",
      "Training Loss:[0.51344317]|Training Accuracy:0.75|Test Loss:[0.51281065]|Test Accuracy:0.75\n",
      "121th EPOCH:\n",
      "Training Loss:[0.51281065]|Training Accuracy:0.75|Test Loss:[0.51216941]|Test Accuracy:0.75\n",
      "122th EPOCH:\n",
      "Training Loss:[0.51216941]|Training Accuracy:0.75|Test Loss:[0.51151949]|Test Accuracy:0.75\n",
      "123th EPOCH:\n",
      "Training Loss:[0.51151949]|Training Accuracy:0.75|Test Loss:[0.51086087]|Test Accuracy:0.75\n",
      "124th EPOCH:\n",
      "Training Loss:[0.51086087]|Training Accuracy:0.75|Test Loss:[0.51019359]|Test Accuracy:0.75\n",
      "125th EPOCH:\n",
      "Training Loss:[0.51019359]|Training Accuracy:0.75|Test Loss:[0.50951764]|Test Accuracy:0.75\n",
      "126th EPOCH:\n",
      "Training Loss:[0.50951764]|Training Accuracy:0.75|Test Loss:[0.50883303]|Test Accuracy:0.75\n",
      "127th EPOCH:\n",
      "Training Loss:[0.50883303]|Training Accuracy:0.75|Test Loss:[0.50813979]|Test Accuracy:0.75\n",
      "128th EPOCH:\n",
      "Training Loss:[0.50813979]|Training Accuracy:0.75|Test Loss:[0.50743793]|Test Accuracy:0.75\n",
      "129th EPOCH:\n",
      "Training Loss:[0.50743793]|Training Accuracy:0.75|Test Loss:[0.50672745]|Test Accuracy:0.75\n",
      "130th EPOCH:\n",
      "Training Loss:[0.50672745]|Training Accuracy:0.75|Test Loss:[0.50600837]|Test Accuracy:0.75\n",
      "131th EPOCH:\n",
      "Training Loss:[0.50600837]|Training Accuracy:0.75|Test Loss:[0.5052807]|Test Accuracy:0.75\n",
      "132th EPOCH:\n",
      "Training Loss:[0.5052807]|Training Accuracy:0.75|Test Loss:[0.50454446]|Test Accuracy:0.75\n",
      "133th EPOCH:\n",
      "Training Loss:[0.50454446]|Training Accuracy:0.75|Test Loss:[0.50379967]|Test Accuracy:0.75\n",
      "134th EPOCH:\n",
      "Training Loss:[0.50379967]|Training Accuracy:0.75|Test Loss:[0.50304633]|Test Accuracy:0.75\n",
      "135th EPOCH:\n",
      "Training Loss:[0.50304633]|Training Accuracy:0.75|Test Loss:[0.50228446]|Test Accuracy:0.75\n",
      "136th EPOCH:\n",
      "Training Loss:[0.50228446]|Training Accuracy:0.75|Test Loss:[0.50151407]|Test Accuracy:0.75\n",
      "137th EPOCH:\n",
      "Training Loss:[0.50151407]|Training Accuracy:0.75|Test Loss:[0.50073518]|Test Accuracy:0.75\n",
      "138th EPOCH:\n",
      "Training Loss:[0.50073518]|Training Accuracy:0.75|Test Loss:[0.49994781]|Test Accuracy:0.75\n",
      "139th EPOCH:\n",
      "Training Loss:[0.49994781]|Training Accuracy:0.75|Test Loss:[0.49915197]|Test Accuracy:0.75\n",
      "140th EPOCH:\n",
      "Training Loss:[0.49915197]|Training Accuracy:0.75|Test Loss:[0.49834768]|Test Accuracy:0.75\n",
      "141th EPOCH:\n",
      "Training Loss:[0.49834768]|Training Accuracy:0.75|Test Loss:[0.49753494]|Test Accuracy:0.75\n",
      "142th EPOCH:\n",
      "Training Loss:[0.49753494]|Training Accuracy:0.75|Test Loss:[0.49671379]|Test Accuracy:0.75\n",
      "143th EPOCH:\n",
      "Training Loss:[0.49671379]|Training Accuracy:0.75|Test Loss:[0.49588422]|Test Accuracy:0.75\n",
      "144th EPOCH:\n",
      "Training Loss:[0.49588422]|Training Accuracy:0.75|Test Loss:[0.49504627]|Test Accuracy:0.75\n",
      "145th EPOCH:\n",
      "Training Loss:[0.49504627]|Training Accuracy:0.75|Test Loss:[0.49419994]|Test Accuracy:0.75\n",
      "146th EPOCH:\n",
      "Training Loss:[0.49419994]|Training Accuracy:0.75|Test Loss:[0.49334526]|Test Accuracy:0.75\n",
      "147th EPOCH:\n",
      "Training Loss:[0.49334526]|Training Accuracy:0.75|Test Loss:[0.49248223]|Test Accuracy:0.75\n",
      "148th EPOCH:\n",
      "Training Loss:[0.49248223]|Training Accuracy:0.75|Test Loss:[0.49161088]|Test Accuracy:0.75\n",
      "149th EPOCH:\n",
      "Training Loss:[0.49161088]|Training Accuracy:0.75|Test Loss:[0.49073123]|Test Accuracy:0.75\n",
      "150th EPOCH:\n",
      "Training Loss:[0.49073123]|Training Accuracy:0.75|Test Loss:[0.48984329]|Test Accuracy:0.75\n",
      "151th EPOCH:\n",
      "Training Loss:[0.48984329]|Training Accuracy:0.75|Test Loss:[0.48894708]|Test Accuracy:0.75\n",
      "152th EPOCH:\n",
      "Training Loss:[0.48894708]|Training Accuracy:0.75|Test Loss:[0.48804262]|Test Accuracy:0.75\n",
      "153th EPOCH:\n",
      "Training Loss:[0.48804262]|Training Accuracy:0.75|Test Loss:[0.48712994]|Test Accuracy:0.75\n",
      "154th EPOCH:\n",
      "Training Loss:[0.48712994]|Training Accuracy:0.75|Test Loss:[0.48620904]|Test Accuracy:0.75\n",
      "155th EPOCH:\n",
      "Training Loss:[0.48620904]|Training Accuracy:0.75|Test Loss:[0.48527995]|Test Accuracy:0.75\n",
      "156th EPOCH:\n",
      "Training Loss:[0.48527995]|Training Accuracy:0.75|Test Loss:[0.4843427]|Test Accuracy:0.75\n",
      "157th EPOCH:\n",
      "Training Loss:[0.4843427]|Training Accuracy:0.75|Test Loss:[0.4833973]|Test Accuracy:0.75\n",
      "158th EPOCH:\n",
      "Training Loss:[0.4833973]|Training Accuracy:0.75|Test Loss:[0.48244377]|Test Accuracy:0.75\n",
      "159th EPOCH:\n",
      "Training Loss:[0.48244377]|Training Accuracy:0.75|Test Loss:[0.48148214]|Test Accuracy:0.75\n",
      "160th EPOCH:\n",
      "Training Loss:[0.48148214]|Training Accuracy:0.75|Test Loss:[0.48051243]|Test Accuracy:0.75\n",
      "161th EPOCH:\n",
      "Training Loss:[0.48051243]|Training Accuracy:0.75|Test Loss:[0.47953466]|Test Accuracy:0.75\n",
      "162th EPOCH:\n",
      "Training Loss:[0.47953466]|Training Accuracy:0.75|Test Loss:[0.47854887]|Test Accuracy:0.75\n",
      "163th EPOCH:\n",
      "Training Loss:[0.47854887]|Training Accuracy:0.75|Test Loss:[0.47755507]|Test Accuracy:0.75\n",
      "164th EPOCH:\n",
      "Training Loss:[0.47755507]|Training Accuracy:0.75|Test Loss:[0.47655329]|Test Accuracy:0.75\n",
      "165th EPOCH:\n",
      "Training Loss:[0.47655329]|Training Accuracy:0.75|Test Loss:[0.47554356]|Test Accuracy:0.75\n",
      "166th EPOCH:\n",
      "Training Loss:[0.47554356]|Training Accuracy:0.75|Test Loss:[0.4745259]|Test Accuracy:0.75\n",
      "167th EPOCH:\n",
      "Training Loss:[0.4745259]|Training Accuracy:0.75|Test Loss:[0.47350035]|Test Accuracy:0.75\n",
      "168th EPOCH:\n",
      "Training Loss:[0.47350035]|Training Accuracy:0.75|Test Loss:[0.47246694]|Test Accuracy:0.75\n",
      "169th EPOCH:\n",
      "Training Loss:[0.47246694]|Training Accuracy:0.75|Test Loss:[0.47142569]|Test Accuracy:0.75\n",
      "170th EPOCH:\n",
      "Training Loss:[0.47142569]|Training Accuracy:0.75|Test Loss:[0.47037664]|Test Accuracy:0.75\n",
      "171th EPOCH:\n",
      "Training Loss:[0.47037664]|Training Accuracy:0.75|Test Loss:[0.46931981]|Test Accuracy:0.75\n",
      "172th EPOCH:\n",
      "Training Loss:[0.46931981]|Training Accuracy:0.75|Test Loss:[0.46825525]|Test Accuracy:0.75\n",
      "173th EPOCH:\n",
      "Training Loss:[0.46825525]|Training Accuracy:0.75|Test Loss:[0.46718299]|Test Accuracy:0.75\n",
      "174th EPOCH:\n",
      "Training Loss:[0.46718299]|Training Accuracy:0.75|Test Loss:[0.46610306]|Test Accuracy:0.75\n",
      "175th EPOCH:\n",
      "Training Loss:[0.46610306]|Training Accuracy:0.75|Test Loss:[0.46501551]|Test Accuracy:0.75\n",
      "176th EPOCH:\n",
      "Training Loss:[0.46501551]|Training Accuracy:0.75|Test Loss:[0.46392036]|Test Accuracy:0.75\n",
      "177th EPOCH:\n",
      "Training Loss:[0.46392036]|Training Accuracy:0.75|Test Loss:[0.46281766]|Test Accuracy:0.75\n",
      "178th EPOCH:\n",
      "Training Loss:[0.46281766]|Training Accuracy:0.75|Test Loss:[0.46170745]|Test Accuracy:0.75\n",
      "179th EPOCH:\n",
      "Training Loss:[0.46170745]|Training Accuracy:0.75|Test Loss:[0.46058977]|Test Accuracy:0.75\n",
      "180th EPOCH:\n",
      "Training Loss:[0.46058977]|Training Accuracy:0.75|Test Loss:[0.45946467]|Test Accuracy:0.75\n",
      "181th EPOCH:\n",
      "Training Loss:[0.45946467]|Training Accuracy:0.75|Test Loss:[0.45833218]|Test Accuracy:0.75\n",
      "182th EPOCH:\n",
      "Training Loss:[0.45833218]|Training Accuracy:0.75|Test Loss:[0.45719236]|Test Accuracy:0.75\n",
      "183th EPOCH:\n",
      "Training Loss:[0.45719236]|Training Accuracy:0.75|Test Loss:[0.45604525]|Test Accuracy:0.75\n",
      "184th EPOCH:\n",
      "Training Loss:[0.45604525]|Training Accuracy:0.75|Test Loss:[0.4548909]|Test Accuracy:0.75\n",
      "185th EPOCH:\n",
      "Training Loss:[0.4548909]|Training Accuracy:0.75|Test Loss:[0.45372936]|Test Accuracy:0.75\n",
      "186th EPOCH:\n",
      "Training Loss:[0.45372936]|Training Accuracy:0.75|Test Loss:[0.45256068]|Test Accuracy:0.75\n",
      "187th EPOCH:\n",
      "Training Loss:[0.45256068]|Training Accuracy:0.75|Test Loss:[0.45138491]|Test Accuracy:0.75\n",
      "188th EPOCH:\n",
      "Training Loss:[0.45138491]|Training Accuracy:0.75|Test Loss:[0.45020211]|Test Accuracy:0.75\n",
      "189th EPOCH:\n",
      "Training Loss:[0.45020211]|Training Accuracy:0.75|Test Loss:[0.44901233]|Test Accuracy:0.75\n",
      "190th EPOCH:\n",
      "Training Loss:[0.44901233]|Training Accuracy:0.75|Test Loss:[0.44781563]|Test Accuracy:0.75\n",
      "191th EPOCH:\n",
      "Training Loss:[0.44781563]|Training Accuracy:0.75|Test Loss:[0.44661207]|Test Accuracy:0.75\n",
      "192th EPOCH:\n",
      "Training Loss:[0.44661207]|Training Accuracy:0.75|Test Loss:[0.44540171]|Test Accuracy:0.75\n",
      "193th EPOCH:\n",
      "Training Loss:[0.44540171]|Training Accuracy:0.75|Test Loss:[0.44418461]|Test Accuracy:0.75\n",
      "194th EPOCH:\n",
      "Training Loss:[0.44418461]|Training Accuracy:0.75|Test Loss:[0.44296083]|Test Accuracy:0.75\n",
      "195th EPOCH:\n",
      "Training Loss:[0.44296083]|Training Accuracy:0.75|Test Loss:[0.44173044]|Test Accuracy:0.75\n",
      "196th EPOCH:\n",
      "Training Loss:[0.44173044]|Training Accuracy:0.75|Test Loss:[0.4404935]|Test Accuracy:0.75\n",
      "197th EPOCH:\n",
      "Training Loss:[0.4404935]|Training Accuracy:0.75|Test Loss:[0.43925008]|Test Accuracy:0.75\n",
      "198th EPOCH:\n",
      "Training Loss:[0.43925008]|Training Accuracy:0.75|Test Loss:[0.43800026]|Test Accuracy:0.75\n",
      "199th EPOCH:\n",
      "Training Loss:[0.43800026]|Training Accuracy:0.75|Test Loss:[0.43674409]|Test Accuracy:0.75\n"
     ]
    }
   ],
   "source": [
    "# Now we can train the model by iteratively on each datapoint.\n",
    "\n",
    "layer_list = [2,3, 1]\n",
    "activation_list = ['sigmoid','sigmoid']\n",
    "model = MultiLayerPerceptron(layer_list,activation_list)\n",
    "\n",
    "\n",
    "_=model.train(X_train,\n",
    "            Y_train,\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            metric ='accuracy_binary',\n",
    "            loss_function_string='mean_binary_cross_entropy',\n",
    "            epochs=200,\n",
    "            record_at=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can predict the values for unseen data or trained data also\n",
    "# We can also calculate the accuracy of the model we have trained\n",
    "model.metric_function(X_train,Y_train,metric='accuracy_binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N Bit XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Lets try working with just a little better data. A n XOR operator. So lets create the dataset for n bit xor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would have atmost 2^n data point in this type of data set.But we would limit our dataset to a 1000 data points\n",
    "whichever is smaller.\n",
    "\n",
    "Then we can divide into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "max_datapoint = 10000\n",
    "datapoints = min(pow(2,n) , max_datapoint)\n",
    "\n",
    "X = np.zeros((datapoints , n) , dtype=np.int32)\n",
    "Y = np.zeros((datapoints , 1), dtype=np.int32)\n",
    "\n",
    "for i in range(datapoints):\n",
    "    tmp = i\n",
    "    y_tmp = 0\n",
    "    for j in range(n-1 , -1 , -1):\n",
    "        X[i,j] = tmp&1\n",
    "        y_tmp = y_tmp^X[i,j]\n",
    "        tmp = tmp>>1\n",
    "    Y[i] = y_tmp\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 1] [1]\n"
     ]
    }
   ],
   "source": [
    "# for sanity check lets print one example\n",
    "ind = 11\n",
    "print(X[ind] , Y[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets divide the set in training and testing\n",
    "div = 0.9\n",
    "train_n = int(div * datapoints)\n",
    "X_train = X[:train_n]\n",
    "Y_train = Y[:train_n]\n",
    "\n",
    "X_test = X[train_n:]\n",
    "Y_test = Y[train_n:]\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20) (20,)\n",
      "<function relu at 0x7f1c10610bf8>\n",
      "(20, 20) (20,)\n",
      "<function sigmoid at 0x7f1c106109d8>\n",
      "(20, 15) (15,)\n",
      "<function sigmoid at 0x7f1c106109d8>\n",
      "(15, 8) (8,)\n",
      "<function sigmoid at 0x7f1c106109d8>\n",
      "(8, 4) (4,)\n",
      "<function tanh at 0x7f1c10610ae8>\n",
      "(4, 1) (1,)\n",
      "<function sigmoid at 0x7f1c106109d8>\n"
     ]
    }
   ],
   "source": [
    "layer_list = [n,20,20,15,8,4,1]\n",
    "activation_list = ['relu','sigmoid','sigmoid','sigmoid','tanh','sigmoid']\n",
    "\n",
    "model = MultiLayerPerceptron(layer_list,activation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th EPOCH:\n",
      "Training Loss:[1.32349133]|Training Accuracy:0.500542888165038|Test Loss:[0.92895098]|Test Accuracy:0.5048543689320388\n",
      "2000th EPOCH:\n",
      "Training Loss:[0.69314659]|Training Accuracy:0.500542888165038|Test Loss:[0.69315831]|Test Accuracy:0.49514563106796117\n",
      "4000th EPOCH:\n",
      "Training Loss:[0.69314659]|Training Accuracy:0.500542888165038|Test Loss:[0.69315831]|Test Accuracy:0.49514563106796117\n",
      "6000th EPOCH:\n",
      "Training Loss:[0.69314659]|Training Accuracy:0.500542888165038|Test Loss:[0.69315831]|Test Accuracy:0.49514563106796117\n",
      "8000th EPOCH:\n",
      "Training Loss:[0.69314659]|Training Accuracy:0.500542888165038|Test Loss:[0.69315831]|Test Accuracy:0.49514563106796117\n",
      "10000th EPOCH:\n",
      "Training Loss:[0.69314659]|Training Accuracy:0.500542888165038|Test Loss:[0.69315831]|Test Accuracy:0.49514563106796117\n",
      "12000th EPOCH:\n",
      "Training Loss:[0.69314659]|Training Accuracy:0.500542888165038|Test Loss:[0.69315831]|Test Accuracy:0.49514563106796117\n",
      "14000th EPOCH:\n",
      "Training Loss:[0.69314659]|Training Accuracy:0.500542888165038|Test Loss:[0.69315831]|Test Accuracy:0.49514563106796117\n",
      "16000th EPOCH:\n",
      "Training Loss:[0.69314659]|Training Accuracy:0.500542888165038|Test Loss:[0.69315831]|Test Accuracy:0.49514563106796117\n",
      "18000th EPOCH:\n",
      "Training Loss:[0.69314659]|Training Accuracy:0.500542888165038|Test Loss:[0.69315831]|Test Accuracy:0.49514563106796117\n"
     ]
    }
   ],
   "source": [
    "train_loss_his,train_acc_his,test_loss_his,test_acc_his,epoch_his = model.train(X_train,\n",
    "                                                                                Y_train ,\n",
    "                                                                                X_test,\n",
    "                                                                                Y_test,\n",
    "                                                                                metric='accuracy_binary',\n",
    "                                                                                loss_function_string='mean_binary_cross_entropy',\n",
    "                                                                                epochs = 20000,\n",
    "                                                                                record_at = 2000,\n",
    "                                                                                learning_rate= 0.5,\n",
    "                                                                                learning_rate_decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(epoch_his,train_loss_his,test_loss_his)\n",
    "plot_loss(epoch_his,train_acc_his,test_acc_his)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Multiclass classification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcoords1 = [1,1,1,1,1]\n",
    "xcoords2 = [2,2,2,2,2]\n",
    "xcoords3 = [3,3,3,3,3]\n",
    "ycoords = [1,2,3,4,5]\n",
    "plt.plot(xcoords1, ycoords, label='class 1',marker='o')\n",
    "plt.plot(xcoords2, ycoords, label='class 2',marker='s')\n",
    "plt.plot(xcoords3, ycoords, label='class 3',marker='D')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the dataset\n",
    "dataset = [[i,j] for i in range(1,6) for j in range(1,4)]\n",
    "labels = [[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = 0.8\n",
    "N = len(dataset)\n",
    "X_train = np.array(dataset[:int(div*N)])\n",
    "Y_train = np.array(labels[:int(div*N)])\n",
    "X_test = np.array(dataset[int(div*N):])\n",
    "Y_test = np.array(labels[int(div*N):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = [2,6,3]#,8,8,8,6,3]\n",
    "activation_list = ['relu','sigmoid']#,'relu','relu','relu','relu']\n",
    "model = MultiLayerPerceptron(layer_list,activation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_his,train_acc_his,test_loss_his,test_acc_his,epoch_his = model.train(X_train,\n",
    "                                                                                Y_train ,\n",
    "                                                                                X_test,\n",
    "                                                                                Y_test,\n",
    "                                                                                metric='accuracy_multiclass',\n",
    "                                                                                loss_function_string='mean_multiclass_cross_entropy',\n",
    "                                                                                epochs = 20000,\n",
    "                                                                                record_at = 1000,\n",
    "                                                                                learning_rate= 0.1,\n",
    "                                                                                learning_rate_decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[1].W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(epoch_his,train_loss_his,test_loss_his)\n",
    "plot_accuracy(epoch_his,train_acc_his,test_acc_his)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gene expression cancer RNA-Seq Data Set\n",
    "From UCI Machine Learning Dataset Repository  \n",
    "By Samuele Fiorini, University of Genoa  \n",
    "Link : https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('TCGA-PANCAN-HiSeq-801x20531/data.csv')\n",
    "labels = pd.read_csv('TCGA-PANCAN-HiSeq-801x20531/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
